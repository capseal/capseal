
//==============================================================================
// FILE: ./Cargo.toml
//==============================================================================
[workspace]
members = [
    "crates/fusion-core",
    "crates/fusion-envs",
    "crates/fusion-bindings",
]
resolver = "2"

[workspace.dependencies]
nalgebra = { version = "0.33", features = ["serde-serialize"] }
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
anyhow = "1.0"
rayon = "1.10"
rand = "0.8"
rand_chacha = "0.3"

[profile.release]
opt-level = 3
lto = true
codegen-units = 1
//==============================================================================
// FILE: ./crates/fusion-bindings/Cargo.toml
//==============================================================================
[package]
name = "fusion-bindings"
version = "0.1.0"
edition = "2021"

[lib]
name = "fusion_alpha"
crate-type = ["cdylib"]

[dependencies]
fusion-core = { path = "../fusion-core" }
fusion-envs = { path = "../fusion-envs" }
pyo3 = { version = "0.20", features = ["extension-module", "abi3-py38"] }
numpy = "0.20"
ndarray = "0.15"
anyhow = { workspace = true }

[build-dependencies]
pyo3-build-config = "0.20"

//==============================================================================
// FILE: ./crates/fusion-bindings/src/lib.rs
//==============================================================================
use fusion_core::*;
use numpy::{PyArray1, PyArray2, PyReadonlyArray1, PyReadonlyArray2};
use pyo3::prelude::*;

const ETA_MIN: f32 = 0.1;
const ETA_MAX: f32 = 10.0;

/// Simple committor propagation (core functionality)
#[pyfunction]
fn simple_propagate<'py>(
    py: Python<'py>,
    nodes: PyReadonlyArray2<f32>, // (N, 2) node coordinates
    edges: PyReadonlyArray2<f32>, // (M, 3) edge list [u, v, w]
    goal_node: usize,
    current_node: usize,
    enn_q_prior: f32,
    severity: f32,
    t_max: usize,
) -> PyResult<&'py PyArray1<f32>> {
    // Build graph with shape validation
    let nodes_array = nodes.as_array();
    let edges_array = edges.as_array();

    // Validate shapes
    if nodes_array.ncols() != 2 {
        return Err(PyErr::new::<pyo3::exceptions::PyValueError, _>(format!(
            "nodes must be (N, 2), got shape ({}, {})",
            nodes_array.nrows(),
            nodes_array.ncols()
        )));
    }

    if edges_array.ncols() != 3 {
        return Err(PyErr::new::<pyo3::exceptions::PyValueError, _>(format!(
            "edges must be (M, 3), got shape ({}, {})",
            edges_array.nrows(),
            edges_array.ncols()
        )));
    }

    let n_nodes = nodes_array.nrows();

    let mut node_list = Vec::new();
    for i in 0..n_nodes {
        let x = nodes_array[[i, 0]];
        let y = nodes_array[[i, 1]];
        node_list.push(NodeFeat::new(x, y));
    }

    let mut edge_list = Vec::new();
    for i in 0..edges_array.nrows() {
        let u = edges_array[[i, 0]];
        let v = edges_array[[i, 1]];
        let w = edges_array[[i, 2]];

        // Validate edge indices and weights
        if !u.is_finite() || !v.is_finite() || !w.is_finite() {
            return Err(PyErr::new::<pyo3::exceptions::PyValueError, _>(format!(
                "edge {} contains non-finite values: [{}, {}, {}]",
                i, u, v, w
            )));
        }

        let u_idx = u as usize;
        let v_idx = v as usize;

        if u_idx >= n_nodes || v_idx >= n_nodes {
            return Err(PyErr::new::<pyo3::exceptions::PyValueError, _>(format!(
                "edge {} has invalid indices: {} -> {} (max node: {})",
                i,
                u_idx,
                v_idx,
                n_nodes - 1
            )));
        }

        if w < 0.0 {
            return Err(PyErr::new::<pyo3::exceptions::PyValueError, _>(format!(
                "edge {} has negative weight: {}",
                i, w
            )));
        }

        edge_list.push(Edge::new(u_idx, v_idx, w));
    }

    let graph = Graph::new(node_list, edge_list);

    // Validate node indices
    if goal_node >= n_nodes {
        return Err(PyErr::new::<pyo3::exceptions::PyValueError, _>(format!(
            "goal_node {} exceeds max node index {}",
            goal_node,
            n_nodes - 1
        )));
    }

    if current_node >= n_nodes {
        return Err(PyErr::new::<pyo3::exceptions::PyValueError, _>(format!(
            "current_node {} exceeds max node index {}",
            current_node,
            n_nodes - 1
        )));
    }

    // Validate parameters
    if !enn_q_prior.is_finite() || enn_q_prior < 0.0 || enn_q_prior > 1.0 {
        return Err(PyErr::new::<pyo3::exceptions::PyValueError, _>(format!(
            "enn_q_prior must be finite and in [0,1], got {}",
            enn_q_prior
        )));
    }

    if !severity.is_finite() || severity < 0.0 || severity > 1.0 {
        return Err(PyErr::new::<pyo3::exceptions::PyValueError, _>(format!(
            "severity must be finite and in [0,1], got {}",
            severity
        )));
    }

    // Set up priors
    let mut q0 = vec![None; graph.num_nodes()];
    let mut eta = vec![0.0; graph.num_nodes()];

    // Goal boundary
    q0[goal_node] = Some(1.0);
    eta[goal_node] = 1e9;

    let fusion_state = FusionState::from_severity(enn_q_prior, severity, 0.0);

    // ENN prior using reliability mapping
    q0[current_node] = Some(fusion_state.q_prior_enn);
    eta[current_node] = eta_from_reliability(fusion_state.obs_reliability);

    // Propagate
    let config = PropConfig {
        t_max,
        eps: 1e-4,
        use_parallel: true,
        alpha_max: 6.0,
        step_policy: StepPolicy::RiskScaled,
    };

    let t_steps = fusion_state.propagation_steps(&config);
    let q_values = propagate_committor(
        &graph,
        &q0,
        &eta,
        &config,
        t_steps,
        fusion_state.effective_risk(),
    );

    Ok(PyArray1::from_vec(py, q_values))
}

/// Full-field committor propagation
#[pyfunction]
fn propagate_field<'py>(
    py: Python<'py>,
    nodes: PyReadonlyArray2<f32>, // (N, 2) node coordinates
    edges: PyReadonlyArray2<f32>, // (M, 3) edge list [u, v, w]
    priors: PyReadonlyArray1<f32>,      // (N) prior values, use NaN for missing
    confidences: PyReadonlyArray1<f32>, // (N) confidence weights
    severity: f32,
    t_max: usize,
) -> PyResult<&'py PyArray1<f32>> {
    let nodes_array = nodes.as_array();
    let edges_array = edges.as_array();
    let priors_array = priors.as_array();
    let conf_array = confidences.as_array();
    
    let n_nodes = nodes_array.nrows();

    if priors_array.len() != n_nodes {
        return Err(PyErr::new::<pyo3::exceptions::PyValueError, _>(format!(
            "priors must have length {}, got {}", n_nodes, priors_array.len()
        )));
    }
    if conf_array.len() != n_nodes {
        return Err(PyErr::new::<pyo3::exceptions::PyValueError, _>(format!(
            "confidences must have length {}, got {}", n_nodes, conf_array.len()
        )));
    }

    let mut node_list = Vec::new();
    for i in 0..n_nodes {
        node_list.push(NodeFeat::new(nodes_array[[i, 0]], nodes_array[[i, 1]]));
    }

    let mut edge_list = Vec::new();
    for i in 0..edges_array.nrows() {
        let u = edges_array[[i, 0]] as usize;
        let v = edges_array[[i, 1]] as usize;
        let w = edges_array[[i, 2]];
        edge_list.push(Edge::new(u, v, w));
    }

    let graph = Graph::new(node_list, edge_list);

    let mut q0 = vec![None; n_nodes];
    let mut eta = vec![0.0; n_nodes];

    for i in 0..n_nodes {
        let p = priors_array[i];
        let c = conf_array[i];
        if p.is_finite() {
            q0[i] = Some(p);
            eta[i] = c; // Directly map confidence to eta
        }
    }

    let config = PropConfig {
        t_max,
        eps: 1e-4,
        use_parallel: true,
        alpha_max: 6.0,
        step_policy: StepPolicy::RiskScaled,
    };

    // Use severity to scale risk aversion
    let risk_aversion = severity.clamp(0.0, 1.0);
    
    // We use a fixed number of steps here for simplicity, or we could derive it
    let effective_steps = t_max;

    let q_values = propagate_committor(
        &graph,
        &q0,
        &eta,
        &config,
        effective_steps,
        risk_aversion,
    );

    Ok(PyArray1::from_vec(py, q_values))
}

fn eta_from_reliability(rel: f32) -> f32 {
    let clamped = rel.clamp(0.0, 1.0);
    ETA_MIN + (ETA_MAX - ETA_MIN) * clamped
}

/// Create a simple test graph
#[pyfunction]
fn create_simple_graph<'py>(
    py: Python<'py>,
) -> PyResult<(
    &'py PyArray2<f32>, // nodes
    &'py PyArray2<f32>, // edges
    usize,              // current_node
    usize,              // goal_node
)> {
    // 3-node chain: 0 -- 1 -- 2
    let nodes = vec![
        vec![0.0, 0.0], // Node 0
        vec![1.0, 0.0], // Node 1
        vec![2.0, 0.0], // Node 2 (goal)
    ];

    let edges = vec![
        vec![0.0, 1.0, 1.0], // 0 -> 1
        vec![1.0, 0.0, 1.0], // 1 -> 0
        vec![1.0, 2.0, 1.0], // 1 -> 2
        vec![2.0, 1.0, 1.0], // 2 -> 1
    ];

    let nodes_array = PyArray2::from_vec2(py, &nodes)?;
    let edges_array = PyArray2::from_vec2(py, &edges)?;

    Ok((nodes_array, edges_array, 0, 2))
}

/// Python module for Fusion Alpha committor planning
#[pymodule]
fn fusion_alpha(_py: Python<'_>, m: &PyModule) -> PyResult<()> {
    m.add_function(wrap_pyfunction!(simple_propagate, m)?)?;
    m.add_function(wrap_pyfunction!(propagate_field, m)?)?;
    m.add_function(wrap_pyfunction!(create_simple_graph, m)?)?;
    Ok(())
}

//==============================================================================
// FILE: ./crates/fusion-bindings/src/simple_lib.rs
//==============================================================================
use pyo3::prelude::*;
use numpy::{PyArray1, PyArray2, PyReadonlyArray1, PyReadonlyArray2};
use fusion_core::*;

const ETA_MIN: f32 = 0.1;
const ETA_MAX: f32 = 10.0;

/// Simplified Python bindings with working example
#[pymodule]
fn fusion_alpha(_py: Python<'_>, m: &PyModule) -> PyResult<()> {
    m.add_function(wrap_pyfunction!(simple_propagate, m)?)?;
    m.add_function(wrap_pyfunction!(create_simple_graph, m)?)?;
    Ok(())
}

/// Simple committor propagation (core functionality)
#[pyfunction]
fn simple_propagate<'py>(
    py: Python<'py>,
    nodes: PyReadonlyArray2<f32>,        // (N, 2) node coordinates
    edges: PyReadonlyArray2<f32>,        // (M, 3) edge list [u, v, w]
    goal_node: usize,
    current_node: usize,
    enn_q_prior: f32,
    severity: f32,
    t_max: usize,
) -> PyResult<&'py PyArray1<f32>> {
    
    // Build graph
    let nodes_array = nodes.as_array();
    let edges_array = edges.as_array();
    
    let mut node_list = Vec::new();
    for i in 0..nodes_array.nrows() {
        let x = nodes_array[[i, 0]];
        let y = nodes_array[[i, 1]];
        node_list.push(NodeFeat::new(x, y));
    }
    
    let mut edge_list = Vec::new();
    for i in 0..edges_array.nrows() {
        let u = edges_array[[i, 0]] as usize;
        let v = edges_array[[i, 1]] as usize;
        let w = edges_array[[i, 2]];
        edge_list.push(Edge::new(u, v, w));
    }
    
    let graph = Graph::new(node_list, edge_list);
    
    // Set up priors
    let mut q0 = vec![None; graph.num_nodes()];
    let mut eta = vec![0.0; graph.num_nodes()];
    
    // Goal boundary
    q0[goal_node] = Some(1.0);
    eta[goal_node] = 1e9;
    
    let fusion_state = FusionState::from_severity(enn_q_prior, severity, 0.0);
    q0[current_node] = Some(fusion_state.q_prior_enn);
    eta[current_node] = eta_from_reliability(fusion_state.obs_reliability);

    // Propagate
    let config = PropConfig {
        t_max,
        eps: 1e-4,
        use_parallel: true,
        alpha_max: 6.0,
        step_policy: StepPolicy::RiskScaled,
    };
    
    let t_steps = fusion_state.propagation_steps(&config);
    let q_values = propagate_committor(
        &graph,
        &q0,
        &eta,
        &config,
        t_steps,
        fusion_state.effective_risk(),
    );
    
    Ok(PyArray1::from_vec(py, q_values))
}

fn eta_from_reliability(rel: f32) -> f32 {
    let clamped = rel.clamp(0.0, 1.0);
    ETA_MIN + (ETA_MAX - ETA_MIN) * clamped
}

/// Create a simple test graph
#[pyfunction]
fn create_simple_graph<'py>(py: Python<'py>) -> PyResult<(
    &'py PyArray2<f32>,  // nodes
    &'py PyArray2<f32>,  // edges
    usize,               // current_node
    usize,               // goal_node
)> {
    // 3-node chain: 0 -- 1 -- 2
    let nodes = vec![
        vec![0.0, 0.0],  // Node 0
        vec![1.0, 0.0],  // Node 1
        vec![2.0, 0.0],  // Node 2 (goal)
    ];
    
    let edges = vec![
        vec![0.0, 1.0, 1.0],  // 0 -> 1
        vec![1.0, 0.0, 1.0],  // 1 -> 0
        vec![1.0, 2.0, 1.0],  // 1 -> 2
        vec![2.0, 1.0, 1.0],  // 2 -> 1
    ];
    
    let nodes_array = PyArray2::from_vec2(py, &nodes)?;
    let edges_array = PyArray2::from_vec2(py, &edges)?;
    
    Ok((nodes_array, edges_array, 0, 2))
}

//==============================================================================
// FILE: ./crates/fusion-core/Cargo.toml
//==============================================================================
[package]
name = "fusion-core"
version = "0.1.0"
edition = "2021"

[dependencies]
nalgebra = { workspace = true }
serde = { workspace = true }
serde_json = { workspace = true }
anyhow = { workspace = true }
rayon = { workspace = true }
rand = { workspace = true }

[dev-dependencies]
rand = { workspace = true }
rand_chacha = { workspace = true }
//==============================================================================
// FILE: ./crates/fusion-core/src/actions.rs
//==============================================================================
use crate::{Committor, Graph, NodeFeat, NodeId, F};
use std::cmp::Ordering;

/// Action selection from committor values
pub fn pick_next_node(graph: &Graph, q: &[Committor], current: NodeId) -> Option<NodeId> {
    if current >= graph.num_nodes() {
        return None;
    }

    let neighbors = graph.neighbors(current);
    if neighbors.is_empty() {
        return None;
    }

    // Find neighbor with highest committor value
    neighbors
        .iter()
        .max_by(|(u, _), (v, _)| match q[*u].partial_cmp(&q[*v]) {
            Some(Ordering::Equal) | None => u.cmp(v),
            Some(ordering) => ordering,
        })
        .map(|(node_id, _)| *node_id)
}

/// Improved action selection with exploration
pub fn pick_next_node_weighted(
    graph: &Graph,
    q: &[Committor],
    current: NodeId,
    temperature: F, // Higher = more exploration
    rng: &mut impl rand::Rng,
) -> Option<NodeId> {
    if current >= graph.num_nodes() {
        return None;
    }

    let neighbors = graph.neighbors(current);
    if neighbors.is_empty() {
        return None;
    }

    if temperature <= 1e-6 {
        // Greedy selection
        return pick_next_node(graph, q, current);
    }

    // Softmax over neighbor committor values
    let mut exp_vals = Vec::new();
    let mut sum_exp = 0.0;

    for &(neighbor, _) in neighbors {
        let exp_val = (q[neighbor] / temperature).exp();
        exp_vals.push(exp_val);
        sum_exp += exp_val;
    }

    // Sample from distribution
    let mut cumsum = 0.0;
    let sample = rng.gen::<f32>() * sum_exp;

    for (i, &exp_val) in exp_vals.iter().enumerate() {
        cumsum += exp_val;
        if sample <= cumsum {
            return Some(neighbors[i].0);
        }
    }

    // Fallback
    neighbors.last().map(|(node_id, _)| *node_id)
}

/// Environment-specific action decoders
pub trait ActionDecoder<Obs, Action> {
    fn to_action(&self, obs: &Obs, current_node: &NodeFeat, target_node: &NodeFeat) -> Action;
}

/// Waypoint-based action for spatial navigation
#[derive(Clone, Debug)]
pub struct WaypointDecoder {
    pub max_velocity: F,
    pub lookahead_steps: usize,
}

impl WaypointDecoder {
    pub fn new(max_velocity: F, lookahead_steps: usize) -> Self {
        Self {
            max_velocity,
            lookahead_steps,
        }
    }

    /// Convert target waypoint to velocity command
    pub fn waypoint_to_velocity(&self, current_pos: (F, F), target_pos: (F, F)) -> (F, F) {
        let dx = target_pos.0 - current_pos.0;
        let dy = target_pos.1 - current_pos.1;
        let dist = (dx * dx + dy * dy).sqrt();

        if dist < 1e-6 {
            return (0.0, 0.0);
        }

        let scale = (self.max_velocity / dist).min(1.0);
        (dx * scale, dy * scale)
    }

    /// Multi-step lookahead for smoother paths
    pub fn multi_step_target(
        &self,
        graph: &Graph,
        q: &[Committor],
        current: NodeId,
    ) -> Option<NodeId> {
        let mut node = current;

        // Follow gradient for multiple steps
        for _ in 0..self.lookahead_steps {
            if let Some(next) = pick_next_node(graph, q, node) {
                node = next;
            } else {
                break;
            }
        }

        if node != current {
            Some(node)
        } else {
            None
        }
    }
}

/// Humanoid maze actions
#[derive(Clone, Debug)]
pub struct HumanoidAction {
    pub forward_velocity: F,
    pub angular_velocity: F,
}

impl ActionDecoder<HumanoidObs, HumanoidAction> for WaypointDecoder {
    fn to_action(
        &self,
        obs: &HumanoidObs,
        _current: &NodeFeat,
        target: &NodeFeat,
    ) -> HumanoidAction {
        let current_pos = (obs.x, obs.y);
        let target_pos = (target.x, target.y);
        let current_angle = obs.angle;

        // Compute desired heading
        let dx = target_pos.0 - current_pos.0;
        let dy = target_pos.1 - current_pos.1;
        let target_angle = dy.atan2(dx);

        // Angular control
        let mut angle_diff = target_angle - current_angle;
        while angle_diff > std::f32::consts::PI {
            angle_diff -= 2.0 * std::f32::consts::PI;
        }
        while angle_diff < -std::f32::consts::PI {
            angle_diff += 2.0 * std::f32::consts::PI;
        }

        let angular_velocity = (angle_diff * 2.0).clamp(-self.max_velocity, self.max_velocity);

        // Forward velocity - reduce when turning
        let forward_scale = 1.0 - (angle_diff.abs() / std::f32::consts::PI) * 0.7;
        let forward_velocity = self.max_velocity * forward_scale.max(0.1);

        HumanoidAction {
            forward_velocity,
            angular_velocity,
        }
    }
}

/// Ant soccer actions  
#[derive(Clone, Debug)]
pub struct AntAction {
    pub torques: Vec<F>, // Joint torques
}

impl ActionDecoder<AntObs, AntAction> for WaypointDecoder {
    fn to_action(&self, obs: &AntObs, _current: &NodeFeat, target: &NodeFeat) -> AntAction {
        // Simple ball-chasing behavior
        // In practice, this would be a learned policy conditioned on target

        let ball_pos = (obs.ball_x, obs.ball_y);
        let ant_pos = (obs.ant_x, obs.ant_y);
        let target_pos = (target.x, target.y);

        // Compute desired ball displacement
        let desired_ball_dx = target_pos.0 - ball_pos.0;
        let desired_ball_dy = target_pos.1 - ball_pos.1;

        // Ant should position to push ball toward target
        let push_angle = desired_ball_dy.atan2(desired_ball_dx) + std::f32::consts::PI;
        let push_distance = 0.5; // Stay close to ball

        let desired_ant_x = ball_pos.0 + push_distance * push_angle.cos();
        let desired_ant_y = ball_pos.1 + push_distance * push_angle.sin();

        // Convert to joint torques (simplified PD controller)
        let ant_dx = desired_ant_x - ant_pos.0;
        let ant_dy = desired_ant_y - ant_pos.1;

        // Mock torque computation - in practice use learned controller
        let n_joints = 8;
        let mut torques = vec![0.0; n_joints];

        for i in 0..n_joints {
            let phase = i as F * 2.0 * std::f32::consts::PI / n_joints as F;
            torques[i] = 0.3 * (ant_dx * phase.cos() + ant_dy * phase.sin());
            torques[i] = torques[i].clamp(-1.0, 1.0);
        }

        AntAction { torques }
    }
}

/// Puzzle button press action
#[derive(Clone, Debug)]
pub struct PuzzleAction {
    pub button_id: usize, // Which button to press (0-19)
}

pub struct PuzzleDecoder;

impl ActionDecoder<PuzzleObs, PuzzleAction> for PuzzleDecoder {
    fn to_action(&self, _obs: &PuzzleObs, _current: &NodeFeat, _target: &NodeFeat) -> PuzzleAction {
        // For puzzle, the "action" is encoded in the edge between current and target
        // This is handled by pick_puzzle_button function
        PuzzleAction { button_id: 0 } // Placeholder
    }
}

/// Special case for puzzle: button selection
pub fn pick_puzzle_button(
    current_config: u32, // Current light configuration (bitmask)
    target_config: u32,  // Target light configuration
) -> Option<usize> {
    // Find which button press transforms current -> target
    for button in 0..20 {
        let mask = puzzle_button_mask(button);
        if current_config ^ mask == target_config {
            return Some(button);
        }
    }
    None
}

/// Get toggle mask for puzzle button
fn puzzle_button_mask(button: usize) -> u32 {
    // 4x5 grid, button affects itself + cross neighbors
    let row = button / 5;
    let col = button % 5;

    let mut mask = 0u32;

    // Toggle button itself
    mask |= 1 << button;

    // Toggle neighbors (cross pattern)
    let neighbors = [
        (row.wrapping_sub(1), col), // up
        (row + 1, col),             // down
        (row, col.wrapping_sub(1)), // left
        (row, col + 1),             // right
    ];

    for (r, c) in neighbors {
        if r < 4 && c < 5 {
            let neighbor_id = r * 5 + c;
            mask |= 1 << neighbor_id;
        }
    }

    mask
}

// Mock observation types for compilation
#[derive(Clone, Debug)]
pub struct HumanoidObs {
    pub x: F,
    pub y: F,
    pub angle: F,
}

#[derive(Clone, Debug)]
pub struct AntObs {
    pub ant_x: F,
    pub ant_y: F,
    pub ball_x: F,
    pub ball_y: F,
}

#[derive(Clone, Debug)]
pub struct PuzzleObs {
    pub config: u32, // 20-bit light configuration
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::{Edge, Graph};
    use rand::SeedableRng;
    use rand_chacha::ChaCha20Rng;

    #[test]
    fn test_pick_next_node() {
        let nodes = vec![
            NodeFeat::new(0.0, 0.0), // 0
            NodeFeat::new(1.0, 0.0), // 1
            NodeFeat::new(2.0, 0.0), // 2
        ];
        let edges = vec![Edge::new(0, 1, 1.0), Edge::new(0, 2, 1.0)];
        let graph = Graph::new(nodes, edges);

        let q = vec![0.3, 0.7, 0.9]; // Node 2 has highest value

        let next = pick_next_node(&graph, &q, 0).unwrap();
        assert_eq!(next, 2); // Should pick node 2 (highest q)
    }

    #[test]
    fn test_weighted_selection() {
        let nodes = vec![
            NodeFeat::new(0.0, 0.0),
            NodeFeat::new(1.0, 0.0),
            NodeFeat::new(2.0, 0.0),
        ];
        let edges = vec![Edge::new(0, 1, 1.0), Edge::new(0, 2, 1.0)];
        let graph = Graph::new(nodes, edges);

        let q = vec![0.0, 0.2, 0.8];
        let mut rng = ChaCha20Rng::seed_from_u64(42);

        // With high temperature, should sometimes pick suboptimal node 1
        let mut picks = [0; 3];
        for _ in 0..100 {
            if let Some(next) = pick_next_node_weighted(&graph, &q, 0, 2.0, &mut rng) {
                picks[next] += 1;
            }
        }

        assert!(picks[2] > picks[1]); // Node 2 should be picked more often
        assert!(picks[1] > 0); // But node 1 should sometimes be picked too
        assert_eq!(picks[0], 0); // Node 0 is not a neighbor
    }

    #[test]
    fn test_waypoint_decoder() {
        let decoder = WaypointDecoder::new(2.0, 3);

        // Test velocity computation
        let (vx, vy) = decoder.waypoint_to_velocity((0.0, 0.0), (3.0, 4.0));
        let speed = (vx * vx + vy * vy).sqrt();
        assert!((speed - 2.0).abs() < 1e-6); // Should be clamped to max_velocity

        // Direction should be correct
        assert!((vx / vy - 3.0 / 4.0).abs() < 1e-6);
    }

    #[test]
    fn test_puzzle_button_mask() {
        // Button 0 (top-left) should toggle itself + right + down
        let mask = puzzle_button_mask(0);
        let expected = (1 << 0) | (1 << 1) | (1 << 5); // positions 0, 1, 5
        assert_eq!(mask, expected);

        // Button 12 (middle) should toggle cross pattern
        let mask = puzzle_button_mask(12);
        let expected = (1 << 12) | (1 << 7) | (1 << 17) | (1 << 11) | (1 << 13);
        assert_eq!(mask, expected);
    }

    #[test]
    fn test_pick_puzzle_button() {
        let current = 0b00000_00000_00000_00000; // All lights off

        // Calculate what button 12 actually produces (light 12 + its cross)
        let mask12 = puzzle_button_mask(12);
        let target = current ^ mask12; // This is what button 12 creates

        // Try to find the button that transforms current -> target
        let button = pick_puzzle_button(current, target);

        // Should find button 12
        assert!(button.is_some());
        assert_eq!(button.unwrap(), 12);

        // Verify the transformation works
        let mask = puzzle_button_mask(button.unwrap());
        assert_eq!(current ^ mask, target);
    }
}

//==============================================================================
// FILE: ./crates/fusion-core/src/graph.rs
//==============================================================================
use serde::{Deserialize, Serialize};
use std::cmp::Ordering;

/// Generic node features (spatial coords + extra)
#[derive(Clone, Debug, Serialize, Deserialize)]
pub struct NodeFeat {
    pub x: f32,
    pub y: f32,
    pub extra: Vec<f32>,
}

impl NodeFeat {
    pub fn new(x: f32, y: f32) -> Self {
        Self {
            x,
            y,
            extra: Vec::new(),
        }
    }

    pub fn with_extra(x: f32, y: f32, extra: Vec<f32>) -> Self {
        Self { x, y, extra }
    }

    pub fn distance_to(&self, other: &NodeFeat) -> f32 {
        ((self.x - other.x).powi(2) + (self.y - other.y).powi(2)).sqrt()
    }

    pub fn to_vec(&self) -> Vec<f32> {
        let mut v = vec![self.x, self.y];
        v.extend(&self.extra);
        v
    }
}

/// Weighted edge between nodes
#[derive(Clone, Debug, Serialize, Deserialize)]
pub struct Edge {
    pub u: usize, // source node id
    pub v: usize, // target node id
    pub w: f32,   // edge weight (reliability/frequency)
}

impl Edge {
    pub fn new(u: usize, v: usize, w: f32) -> Self {
        Self { u, v, w }
    }
}

/// Task graph for committor propagation
#[derive(Clone, Debug, Serialize, Deserialize)]
pub struct Graph {
    pub nodes: Vec<NodeFeat>,
    pub edges: Vec<Edge>,
    adjacency: Option<Vec<Vec<(usize, f32)>>>, // cached adjacency lists
}

impl Graph {
    pub fn new(nodes: Vec<NodeFeat>, edges: Vec<Edge>) -> Self {
        let mut g = Self {
            nodes,
            edges,
            adjacency: None,
        };
        g.build_adjacency();
        g
    }

    pub fn num_nodes(&self) -> usize {
        self.nodes.len()
    }

    pub fn num_edges(&self) -> usize {
        self.edges.len()
    }

    /// Build adjacency list representation for fast neighbor queries
    fn build_adjacency(&mut self) {
        let n = self.nodes.len();
        let mut adj = vec![Vec::new(); n];

        for edge in &self.edges {
            if edge.u < n && edge.v < n {
                adj[edge.u].push((edge.v, edge.w));
            }
        }

        for neighbors in adj.iter_mut() {
            neighbors.sort_by(|(a, wa), (b, wb)| {
                a.cmp(b)
                    .then_with(|| wa.partial_cmp(wb).unwrap_or(Ordering::Equal))
            });
        }

        self.edges
            .sort_by(|a, b| a.u.cmp(&b.u).then_with(|| a.v.cmp(&b.v)));

        self.adjacency = Some(adj);
    }

    /// Get neighbors of node u with edge weights
    pub fn neighbors(&self, u: usize) -> &[(usize, f32)] {
        match &self.adjacency {
            Some(adj) => adj.get(u).map(|v| v.as_slice()).unwrap_or(&[]),
            None => &[],
        }
    }

    /// Add goal node at specified coordinates
    pub fn add_goal(&mut self, x: f32, y: f32) -> usize {
        let goal_id = self.nodes.len();
        self.nodes.push(NodeFeat::new(x, y));
        self.build_adjacency(); // rebuild adjacency
        goal_id
    }

    /// Add fail node(s) - absorbing boundaries
    pub fn add_fail(&mut self, x: f32, y: f32) -> usize {
        let fail_id = self.nodes.len();
        self.nodes.push(NodeFeat::new(x, y));
        self.build_adjacency();
        fail_id
    }

    /// Find nearest node to given coordinates
    pub fn nearest_node(&self, x: f32, y: f32) -> Option<usize> {
        let target = NodeFeat::new(x, y);
        self.nodes
            .iter()
            .enumerate()
            .min_by(|(_, a), (_, b)| {
                target
                    .distance_to(a)
                    .partial_cmp(&target.distance_to(b))
                    .unwrap_or(std::cmp::Ordering::Equal)
            })
            .map(|(i, _)| i)
    }

    /// Create grid-based graph for spatial domains
    pub fn grid(width: usize, height: usize, cell_size: f32, walls: Option<&[bool]>) -> Self {
        let mut nodes = Vec::new();
        let mut edges = Vec::new();

        // Create nodes
        for i in 0..height {
            for j in 0..width {
                let x = j as f32 * cell_size;
                let y = i as f32 * cell_size;
                nodes.push(NodeFeat::new(x, y));
            }
        }

        // Create edges (4-connected grid)
        for i in 0..height {
            for j in 0..width {
                let node_id = i * width + j;

                // Skip if current cell is wall
                if let Some(w) = walls {
                    if w.get(node_id) == Some(&true) {
                        continue;
                    }
                }

                // Connect to neighbors
                let neighbors = [
                    (i.wrapping_sub(1), j), // up
                    (i + 1, j),             // down
                    (i, j.wrapping_sub(1)), // left
                    (i, j + 1),             // right
                ];

                for (ni, nj) in neighbors {
                    if ni < height && nj < width {
                        let neighbor_id = ni * width + nj;

                        // Skip if neighbor is wall
                        if let Some(w) = walls {
                            if w.get(neighbor_id) == Some(&true) {
                                continue;
                            }
                        }

                        edges.push(Edge::new(node_id, neighbor_id, 1.0));
                    }
                }
            }
        }

        Self::new(nodes, edges)
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_node_feat() {
        let n1 = NodeFeat::new(0.0, 0.0);
        let n2 = NodeFeat::new(3.0, 4.0);
        assert!((n1.distance_to(&n2) - 5.0).abs() < 1e-6);
    }

    #[test]
    fn test_grid_graph() {
        let g = Graph::grid(3, 3, 1.0, None);
        assert_eq!(g.num_nodes(), 9);

        // Each interior node has 4 neighbors, boundary nodes fewer
        let center = 4; // middle of 3x3
        assert_eq!(g.neighbors(center).len(), 4);

        let corner = 0;
        assert_eq!(g.neighbors(corner).len(), 2);
    }

    #[test]
    fn test_walls() {
        let mut walls = vec![false; 9];
        walls[4] = true; // block center

        let g = Graph::grid(3, 3, 1.0, Some(&walls));

        // Center node should have no edges
        assert_eq!(g.neighbors(4).len(), 0);

        // Neighbors of center should not connect to center
        for &(neighbor, _) in g.neighbors(1) {
            assert_ne!(neighbor, 4);
        }
    }
}

//==============================================================================
// FILE: ./crates/fusion-core/src/lib.rs
//==============================================================================
pub mod actions;
pub mod graph;
pub mod priors;
pub mod propagation;

pub use actions::{pick_next_node, ActionDecoder};
pub use graph::{Edge, Graph, NodeFeat};
pub use priors::{PriorSource, Priors};
pub use propagation::{propagate_committor, PropConfig, StepPolicy};

/// Core types
pub type NodeId = usize;
pub type F = f32;
pub type Severity = f32; // [0,1] from ENN
pub type Committor = f32; // [0,1] value

const RELIABILITY_OOD_THRESHOLD: F = 0.05;
const DEFAULT_RISK_FALLBACK: F = 1.0;

/// Integration with BICEP/ENN
#[derive(Clone, Debug)]
pub struct FusionState {
    pub q_prior_enn: F,      // ENN's q prediction
    pub obs_reliability: F,  // Calibrated reliability [0,1]
    pub risk_aversion: F,    // Policy knob [0,1]
    pub bicep_confidence: F, // BICEP path reliability
}

impl FusionState {
    pub fn new(q_prior_enn: F, obs_reliability: F, risk_aversion: F, bicep_confidence: F) -> Self {
        Self {
            q_prior_enn,
            obs_reliability: obs_reliability.clamp(0.0, 1.0),
            risk_aversion: risk_aversion.clamp(0.0, 1.0),
            bicep_confidence,
        }
    }

    /// Backwards-compatible constructor from severity (legacy semantics).
    pub fn from_severity(q_prior_enn: F, severity: Severity, bicep_confidence: F) -> Self {
        let s = severity.clamp(0.0, 1.0);
        let obs_reliability = (1.0 - s).clamp(0.0, 1.0);
        Self::new(q_prior_enn, obs_reliability, s, bicep_confidence)
    }

    pub fn effective_risk(&self) -> F {
        if self.obs_reliability < RELIABILITY_OOD_THRESHOLD {
            DEFAULT_RISK_FALLBACK
        } else {
            self.risk_aversion
        }
    }

    pub fn propagation_steps(&self, config: &PropConfig) -> usize {
        let risk = self.effective_risk();
        match config.step_policy {
            StepPolicy::Fixed => config.t_max.max(1),
            StepPolicy::RiskScaled => {
                if config.t_max <= 1 {
                    1
                } else {
                    let span = (config.t_max - 1) as F;
                    1 + (span * risk).floor() as usize
                }
            }
        }
    }
}

//==============================================================================
// FILE: ./crates/fusion-core/src/priors.rs
//==============================================================================
use crate::{NodeId, F};
use serde::{Deserialize, Serialize};

/// Prior information for committor propagation
#[derive(Clone, Debug, Serialize, Deserialize)]
pub struct Priors {
    pub q0: Vec<Option<F>>, // Initial committor estimates (None = no prior)
    pub eta: Vec<F>,        // Confidence weights per node
}

impl Priors {
    pub fn new(num_nodes: usize) -> Self {
        Self {
            q0: vec![None; num_nodes],
            eta: vec![0.0; num_nodes],
        }
    }

    /// Set hard boundary condition (goal/fail)
    pub fn set_boundary(&mut self, node: NodeId, value: F, confidence: F) {
        if node < self.q0.len() {
            self.q0[node] = Some(value);
            self.eta[node] = confidence;
        }
    }

    /// Set soft prior (from ENN/BICEP)
    pub fn set_prior(&mut self, node: NodeId, value: F, confidence: F) {
        if node < self.q0.len() {
            self.q0[node] = Some(value);
            self.eta[node] = confidence;
        }
    }

    /// Set prior using reliability mapping to eta
    pub fn set_prior_with_reliability(
        &mut self,
        node: NodeId,
        value: F,
        obs_reliability: F,
        eta_min: F,
        eta_max: F,
    ) {
        if node < self.q0.len() {
            let eta = confidence::from_reliability(obs_reliability, eta_min, eta_max);
            self.set_prior(node, value, eta);
        }
    }

    /// Mark goal nodes (q = 1, high confidence)
    pub fn set_goals(&mut self, goal_nodes: &[NodeId]) {
        for &node in goal_nodes {
            self.set_boundary(node, 1.0, 1e9);
        }
    }

    /// Mark fail nodes (q = 0, high confidence)
    pub fn set_fails(&mut self, fail_nodes: &[NodeId]) {
        for &node in fail_nodes {
            self.set_boundary(node, 0.0, 1e9);
        }
    }

    /// Clear all priors
    pub fn clear(&mut self) {
        for i in 0..self.q0.len() {
            self.q0[i] = None;
            self.eta[i] = 0.0;
        }
    }

    pub fn len(&self) -> usize {
        self.q0.len()
    }

    pub fn is_empty(&self) -> bool {
        self.q0.is_empty()
    }
}

/// Source of prior information
#[derive(Clone, Debug)]
pub enum PriorSource {
    ENN {
        q_pred: F,     // ENN's q prediction
        confidence: F, // Based on ENN uncertainty
    },
    BICEP {
        success_rate: F, // Empirical success rate from rollouts
        n_paths: usize,  // Number of BICEP paths
        variance: F,     // Variance across paths
    },
    Manual {
        value: F,
        confidence: F,
    },
}

impl PriorSource {
    /// Convert to (value, confidence) pair
    pub fn to_prior(&self) -> (F, F) {
        match self {
            PriorSource::ENN { q_pred, confidence } => (*q_pred, *confidence),
            PriorSource::BICEP {
                success_rate,
                n_paths,
                variance,
            } => {
                // Confidence increases with more paths, decreases with variance
                let confidence = (*n_paths as F) / ((*n_paths as F) + 16.0);
                let confidence = confidence * (1.0 - variance.min(0.5) * 2.0);
                (*success_rate, confidence.max(0.01))
            }
            PriorSource::Manual { value, confidence } => (*value, *confidence),
        }
    }

    /// Create ENN-based prior with severity scaling
    pub fn from_enn(q_pred: F, severity: F, base_confidence: F) -> Self {
        // Higher severity = lower confidence in prediction
        let confidence = base_confidence * (1.0 - severity * 0.5);
        Self::ENN { q_pred, confidence }
    }

    /// Create ENN prior using calibrated reliability directly
    pub fn from_enn_reliability(q_pred: F, obs_reliability: F, eta_min: F, eta_max: F) -> Self {
        let confidence = confidence::from_reliability(obs_reliability, eta_min, eta_max);
        Self::ENN { q_pred, confidence }
    }

    /// Create BICEP-based prior from simulation results
    pub fn from_bicep_paths(outcomes: &[bool]) -> Self {
        let n_paths = outcomes.len();
        let success_count = outcomes.iter().filter(|&&x| x).count();
        let success_rate = if n_paths > 0 {
            success_count as F / n_paths as F
        } else {
            0.5
        };

        // Estimate variance (binomial)
        let variance = if n_paths > 1 {
            success_rate * (1.0 - success_rate) / (n_paths as F)
        } else {
            0.25
        };

        Self::BICEP {
            success_rate,
            n_paths,
            variance,
        }
    }
}

/// Builder for constructing priors from multiple sources
pub struct PriorBuilder {
    priors: Priors,
}

impl PriorBuilder {
    pub fn new(num_nodes: usize) -> Self {
        Self {
            priors: Priors::new(num_nodes),
        }
    }

    /// Add prior from any source
    pub fn add_prior(mut self, node: NodeId, source: PriorSource) -> Self {
        let (value, confidence) = source.to_prior();
        self.priors.set_prior(node, value, confidence);
        self
    }

    /// Set goal nodes
    pub fn with_goals(mut self, goal_nodes: &[NodeId]) -> Self {
        self.priors.set_goals(goal_nodes);
        self
    }

    /// Set fail nodes
    pub fn with_fails(mut self, fail_nodes: &[NodeId]) -> Self {
        self.priors.set_fails(fail_nodes);
        self
    }

    /// Build final priors
    pub fn build(self) -> Priors {
        self.priors
    }
}

/// Confidence estimation utilities
pub mod confidence {
    use super::F;

    /// Confidence from BICEP path statistics
    pub fn from_bicep(n_paths: usize, variance: F) -> F {
        let path_factor = (n_paths as F) / ((n_paths as F) + 16.0);
        let variance_factor = 1.0 - (variance * 2.0).min(0.9);
        (path_factor * variance_factor).max(0.01)
    }

    /// Confidence from ENN entropy/severity
    pub fn from_enn_entropy(entropy: F, severity: F, base_conf: F) -> F {
        // Lower entropy = higher confidence
        let entropy_factor = (-entropy).exp().min(1.0);
        // Lower severity = higher confidence
        let severity_factor = 1.0 - severity.min(0.9);
        (base_conf * entropy_factor * severity_factor).max(0.01)
    }

    /// Adaptive confidence based on local graph structure
    pub fn adaptive_spatial(
        distance_to_goal: F,
        local_density: F, // Number of nearby nodes
        max_distance: F,
    ) -> F {
        let dist_factor = 1.0 - (distance_to_goal / max_distance).min(1.0);
        let density_factor = (local_density / 10.0).min(1.0);
        (0.1 + 0.9 * dist_factor * density_factor).min(1.0)
    }

    /// Confidence derived from calibrated reliability
    pub fn from_reliability(obs_reliability: F, eta_min: F, eta_max: F) -> F {
        let rel = obs_reliability.clamp(0.0, 1.0);
        eta_min + (eta_max - eta_min) * rel
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_priors_basic() {
        let mut priors = Priors::new(5);

        priors.set_boundary(0, 1.0, 1e9); // Goal
        priors.set_boundary(4, 0.0, 1e9); // Fail
        priors.set_prior(2, 0.7, 0.5); // ENN prior

        assert_eq!(priors.q0[0], Some(1.0));
        assert_eq!(priors.q0[4], Some(0.0));
        assert_eq!(priors.q0[2], Some(0.7));
        assert_eq!(priors.q0[1], None);

        assert!(priors.eta[0] > 1e6);
        assert!(priors.eta[4] > 1e6);
        assert!((priors.eta[2] - 0.5).abs() < 1e-6);
    }

    #[test]
    fn test_prior_source_enn() {
        let source = PriorSource::from_enn(0.8, 0.3, 1.0);
        let (value, confidence) = source.to_prior();

        assert!((value - 0.8).abs() < 1e-6);
        assert!(confidence < 1.0); // Should be reduced due to severity
        assert!(confidence > 0.5); // But not too much
    }

    #[test]
    fn test_prior_source_bicep() {
        let outcomes = vec![true, true, false, true, false, true]; // 4/6 success
        let source = PriorSource::from_bicep_paths(&outcomes);

        let (value, confidence) = source.to_prior();
        assert!((value - 2.0 / 3.0).abs() < 1e-2); // ~0.67
        assert!(confidence > 0.0);
        assert!(confidence < 1.0);
    }

    #[test]
    fn test_builder() {
        let priors = PriorBuilder::new(4)
            .with_goals(&[3])
            .with_fails(&[0])
            .add_prior(
                1,
                PriorSource::Manual {
                    value: 0.6,
                    confidence: 0.8,
                },
            )
            .build();

        assert_eq!(priors.q0[3], Some(1.0));
        assert_eq!(priors.q0[0], Some(0.0));
        assert_eq!(priors.q0[1], Some(0.6));
        assert_eq!(priors.q0[2], None);
    }

    #[test]
    fn test_confidence_functions() {
        // BICEP confidence
        let conf1 = confidence::from_bicep(100, 0.1);
        let conf2 = confidence::from_bicep(10, 0.1);
        assert!(conf1 > conf2); // More paths = higher confidence

        let conf3 = confidence::from_bicep(100, 0.01);
        let conf4 = confidence::from_bicep(100, 0.3);
        assert!(conf3 > conf4); // Lower variance = higher confidence

        // ENN confidence
        let conf5 = confidence::from_enn_entropy(0.1, 0.2, 1.0);
        let conf6 = confidence::from_enn_entropy(1.0, 0.8, 1.0);
        assert!(conf5 > conf6); // Lower entropy + severity = higher confidence
    }
}

//==============================================================================
// FILE: ./crates/fusion-core/src/propagation.rs
//==============================================================================
use crate::{Committor, Graph, F};
use rayon::prelude::*;

#[derive(Clone, Copy, Debug, PartialEq, Eq)]
pub enum StepPolicy {
    Fixed,
    RiskScaled,
}

impl Default for StepPolicy {
    fn default() -> Self {
        StepPolicy::Fixed
    }
}

/// Configuration for committor propagation
#[derive(Clone, Debug)]
pub struct PropConfig {
    pub t_max: usize,       // Maximum iterations
    pub eps: F,             // Convergence tolerance
    pub use_parallel: bool, // Use parallel iterations
    pub alpha_max: F,       // Maximum risk parameter for risk-sensitive blending
    pub step_policy: StepPolicy,
}

impl Default for PropConfig {
    fn default() -> Self {
        Self {
            t_max: 100,
            eps: 1e-4,
            use_parallel: true,
            alpha_max: 6.0, // Pessimistic blending at high risk
            step_policy: StepPolicy::Fixed,
        }
    }
}

/// Solve committor with priors using Jacobi/Gauss-Seidel relaxation
///
/// Boundary conditions:
/// - Goal nodes: h = 1 (fixed)  
/// - Fail nodes: h = 0 (fixed)
/// - Other nodes: weighted harmonic mean of neighbors + prior
///
/// Update rule:
/// h_v^{t+1} = (Σ_{u∈N(v)} w_uv * h_u^t + η_v * d_v) / (Σ_{u∈N(v)} w_uv + η_v)
pub fn propagate_committor(
    graph: &Graph,
    q0: &[Option<F>], // Initial values (None = no prior)
    eta: &[F],        // Confidence weights
    config: &PropConfig,
    t_steps: usize,   // Actual propagation steps (policy-scaled)
    risk_aversion: F, // Risk sensitivity knob [0,1]
) -> Vec<Committor> {
    let n = graph.num_nodes();
    assert_eq!(q0.len(), n);
    assert_eq!(eta.len(), n);

    // Initialize values - start from zero except for fixed boundary conditions
    let mut h_curr = vec![0.0; n]; // Start from zero for better convergence
    let mut h_next = vec![0.0; n];

    // Set initial conditions - only for high-confidence boundary conditions
    for i in 0..n {
        if let Some(val) = q0[i] {
            if eta[i] > 1e6 {
                // Only set true boundary conditions
                h_curr[i] = val;
            }
        }
    }

    let effective_steps = t_steps.min(config.t_max);
    
    // Jacobi iterations
    for _iter in 0..effective_steps {
        if config.use_parallel {
            // Parallel update
            h_next.par_iter_mut().enumerate().for_each(|(v, h_v_next)| {
                *h_v_next = update_node(graph, &h_curr, q0, eta, v);
            });
        } else {
            // Sequential update
            for v in 0..n {
                h_next[v] = update_node(graph, &h_curr, q0, eta, v);
            }
        }

        // Explicit [0,1] clamp after all updates (prevents drift from α≠0 and spicy priors)
        for v in 0..n {
            h_next[v] = h_next[v].clamp(0.0, 1.0);
        }

        // Check convergence
        let max_change = h_curr
            .iter()
            .zip(h_next.iter())
            .map(|(old, new)| (old - new).abs())
            .fold(0.0, f32::max);

        if max_change < config.eps {
            break;
        }

        std::mem::swap(&mut h_curr, &mut h_next);
    }

    h_curr
}

/// Update single node using weighted harmonic mean + prior
fn update_node(graph: &Graph, h_curr: &[F], q0: &[Option<F>], eta: &[F], v: usize) -> F {
    // Fixed boundary conditions - check first
    if let Some(fixed_val) = q0[v] {
        if eta[v] > 1e6 {
            // High confidence = fixed boundary
            return fixed_val.clamp(0.0, 1.0);
        }
    }

    let neighbors = graph.neighbors(v);
    if neighbors.is_empty() && q0[v].is_none() {
        return 0.0; // Isolated node, start from zero
    }

    // Weighted sum from neighbors
    let mut neighbor_sum = 0.0;
    let mut weight_sum = 0.0;

    for &(u, w) in neighbors {
        neighbor_sum += w * h_curr[u];
        weight_sum += w;
    }

    // Add prior term only for non-boundary conditions
    let (prior_contrib, eta_v) = if let Some(prior_val) = q0[v] {
        if prior_val.is_finite() && eta[v] > 0.0 && eta[v].is_finite() && eta[v] <= 1e6 {
            (eta[v] * prior_val, eta[v])
        } else {
            (0.0, 0.0) // Skip boundary conditions and invalid priors
        }
    } else {
        (0.0, 0.0)
    };

    let total_weight = weight_sum + eta_v;

    if total_weight < 1e-12 {
        return 0.0; // Isolated node
    }

    let mut new_val = (neighbor_sum + prior_contrib) / total_weight;

    // Hard clamp to [0,1] and guard against NaN
    if new_val.is_nan() {
        new_val = 0.0;
    }
    new_val.clamp(0.0, 1.0)
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::Graph;

    #[test]
    fn test_simple_chain() {
        // Linear chain: 0 -- 1 -- 2
        // Goal at 2, start at 0
        let nodes = vec![
            crate::NodeFeat::new(0.0, 0.0),
            crate::NodeFeat::new(1.0, 0.0),
            crate::NodeFeat::new(2.0, 0.0),
        ];
        let edges = vec![
            crate::Edge::new(0, 1, 1.0),
            crate::Edge::new(1, 0, 1.0),
            crate::Edge::new(1, 2, 1.0),
            crate::Edge::new(2, 1, 1.0),
        ];
        let graph = Graph::new(nodes, edges);

        let mut q0 = vec![None; 3];
        q0[2] = Some(1.0); // Goal
        let eta = vec![0.0, 0.0, 1e9]; // Only goal is fixed

        let config = PropConfig {
            step_policy: StepPolicy::Fixed,
            ..PropConfig::default()
        };

        // Use early iterations where gradient is clear (before over-convergence)
        let h = propagate_committor(&graph, &q0, &eta, &config, 3, 0.0);

        // Should have gradient: h[0] < h[1] < h[2] = 1.0
        assert!((h[2] - 1.0).abs() < 1e-3);
        assert!(h[0] < h[1], "h[0]={} should be < h[1]={}", h[0], h[1]);
        assert!(h[1] < h[2]);

        // Expected values after 3 iterations: [0.5, 0.75, 1.0]
        assert!((h[0] - 0.5).abs() < 0.1);
        assert!((h[1] - 0.75).abs() < 0.1);
        assert!(h[1] - h[0] > 0.2); // Meaningful gradient
    }

    #[test]
    fn test_with_prior() {
        // 2x2 grid with strong prior at node 0
        let graph = Graph::grid(2, 2, 1.0, None);

        let mut q0 = vec![None; 4];
        q0[0] = Some(0.9); // Strong prior
        q0[3] = Some(1.0); // Goal

        let eta = vec![10.0, 0.0, 0.0, 1e9];

        let config = PropConfig {
            step_policy: StepPolicy::Fixed,
            ..PropConfig::default()
        };
        let h = propagate_committor(&graph, &q0, &eta, &config, 30, 0.0);

        assert!((h[3] - 1.0).abs() < 1e-3); // Goal fixed
        assert!(h[0] > 0.8); // Prior should persist
    }
}
//==============================================================================
// FILE: ./crates/fusion-envs/Cargo.toml
//==============================================================================
[package]
name = "fusion-envs"
version = "0.1.0"
edition = "2021"

[dependencies]
fusion-core = { path = "../fusion-core" }
nalgebra = { workspace = true }
serde = { workspace = true }
serde_json = { workspace = true }
anyhow = { workspace = true }
rand = { workspace = true }
rand_chacha = { workspace = true }

[dev-dependencies]
rand_chacha = { workspace = true }

[[example]]
name = "simple_demo"
path = "../../examples/simple_demo.rs"
//==============================================================================
// FILE: ./crates/fusion-envs/src/ant_soccer.rs
//==============================================================================
use fusion_core::{Graph, NodeFeat, Edge, Priors, PriorSource, F};

const ETA_MIN: F = 0.1;
const ETA_MAX: F = 10.0;
use fusion_core::priors::PriorBuilder;
use serde::{Deserialize, Serialize};
use std::collections::HashMap;

/// Ant soccer field configuration
#[derive(Clone, Debug, Serialize, Deserialize)]
pub struct FieldConfig {
    pub width: F,           // Field width (meters)
    pub height: F,          // Field height (meters) 
    pub cell_size: F,       // Ball position discretization
    pub goal_width: F,      // Goal width
    pub obstacles: Vec<Obstacle>, // Field obstacles
}

#[derive(Clone, Debug, Serialize, Deserialize)]
pub struct Obstacle {
    pub x: F,
    pub y: F,
    pub radius: F,
}

/// Ant soccer observation
#[derive(Clone, Debug)]
pub struct AntObs {
    pub ant_x: F,
    pub ant_y: F,
    pub ant_angle: F,
    pub ball_x: F,
    pub ball_y: F,
    pub ball_velocity: (F, F),
}

/// Soccer goal specification
#[derive(Clone, Debug)]
pub struct SoccerGoal {
    pub center_x: F,
    pub center_y: F,
    pub width: F,
    pub direction: F, // Goal direction (0 = right, π = left)
}

impl SoccerGoal {
    pub fn new(center_x: F, center_y: F, width: F, direction: F) -> Self {
        Self { center_x, center_y, width, direction }
    }
    
    /// Check if ball position scores
    pub fn scores(&self, ball_x: F, ball_y: F) -> bool {
        let dy = (ball_y - self.center_y).abs();
        
        if dy > self.width / 2.0 {
            return false;
        }
        
        // Check if ball crossed goal line
        match self.direction {
            d if d.abs() < 0.1 => ball_x > self.center_x,  // Right goal
            d if (d - std::f32::consts::PI).abs() < 0.1 => ball_x < self.center_x, // Left goal
            _ => false,
        }
    }
}

/// Build graph for ant soccer (ball-centric nodes)
pub fn build_graph_ant_soccer(
    obs: &AntObs,
    goal: &SoccerGoal,
    field: &FieldConfig,
    bicep_paths: Option<&SoccerBICEPPaths>,
) -> (Graph, usize, usize) {
    let grid_width = (field.width / field.cell_size) as usize;
    let grid_height = (field.height / field.cell_size) as usize;
    
    let mut nodes = Vec::new();
    let mut edges = Vec::new();
    
    // Create ball position nodes
    let mut node_map: HashMap<(usize, usize), usize> = HashMap::new();
    let mut node_id = 0;
    
    for i in 0..grid_height {
        for j in 0..grid_width {
            let x = j as F * field.cell_size + field.cell_size * 0.5;
            let y = i as F * field.cell_size + field.cell_size * 0.5;
            
            // Skip positions inside obstacles
            if is_inside_obstacle(x, y, &field.obstacles) {
                continue;
            }
            
            // Add control state information
            let ant_dist = ((x - obs.ant_x).powi(2) + (y - obs.ant_y).powi(2)).sqrt();
            let in_control = ant_dist < 1.5; // Ant can influence ball
            
            let mut extra = vec![if in_control { 1.0 } else { 0.0 }];
            extra.push(ant_dist); // Distance to ant
            
            nodes.push(NodeFeat::with_extra(x, y, extra));
            node_map.insert((i, j), node_id);
            node_id += 1;
        }
    }
    
    // Create edges (ball movement transitions)
    for ((i, j), &from_id) in &node_map {
        let from_x = nodes[from_id].x;
        let from_y = nodes[from_id].y;
        
        // Local ball movements (adjacent cells)
        let neighbors = [
            (*i as i32 - 1, *j as i32),     // up
            (*i as i32 + 1, *j as i32),     // down  
            (*i as i32, *j as i32 - 1),     // left
            (*i as i32, *j as i32 + 1),     // right
            (*i as i32 - 1, *j as i32 - 1), // diagonals
            (*i as i32 - 1, *j as i32 + 1),
            (*i as i32 + 1, *j as i32 - 1),
            (*i as i32 + 1, *j as i32 + 1),
        ];
        
        for (ni, nj) in neighbors {
            if ni >= 0 && nj >= 0 && (ni as usize) < grid_height && (nj as usize) < grid_width {
                if let Some(&to_id) = node_map.get(&(ni as usize, nj as usize)) {
                    let to_x = nodes[to_id].x;
                    let to_y = nodes[to_id].y;
                    
                    // Weight based on ant positioning cost
                    let move_dist = ((to_x - from_x).powi(2) + (to_y - from_y).powi(2)).sqrt();
                    let ant_repositioning_cost = compute_ant_cost(obs, from_x, from_y, to_x, to_y);
                    
                    let base_weight = 1.0 / (1.0 + move_dist);
                    let weight = base_weight / (1.0 + ant_repositioning_cost);
                    
                    edges.push(Edge::new(from_id, to_id, weight));
                }
            }
        }
        
        // Long-range ball shots (if ant is in control)
        let ant_dist = nodes[from_id].extra[1];
        if ant_dist < 1.0 {
            add_shot_edges(&mut edges, from_id, &nodes, from_x, from_y, field, goal);
        }
    }
    
    let mut graph = Graph::new(nodes, edges);
    
    // Find current ball node
    let current_ball_node = find_nearest_ball_node(&graph, obs.ball_x, obs.ball_y);
    
    // Add goal node
    let goal_node = graph.add_goal(goal.center_x, goal.center_y);
    
    // Connect goal to scoring positions
    add_goal_connections(&mut graph, goal_node, goal, field);
    
    // Add BICEP-discovered transitions
    if let Some(paths) = bicep_paths {
        add_soccer_bicep_edges(&mut graph, paths, field);
    }
    
    (graph, current_ball_node, goal_node)
}

/// Check if position is inside any obstacle
fn is_inside_obstacle(x: F, y: F, obstacles: &[Obstacle]) -> bool {
    obstacles.iter().any(|obs| {
        let dx = x - obs.x;
        let dy = y - obs.y;
        dx * dx + dy * dy <= obs.radius * obs.radius
    })
}

/// Compute cost for ant to reposition for ball movement
fn compute_ant_cost(obs: &AntObs, from_x: F, from_y: F, to_x: F, to_y: F) -> F {
    // Desired ant position to push ball from 'from' to 'to'
    let push_angle = (to_y - from_y).atan2(to_x - from_x) + std::f32::consts::PI;
    let desired_ant_x = from_x + 0.8 * push_angle.cos();
    let desired_ant_y = from_y + 0.8 * push_angle.sin();
    
    // Distance ant needs to move
    let ant_move_dist = ((desired_ant_x - obs.ant_x).powi(2) + (desired_ant_y - obs.ant_y).powi(2)).sqrt();
    
    // Angular cost (ant reorientation)
    let current_ant_angle = obs.ant_angle;
    let desired_ant_angle = (to_y - from_y).atan2(to_x - from_x);
    let mut angle_diff = (desired_ant_angle - current_ant_angle).abs();
    if angle_diff > std::f32::consts::PI {
        angle_diff = 2.0 * std::f32::consts::PI - angle_diff;
    }
    
    ant_move_dist * 0.5 + angle_diff * 0.3
}

/// Add long-range shot edges when ant is in control
fn add_shot_edges(
    edges: &mut Vec<Edge>,
    from_id: usize,
    nodes: &[NodeFeat],
    from_x: F,
    from_y: F,
    field: &FieldConfig,
    goal: &SoccerGoal,
) {
    let max_shot_dist = 4.0;
    let shot_angle_spread = std::f32::consts::PI / 3.0; // 60 degrees
    
    // Direction towards goal
    let goal_angle = (goal.center_y - from_y).atan2(goal.center_x - from_x);
    
    // Try shots in goal direction ± spread
    let num_shots = 5;
    for i in 0..num_shots {
        let angle_offset = (i as F - 2.0) * shot_angle_spread / 4.0;
        let shot_angle = goal_angle + angle_offset;
        
        for dist in [1.0, 2.0, 3.0, 4.0] {
            let target_x = from_x + dist * shot_angle.cos();
            let target_y = from_y + dist * shot_angle.sin();
            
            // Check bounds
            if target_x < 0.0 || target_x >= field.width || target_y < 0.0 || target_y >= field.height {
                continue;
            }
            
            // Find nearest node to target
            if let Some(target_id) = find_nearest_node(nodes, target_x, target_y) {
                if target_id != from_id {
                    // Weight decreases with distance and angle deviation
                    let angle_penalty = (angle_offset.abs() / shot_angle_spread).min(1.0);
                    let dist_penalty = (dist / max_shot_dist).min(1.0);
                    let shot_weight = 0.8 * (1.0 - angle_penalty) * (1.0 - dist_penalty);
                    
                    if shot_weight > 0.1 {
                        edges.push(Edge::new(from_id, target_id, shot_weight));
                    }
                }
            }
        }
    }
}

/// Find nearest node to ball position
fn find_nearest_ball_node(graph: &Graph, ball_x: F, ball_y: F) -> usize {
    graph.nearest_node(ball_x, ball_y).unwrap_or(0)
}

/// Find nearest node to coordinates
fn find_nearest_node(nodes: &[NodeFeat], x: F, y: F) -> Option<usize> {
    let target = NodeFeat::new(x, y);
    nodes.iter()
        .enumerate()
        .min_by(|(_, a), (_, b)| {
            target.distance_to(a).partial_cmp(&target.distance_to(b))
                .unwrap_or(std::cmp::Ordering::Equal)
        })
        .map(|(i, _)| i)
}

/// Connect goal node to scoring positions
fn add_goal_connections(graph: &mut Graph, goal_node: usize, goal: &SoccerGoal, _field: &FieldConfig) {
    let goal_approach_dist = 1.5; // Distance from goal line for high-value connections
    
    // Connect nodes near the goal line
    for node_id in 0..graph.nodes.len() - 1 { // Exclude the goal node itself
        let node = &graph.nodes[node_id];
        
        // Check if node is in scoring position
        if goal.scores(node.x, node.y) {
            // Direct scoring connection (very high weight)
            graph.edges.push(Edge::new(node_id, goal_node, 100.0));
            continue;
        }
        
        // Check if node is near goal and aligned
        let dist_to_goal = ((node.x - goal.center_x).powi(2) + (node.y - goal.center_y).powi(2)).sqrt();
        let y_alignment = (node.y - goal.center_y).abs();
        
        if dist_to_goal < goal_approach_dist && y_alignment < goal.width * 0.6 {
            let weight = 10.0 * (1.0 - dist_to_goal / goal_approach_dist);
            graph.edges.push(Edge::new(node_id, goal_node, weight));
        }
    }
}

/// Add edges from BICEP soccer simulations
fn add_soccer_bicep_edges(graph: &mut Graph, paths: &SoccerBICEPPaths, field: &FieldConfig) {
    let mut transition_counts: HashMap<(usize, usize), usize> = HashMap::new();
    
    // Count ball transitions in BICEP paths
    for path in &paths.paths {
        for window in path.ball_states.windows(2) {
            let from_node = ball_to_node_id(window[0].x, window[0].y, field);
            let to_node = ball_to_node_id(window[1].x, window[1].y, field);
            
            if let (Some(from), Some(to)) = (from_node, to_node) {
                if from != to {
                    *transition_counts.entry((from, to)).or_insert(0) += 1;
                }
            }
        }
    }
    
    // Add frequently observed transitions
    let min_observations = 2;
    for ((from, to), count) in transition_counts {
        if count >= min_observations && from < graph.num_nodes() && to < graph.num_nodes() {
            let weight = (count as F * 0.1).min(1.0);
            graph.edges.push(Edge::new(from, to, weight));
        }
    }
}

/// Convert ball position to node ID
fn ball_to_node_id(ball_x: F, ball_y: F, field: &FieldConfig) -> Option<usize> {
    let grid_x = (ball_x / field.cell_size) as usize;
    let grid_y = (ball_y / field.cell_size) as usize;
    let grid_width = (field.width / field.cell_size) as usize;
    let grid_height = (field.height / field.cell_size) as usize;
    
    if grid_x < grid_width && grid_y < grid_height {
        Some(grid_y * grid_width + grid_x)
    } else {
        None
    }
}

/// Build priors for ant soccer
pub fn build_soccer_priors(
    graph: &Graph,
    current_node: usize,
    goal_node: usize,
    enn_state: Option<&fusion_core::FusionState>,
    bicep_success_rate: Option<F>,
) -> Priors {
    let mut builder = PriorBuilder::new(graph.num_nodes())
        .with_goals(&[goal_node]);
    
    // ENN prior for current ball state
    if let Some(state) = enn_state {
        let enn_source = PriorSource::from_enn_reliability(
            state.q_prior_enn,
            state.obs_reliability,
            ETA_MIN,
            ETA_MAX,
        );
        builder = builder.add_prior(current_node, enn_source);
    }
    
    // BICEP success rate
    if let Some(success_rate) = bicep_success_rate {
        let bicep_source = PriorSource::Manual {
            value: success_rate,
            confidence: 0.7_f32.clamp(0.05, 0.95),
        };
        builder = builder.add_prior(current_node, bicep_source);
    }
    
    // Add distance-based priors (closer to goal = higher prior)
    for (node_id, node) in graph.nodes.iter().enumerate() {
        if node_id != current_node && node_id != goal_node {
            let goal_node_pos = &graph.nodes[goal_node];
            let dist_to_goal = node.distance_to(goal_node_pos);
            
            if dist_to_goal < 3.0 {
                let distance_prior = 1.0 - (dist_to_goal / 3.0);
                let spatial_source = PriorSource::Manual {
                    value: distance_prior,
                    confidence: 0.2_f32.clamp(0.05, 0.95),
                };
                builder = builder.add_prior(node_id, spatial_source);
            }
        }
    }
    
    builder.build()
}

/// BICEP paths for soccer (mock)
#[derive(Clone, Debug)]
pub struct SoccerBICEPPaths {
    pub paths: Vec<SoccerBICEPPath>,
}

#[derive(Clone, Debug)]
pub struct SoccerBICEPPath {
    pub ball_states: Vec<BallState>,
    pub ant_states: Vec<AntState>,
    pub scored: bool,
}

#[derive(Clone, Debug)]
pub struct BallState {
    pub x: F,
    pub y: F,
    pub vx: F,
    pub vy: F,
    pub t: F,
}

#[derive(Clone, Debug)]
pub struct AntState {
    pub x: F,
    pub y: F,
    pub angle: F,
    pub t: F,
}

impl SoccerBICEPPaths {
    pub fn success_rate(&self) -> F {
        if self.paths.is_empty() {
            return 0.1;
        }
        
        let goals = self.paths.iter().filter(|p| p.scored).count();
        goals as F / self.paths.len() as F
    }
}

/// Default field configurations
impl FieldConfig {
    /// Standard soccer field
    pub fn standard() -> Self {
        Self {
            width: 12.0,
            height: 8.0,
            cell_size: 0.4,
            goal_width: 2.0,
            obstacles: Vec::new(),
        }
    }
    
    /// Field with obstacles
    pub fn with_obstacles() -> Self {
        let mut field = Self::standard();
        field.obstacles = vec![
            Obstacle { x: 6.0, y: 4.0, radius: 0.8 }, // Center obstacle
            Obstacle { x: 3.0, y: 2.0, radius: 0.5 }, // Side obstacle
            Obstacle { x: 9.0, y: 6.0, radius: 0.5 }, // Side obstacle
        ];
        field
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    
    #[test]
    fn test_soccer_goal() {
        let goal = SoccerGoal::new(12.0, 4.0, 2.0, 0.0); // Right goal
        
        assert!(goal.scores(12.1, 4.0)); // Ball past goal line, centered
        assert!(goal.scores(12.1, 3.2)); // Ball past goal line, within width
        assert!(!goal.scores(12.1, 2.0)); // Ball past goal line, outside width
        assert!(!goal.scores(11.9, 4.0)); // Ball before goal line
    }
    
    #[test]
    fn test_obstacle_detection() {
        let obstacles = vec![
            Obstacle { x: 5.0, y: 5.0, radius: 1.0 },
        ];
        
        assert!(is_inside_obstacle(5.0, 5.0, &obstacles)); // Center
        assert!(is_inside_obstacle(5.8, 5.0, &obstacles)); // Edge
        assert!(!is_inside_obstacle(6.2, 5.0, &obstacles)); // Outside
    }
    
    #[test]
    fn test_ant_cost_computation() {
        let obs = AntObs {
            ant_x: 3.0,
            ant_y: 3.0,
            ant_angle: 0.0,
            ball_x: 5.0,
            ball_y: 3.0,
            ball_velocity: (0.0, 0.0),
        };
        
        // Moving ball right should have low cost (ant is already behind ball)
        let cost_right = compute_ant_cost(&obs, 5.0, 3.0, 6.0, 3.0);
        
        // Moving ball left should have higher cost (ant needs to reposition)
        let cost_left = compute_ant_cost(&obs, 5.0, 3.0, 4.0, 3.0);
        
        assert!(cost_right < cost_left);
    }
    
    #[test]
    fn test_build_soccer_graph() {
        let field = FieldConfig::standard();
        let obs = AntObs {
            ant_x: 6.0,
            ant_y: 4.0,
            ant_angle: 0.0,
            ball_x: 6.0,
            ball_y: 4.0,
            ball_velocity: (0.0, 0.0),
        };
        let goal = SoccerGoal::new(12.0, 4.0, 2.0, 0.0);
        
        let (graph, current, goal_node) = build_graph_ant_soccer(&obs, &goal, &field, None);
        
        assert!(graph.num_nodes() > 0);
        assert!(graph.num_edges() > 0);
        
        // Goal should have high committor value after propagation
        let priors = build_soccer_priors(&graph, current, goal_node, None, None);
        assert_eq!(priors.q0[goal_node], Some(1.0));
    }
}

//==============================================================================
// FILE: ./crates/fusion-envs/src/humanoid_maze.rs
//==============================================================================
use fusion_core::{Graph, Edge, Priors, PriorSource, F};

const ETA_MIN: F = 0.1;
const ETA_MAX: F = 10.0;
use fusion_core::priors::PriorBuilder;
use serde::{Deserialize, Serialize};
use std::collections::HashMap;

/// Humanoid maze environment configuration
#[derive(Clone, Debug, Serialize, Deserialize)]
pub struct MazeConfig {
    pub width: usize,
    pub height: usize,
    pub cell_size: F,        // Meters per cell
    pub walls: Vec<bool>,    // True = wall, False = free space
    pub teleporters: Vec<Teleporter>,
    pub white_holes: Vec<WhiteHole>, // Dead-end teleport destinations
}

#[derive(Clone, Debug, Serialize, Deserialize)]
pub struct Teleporter {
    pub from_x: usize,
    pub from_y: usize,
    pub to_x: usize,
    pub to_y: usize,
    pub success_prob: F, // Probability of successful teleport
}

#[derive(Clone, Debug, Serialize, Deserialize)]
pub struct WhiteHole {
    pub x: usize,
    pub y: usize,
    pub penalty: F, // Negative reward for ending up here
}

/// Humanoid observation
#[derive(Clone, Debug)]
pub struct HumanoidObs {
    pub x: F,
    pub y: F,
    pub angle: F,
    pub velocity: (F, F),
}

/// Goal specification
#[derive(Clone, Debug)]
pub struct GoalSpec {
    pub x: F,
    pub y: F,
    pub radius: F,
}

impl GoalSpec {
    pub fn new(x: F, y: F, radius: F) -> Self {
        Self { x, y, radius }
    }
    
    pub fn contains(&self, x: F, y: F) -> bool {
        let dx = x - self.x;
        let dy = y - self.y;
        dx * dx + dy * dy <= self.radius * self.radius
    }
}

/// Build graph for humanoid maze navigation
pub fn build_graph_humanoid(
    obs: &HumanoidObs,
    goal: &GoalSpec, 
    maze: &MazeConfig,
    bicep_paths: Option<&BICEPPaths>,
) -> (Graph, usize, usize) {
    // Create grid-based graph
    let mut graph = Graph::grid(maze.width, maze.height, maze.cell_size, Some(&maze.walls));
    
    // Add teleporter edges
    for teleporter in &maze.teleporters {
        let from_id = teleporter.from_y * maze.width + teleporter.from_x;
        let to_id = teleporter.to_y * maze.width + teleporter.to_x;
        
        // Check if destination is a white hole (dead end)
        let mut weight = teleporter.success_prob;
        for white_hole in &maze.white_holes {
            let white_hole_id = white_hole.y * maze.width + white_hole.x;
            if to_id == white_hole_id {
                // Strong penalty for known dead-end white holes
                // Apply both penalty factor and severity-based reduction
                weight *= 0.1 * (1.0 - white_hole.penalty.abs().min(0.8)); // 90% penalty + severity
                break;
            }
        }
        
        // Add stochastic teleport edge (downweighted by success probability and white holes)
        graph.edges.push(Edge::new(from_id, to_id, weight));
    }
    
    // Rebuild adjacency after adding teleporter edges
    let mut new_graph = Graph::new(graph.nodes, graph.edges);
    
    // Find current node (snap to nearest)
    let current_node = new_graph.nearest_node(obs.x, obs.y).unwrap_or(0);
    
    // Add goal node
    let goal_node = new_graph.add_goal(goal.x, goal.y);
    
    // Connect goal to nearby free cells
    add_goal_connections(&mut new_graph, goal_node, goal, maze);
    
    // Add BICEP-discovered edges if available
    if let Some(paths) = bicep_paths {
        add_bicep_edges(&mut new_graph, paths, maze);
    }
    
    (new_graph, current_node, goal_node)
}

/// Connect goal node to nearby reachable cells
fn add_goal_connections(graph: &mut Graph, goal_node: usize, goal: &GoalSpec, maze: &MazeConfig) {
    let goal_cell_x = (goal.x / maze.cell_size) as usize;
    let goal_cell_y = (goal.y / maze.cell_size) as usize;
    
    // Connect to cells within goal radius
    let radius_cells = ((goal.radius / maze.cell_size) as usize).max(1);
    
    for dy in 0..=radius_cells {
        for dx in 0..=radius_cells {
            for &(sx, sy) in &[(goal_cell_x + dx, goal_cell_y + dy),
                               (goal_cell_x.saturating_sub(dx), goal_cell_y + dy),
                               (goal_cell_x + dx, goal_cell_y.saturating_sub(dy)),
                               (goal_cell_x.saturating_sub(dx), goal_cell_y.saturating_sub(dy))] {
                
                if sx < maze.width && sy < maze.height {
                    let cell_id = sy * maze.width + sx;
                    let cell_center_x = sx as F * maze.cell_size + maze.cell_size * 0.5;
                    let cell_center_y = sy as F * maze.cell_size + maze.cell_size * 0.5;
                    
                    // Check if cell is within goal and not a wall
                    if goal.contains(cell_center_x, cell_center_y) && !maze.walls[cell_id] {
                        // Bidirectional connection with high weight
                        graph.edges.push(Edge::new(cell_id, goal_node, 10.0));
                        graph.edges.push(Edge::new(goal_node, cell_id, 10.0));
                    }
                }
            }
        }
    }
}

/// Add edges discovered by BICEP rollouts
fn add_bicep_edges(graph: &mut Graph, paths: &BICEPPaths, maze: &MazeConfig) {
    let mut edge_counts: HashMap<(usize, usize), usize> = HashMap::new();
    
    // Count transitions in BICEP paths
    for path in &paths.paths {
        for window in path.states.windows(2) {
            let from_cell = world_to_cell(window[0].x, window[0].y, maze);
            let to_cell = world_to_cell(window[1].x, window[1].y, maze);
            
            if let (Some(from), Some(to)) = (from_cell, to_cell) {
                if from != to { // Avoid self-loops
                    *edge_counts.entry((from, to)).or_insert(0) += 1;
                }
            }
        }
    }
    
    // Add edges with weights proportional to frequency
    let min_count = 3; // Minimum observations to add edge
    let max_weight = 2.0;
    
    for ((from, to), count) in edge_counts {
        if count >= min_count {
            let weight = (count as F / 10.0).min(max_weight);
            graph.edges.push(Edge::new(from, to, weight));
        }
    }
}

/// Convert world coordinates to grid cell
fn world_to_cell(x: F, y: F, maze: &MazeConfig) -> Option<usize> {
    let cell_x = (x / maze.cell_size) as usize;
    let cell_y = (y / maze.cell_size) as usize;
    
    if cell_x < maze.width && cell_y < maze.height {
        let cell_id = cell_y * maze.width + cell_x;
        if !maze.walls[cell_id] {
            Some(cell_id)
        } else {
            None
        }
    } else {
        None
    }
}

/// Build priors for humanoid maze
pub fn build_humanoid_priors(
    graph: &Graph,
    current_node: usize,
    goal_node: usize,
    enn_state: Option<&fusion_core::FusionState>,
    bicep_success_rate: Option<F>,
) -> Priors {
    let mut builder = PriorBuilder::new(graph.num_nodes())
        .with_goals(&[goal_node]);
    
    // Add ENN prior for current state
    if let Some(state) = enn_state {
        let enn_source = PriorSource::from_enn_reliability(
            state.q_prior_enn,
            state.obs_reliability,
            ETA_MIN,
            ETA_MAX,
        );
        builder = builder.add_prior(current_node, enn_source);
    }
    
    // Add BICEP success rate if available
    if let Some(success_rate) = bicep_success_rate {
        let bicep_source = PriorSource::Manual {
            value: success_rate,
            confidence: 0.8_f32.clamp(0.05, 0.95),
        };
        builder = builder.add_prior(current_node, bicep_source);
    }
    
    // Add white hole penalties
    // (In practice, would parse from maze config and add fail nodes)
    
    builder.build()
}

/// BICEP path integration (mock structure)
#[derive(Clone, Debug)]
pub struct BICEPPaths {
    pub paths: Vec<BICEPPath>,
}

#[derive(Clone, Debug)]  
pub struct BICEPPath {
    pub states: Vec<BICEPState>,
    pub success: bool,
}

#[derive(Clone, Debug)]
pub struct BICEPState {
    pub x: F,
    pub y: F,
    pub t: F,
}

impl BICEPPaths {
    pub fn success_rate(&self) -> F {
        if self.paths.is_empty() {
            return 0.5;
        }
        
        let successes = self.paths.iter().filter(|p| p.success).count();
        successes as F / self.paths.len() as F
    }
    
    pub fn confidence(&self) -> F {
        let n = self.paths.len();
        if n == 0 {
            return 0.1;
        }
        
        // Confidence increases with sample size, decreases with variance
        let success_rate = self.success_rate();
        let variance = success_rate * (1.0 - success_rate);
        
        let sample_factor = (n as F) / ((n as F) + 16.0);
        let variance_factor = 1.0 - variance * 0.5;
        
        // Cap eta to [0.05, 0.95] to prevent bad priors from overriding graph
        let raw_confidence = sample_factor * variance_factor;
        raw_confidence.clamp(0.05, 0.95)
    }
}

/// Default maze configurations for testing
impl MazeConfig {
    pub fn empty_room(width: usize, height: usize) -> Self {
        Self {
            width,
            height, 
            cell_size: 0.5,
            walls: vec![false; width * height],
            teleporters: Vec::new(),
            white_holes: Vec::new(),
        }
    }
    
    pub fn simple_maze() -> Self {
        let width = 10;
        let height = 10;
        let mut walls = vec![false; width * height];
        
        // Add walls around perimeter
        for i in 0..height {
            for j in 0..width {
                if i == 0 || i == height - 1 || j == 0 || j == width - 1 {
                    walls[i * width + j] = true;
                }
            }
        }
        
        // Add some internal walls (create maze structure)
        for i in 2..height-2 {
            for j in 2..width-2 {
                if (i + j) % 4 == 0 {
                    walls[i * width + j] = true;
                }
            }
        }
        
        Self {
            width,
            height,
            cell_size: 0.5,
            walls,
            teleporters: Vec::new(),
            white_holes: Vec::new(),
        }
    }
    
    pub fn teleport_maze() -> Self {
        let mut maze = Self::simple_maze();
        
        // Add teleporter from (2,2) to (7,7) with 80% success
        maze.teleporters.push(Teleporter {
            from_x: 2,
            from_y: 2,
            to_x: 7,
            to_y: 7,
            success_prob: 0.8,
        });
        
        // Add white hole at (8,8)
        maze.white_holes.push(WhiteHole {
            x: 8,
            y: 8, 
            penalty: -10.0,
        });
        
        maze
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    
    #[test]
    fn test_maze_config() {
        let maze = MazeConfig::simple_maze();
        assert_eq!(maze.width, 10);
        assert_eq!(maze.height, 10);
        assert_eq!(maze.walls.len(), 100);
        
        // Check that perimeter is walls
        assert!(maze.walls[0]); // Top-left corner
        assert!(maze.walls[9]); // Top-right corner
        assert!(maze.walls[90]); // Bottom-left corner
        assert!(maze.walls[99]); // Bottom-right corner
        
        // Check that some interior cells are free
        assert!(!maze.walls[11]); // Should be free
    }
    
    #[test]
    fn test_goal_contains() {
        let goal = GoalSpec::new(5.0, 5.0, 2.0);
        
        assert!(goal.contains(5.0, 5.0)); // Center
        assert!(goal.contains(6.0, 5.0)); // Within radius
        assert!(!goal.contains(8.0, 5.0)); // Outside radius
    }
    
    #[test]
    fn test_world_to_cell() {
        let maze = MazeConfig::empty_room(10, 10);
        
        assert_eq!(world_to_cell(0.25, 0.25, &maze), Some(0)); // Top-left
        assert_eq!(world_to_cell(1.25, 0.25, &maze), Some(2)); // Cell (2, 0)
        assert_eq!(world_to_cell(0.25, 1.25, &maze), Some(20)); // Cell (0, 2)
        
        // Out of bounds
        assert_eq!(world_to_cell(-1.0, 0.0, &maze), None);
        assert_eq!(world_to_cell(10.0, 0.0, &maze), None);
    }
    
    #[test]
    fn test_build_graph_simple() {
        let maze = MazeConfig::empty_room(3, 3);
        let obs = HumanoidObs {
            x: 0.25,
            y: 0.25,
            angle: 0.0,
            velocity: (0.0, 0.0),
        };
        let goal = GoalSpec::new(2.25, 2.25, 0.5);
        
        let (graph, current, goal_node) = build_graph_humanoid(&obs, &goal, &maze, None);
        
        assert_eq!(graph.num_nodes(), 10); // 9 maze cells + 1 goal node
        assert_eq!(current, 0); // Should snap to cell (0,0)
        assert_eq!(goal_node, 9); // Goal should be last node added
        
        // Check that goal has connections
        assert!(!graph.neighbors(goal_node).is_empty());
    }
    
    #[test]
    fn test_bicep_paths() {
        let paths = BICEPPaths {
            paths: vec![
                BICEPPath { states: vec![], success: true },
                BICEPPath { states: vec![], success: false },
                BICEPPath { states: vec![], success: true },
                BICEPPath { states: vec![], success: true },
            ],
        };
        
        assert!((paths.success_rate() - 0.75).abs() < 1e-6);
        assert!(paths.confidence() > 0.1);
        assert!(paths.confidence() < 1.0);
    }
}

//==============================================================================
// FILE: ./crates/fusion-envs/src/lib.rs
//==============================================================================
pub mod humanoid_maze;
pub mod ant_soccer;
pub mod puzzle;

pub use humanoid_maze::*;
pub use ant_soccer::*;
pub use puzzle::*;
//==============================================================================
// FILE: ./crates/fusion-envs/src/puzzle.rs
//==============================================================================
use fusion_core::{Graph, NodeFeat, Edge, Priors, PriorSource, F};

const ETA_MIN: F = 0.1;
const ETA_MAX: F = 10.0;
use fusion_core::priors::PriorBuilder;
use serde::{Deserialize, Serialize};
use std::collections::{HashMap, HashSet, VecDeque};

/// Puzzle 4x5 configuration (20 lights, 20 buttons)
#[derive(Clone, Debug, Serialize, Deserialize)]
pub struct PuzzleConfig {
    pub width: usize,   // 5 
    pub height: usize,  // 4
    pub initial_state: u32, // Initial light configuration (20-bit)
    pub goal_state: u32,    // Target light configuration
}

/// Puzzle observation
#[derive(Clone, Debug)]
pub struct PuzzleObs {
    pub config: u32,    // Current 20-bit light configuration
    pub moves_left: usize, // Remaining moves (for time pressure)
}

/// Build graph for puzzle (local subgraph around current state)
pub fn build_graph_puzzle(
    current_config: u32,
    goal_config: u32,
    depth: usize,
    bicep_paths: Option<&PuzzleBICEPPaths>,
) -> (Graph, usize, usize) {
    let mut nodes = Vec::new();
    let mut edges = Vec::new();
    let mut config_to_node: HashMap<u32, usize> = HashMap::new();
    let mut visited: HashSet<u32> = HashSet::new();
    
    // BFS to build local subgraph with capacity limits
    let mut queue = VecDeque::new();
    queue.push_back((current_config, 0)); // (config, depth)
    visited.insert(current_config);
    
    // Add current node
    let current_node_id = 0;
    nodes.push(config_to_node_feat(current_config));
    config_to_node.insert(current_config, current_node_id);
    
    const MAX_NODES: usize = 2000; // Cap graph size for performance
    
    while let Some((config, current_depth)) = queue.pop_front() {
        if current_depth >= depth || nodes.len() >= MAX_NODES {
            continue;
        }
        
        let from_id = config_to_node[&config];
        
        // Try all 20 button presses
        for button in 0..20 {
            let mask = puzzle_button_mask(button);
            let next_config = config ^ mask;
            
            // Skip if already processed - deduplication by bitboard config
            if visited.contains(&next_config) {
                // Still add edge to existing node
                if let Some(&existing_id) = config_to_node.get(&next_config) {
                    edges.push(Edge::new(from_id, existing_id, button_to_weight(button)));
                }
                continue;
            }
            
            // Create new node if under capacity
            if nodes.len() < MAX_NODES {
                let new_id = nodes.len();
                nodes.push(config_to_node_feat(next_config));
                config_to_node.insert(next_config, new_id);
                
                // Add edge
                edges.push(Edge::new(from_id, new_id, button_to_weight(button)));
                
                // Add to frontier if within depth
                if current_depth + 1 < depth {
                    visited.insert(next_config);
                    queue.push_back((next_config, current_depth + 1));
                }
            }
        }
    }
    
    // Add goal node if not already present
    let goal_node_id = if let Some(&existing_id) = config_to_node.get(&goal_config) {
        existing_id
    } else {
        let goal_id = nodes.len();
        nodes.push(config_to_node_feat(goal_config));
        config_to_node.insert(goal_config, goal_id);
        
        // Connect goal to its predecessors (configs that can reach goal in 1 move)
        for button in 0..20 {
            let mask = puzzle_button_mask(button);
            let prev_config = goal_config ^ mask; // Reverse the button press
            
            if let Some(&prev_id) = config_to_node.get(&prev_config) {
                edges.push(Edge::new(prev_id, goal_id, button_to_weight(button)));
            }
        }
        
        goal_id
    };
    
    let mut graph = Graph::new(nodes, edges);
    
    // Add BICEP-discovered move patterns
    if let Some(paths) = bicep_paths {
        add_puzzle_bicep_edges(&mut graph, paths, &config_to_node);
    }
    
    (graph, current_node_id, goal_node_id)
}

/// Convert configuration to node features
fn config_to_node_feat(config: u32) -> NodeFeat {
    // Use Hamming distance to goal as spatial coordinates
    let x = (config.count_ones() as f32) / 20.0; // Density of lights
    let y = hamming_distance_normalized(config, 0); // Distance from all-off
    
    // Pack full configuration into extra features
    let mut extra = Vec::new();
    for i in 0..20 {
        extra.push(if (config >> i) & 1 == 1 { 1.0 } else { 0.0 });
    }
    
    NodeFeat::with_extra(x, y, extra)
}

/// Normalized Hamming distance between two configurations
fn hamming_distance_normalized(a: u32, b: u32) -> f32 {
    (a ^ b).count_ones() as f32 / 20.0
}

/// Convert button ID to edge weight (uniform for now)
fn button_to_weight(_button: usize) -> F {
    1.0 // All button presses equally likely
}

/// Get toggle mask for puzzle button (cross pattern)
pub fn puzzle_button_mask(button: usize) -> u32 {
    let row = button / 5;
    let col = button % 5;
    
    let mut mask = 0u32;
    
    // Toggle button itself
    mask |= 1 << button;
    
    // Toggle cross neighbors
    let neighbors = [
        (row.wrapping_sub(1), col), // up
        (row + 1, col),             // down
        (row, col.wrapping_sub(1)), // left  
        (row, col + 1),             // right
    ];
    
    for (r, c) in neighbors {
        if r < 4 && c < 5 {
            let neighbor_id = r * 5 + c;
            mask |= 1 << neighbor_id;
        }
    }
    
    mask
}

/// Find which button press transforms config A to config B
pub fn find_button_press(from_config: u32, to_config: u32) -> Option<usize> {
    let diff = from_config ^ to_config;
    
    for button in 0..20 {
        if puzzle_button_mask(button) == diff {
            return Some(button);
        }
    }
    
    None
}

/// Build priors for puzzle
pub fn build_puzzle_priors(
    graph: &Graph,
    current_node: usize,
    goal_node: usize,
    goal_config: u32,
    enn_state: Option<&fusion_core::FusionState>,
) -> Priors {
    let mut builder = PriorBuilder::new(graph.num_nodes())
        .with_goals(&[goal_node]);
    
    // ENN prior for current state
    if let Some(state) = enn_state {
        let enn_source = PriorSource::from_enn_reliability(
            state.q_prior_enn,
            state.obs_reliability,
            ETA_MIN,
            ETA_MAX,
        );
        builder = builder.add_prior(current_node, enn_source);
    }
    
    // Heuristic priors based on Hamming distance to goal
    for (node_id, node) in graph.nodes.iter().enumerate() {
        if node_id != current_node && node_id != goal_node {
            let config = node_feat_to_config(node);
            let hamming_dist = hamming_distance_normalized(config, goal_config);
            
            // Closer to goal = higher prior (but low confidence)
            let heuristic_prior = 1.0 - hamming_dist;
            if heuristic_prior > 0.5 {
                let heuristic_source = PriorSource::Manual {
                    value: heuristic_prior,
                    confidence: 0.1_f32.clamp(0.05, 0.95), // Low confidence heuristic
                };
                builder = builder.add_prior(node_id, heuristic_source);
            }
        }
    }
    
    builder.build()
}

/// Extract configuration from node features
fn node_feat_to_config(node: &NodeFeat) -> u32 {
    let mut config = 0u32;
    
    // Reconstruct from extra features
    for (i, &bit) in node.extra.iter().enumerate() {
        if i < 20 && bit > 0.5 {
            config |= 1 << i;
        }
    }
    
    config
}

/// Add edges from BICEP puzzle-solving paths
fn add_puzzle_bicep_edges(
    graph: &mut Graph,
    paths: &PuzzleBICEPPaths,
    config_to_node: &HashMap<u32, usize>,
) {
    let mut move_counts: HashMap<(usize, usize), usize> = HashMap::new();
    
    // Count move transitions
    for path in &paths.paths {
        for window in path.moves.windows(2) {
            let from_config = window[0].config;
            let to_config = window[1].config;
            
            if let (Some(&from_id), Some(&to_id)) = (
                config_to_node.get(&from_config),
                config_to_node.get(&to_config),
            ) {
                *move_counts.entry((from_id, to_id)).or_insert(0) += 1;
            }
        }
    }
    
    // Add frequently used moves with higher weight
    for ((from, to), count) in move_counts {
        if count >= 2 {
            let boosted_weight = 1.0 + (count as F * 0.2).min(1.0);
            
            // Find existing edge and boost its weight
            let existing_edge = graph.edges.iter_mut()
                .find(|e| e.u == from && e.v == to);
                
            if let Some(edge) = existing_edge {
                edge.w = edge.w.max(boosted_weight);
            }
        }
    }
}

/// Solve puzzle with A* for comparison/validation
pub fn solve_puzzle_astar(
    initial: u32,
    goal: u32,
    max_moves: usize,
) -> Option<Vec<usize>> {
    let mut open_set = std::collections::BinaryHeap::new();
    let mut came_from: HashMap<u32, (u32, usize)> = HashMap::new();
    let mut g_score: HashMap<u32, usize> = HashMap::new();
    
    g_score.insert(initial, 0);
    open_set.push(AStarNode {
        config: initial,
        f_score: hamming_distance(initial, goal),
        g_score: 0,
    });
    
    while let Some(current) = open_set.pop() {
        if current.config == goal {
            return Some(reconstruct_path(&came_from, goal));
        }
        
        if current.g_score >= max_moves {
            continue;
        }
        
        for button in 0..20 {
            let mask = puzzle_button_mask(button);
            let neighbor = current.config ^ mask;
            let tentative_g = current.g_score + 1;
            
            if tentative_g < *g_score.get(&neighbor).unwrap_or(&usize::MAX) {
                came_from.insert(neighbor, (current.config, button));
                g_score.insert(neighbor, tentative_g);
                
                let f_score = tentative_g + hamming_distance(neighbor, goal);
                open_set.push(AStarNode {
                    config: neighbor,
                    f_score,
                    g_score: tentative_g,
                });
            }
        }
    }
    
    None
}

/// Hamming distance between configurations
fn hamming_distance(a: u32, b: u32) -> usize {
    (a ^ b).count_ones() as usize
}

/// Reconstruct A* path
fn reconstruct_path(came_from: &HashMap<u32, (u32, usize)>, mut current: u32) -> Vec<usize> {
    let mut path = Vec::new();
    
    while let Some(&(prev_config, button)) = came_from.get(&current) {
        path.push(button);
        current = prev_config;
    }
    
    path.reverse();
    path
}

/// A* node for priority queue
#[derive(Eq, PartialEq)]
struct AStarNode {
    config: u32,
    f_score: usize,
    g_score: usize,
}

impl Ord for AStarNode {
    fn cmp(&self, other: &Self) -> std::cmp::Ordering {
        // Reverse for min-heap
        other.f_score.cmp(&self.f_score)
    }
}

impl PartialOrd for AStarNode {
    fn partial_cmp(&self, other: &Self) -> Option<std::cmp::Ordering> {
        Some(self.cmp(other))
    }
}

/// BICEP paths for puzzle solving
#[derive(Clone, Debug)]
pub struct PuzzleBICEPPaths {
    pub paths: Vec<PuzzleBICEPPath>,
}

#[derive(Clone, Debug)]
pub struct PuzzleBICEPPath {
    pub moves: Vec<PuzzleMove>,
    pub solved: bool,
    pub final_distance: usize, // Hamming distance to goal at end
}

#[derive(Clone, Debug)]
pub struct PuzzleMove {
    pub config: u32,
    pub button: Option<usize>,
    pub t: F,
}

impl PuzzleBICEPPaths {
    pub fn success_rate(&self) -> F {
        if self.paths.is_empty() {
            return 0.1;
        }
        
        let solved = self.paths.iter().filter(|p| p.solved).count();
        solved as F / self.paths.len() as F
    }
    
    pub fn average_final_distance(&self) -> F {
        if self.paths.is_empty() {
            return 10.0;
        }
        
        let total_dist: usize = self.paths.iter()
            .map(|p| p.final_distance)
            .sum();
        
        total_dist as F / self.paths.len() as F
    }
}

/// Default puzzle configurations
impl PuzzleConfig {
    /// Simple puzzle (few lights on)
    pub fn simple() -> Self {
        Self {
            width: 5,
            height: 4,
            initial_state: 0b00000_00000_00000_00000, // All off
            goal_state:    0b11111_11111_11111_11111, // All on
        }
    }
    
    /// Cross pattern puzzle
    pub fn cross_pattern() -> Self {
        Self {
            width: 5,
            height: 4,
            initial_state: 0b00000_00000_00000_00000, // All off
            goal_state:    0b00100_01110_01110_00100, // Cross shape
        }
    }
    
    /// Random intermediate puzzle
    pub fn intermediate() -> Self {
        Self {
            width: 5,
            height: 4,
            initial_state: 0b10101_01010_10101_01010, // Checkerboard
            goal_state:    0b01010_10101_01010_10101, // Inverted checkerboard
        }
    }
    
    /// Hard random configuration
    pub fn hard_random(seed: u64) -> Self {
        use rand::{Rng, SeedableRng};
        use rand_chacha::ChaCha20Rng;
        
        let mut rng = ChaCha20Rng::seed_from_u64(seed);
        
        Self {
            width: 5,
            height: 4,
            initial_state: rng.gen_range(0..=0xFFFFF), // Random 20-bit
            goal_state: rng.gen_range(0..=0xFFFFF),
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    
    #[test]
    fn test_button_mask() {
        // Button 0 (top-left): toggles self + right + down
        let mask = puzzle_button_mask(0);
        let expected = (1 << 0) | (1 << 1) | (1 << 5);
        assert_eq!(mask, expected);
        
        // Button 12 (center): toggles self + all 4 neighbors
        let mask = puzzle_button_mask(12);
        let expected = (1 << 12) | (1 << 7) | (1 << 17) | (1 << 11) | (1 << 13);
        assert_eq!(mask, expected);
        
        // Button 4 (top-right): toggles self + left + down (no right/up neighbors)
        let mask = puzzle_button_mask(4);
        let expected = (1 << 4) | (1 << 3) | (1 << 9);
        assert_eq!(mask, expected);
    }
    
    #[test]
    fn test_find_button_press() {
        let from = 0b00000_00000_00000_00000;
        let to = 0b00000_00000_00100_00110; // Button 12 pattern
        
        let button = find_button_press(from, to);
        assert_eq!(button, Some(12));
        
        // Invalid transition
        let invalid_to = 0b10000_00000_00000_00001;
        assert_eq!(find_button_press(from, invalid_to), None);
    }
    
    #[test]
    fn test_hamming_distance() {
        let a = 0b11110000_11110000_11110000;
        let b = 0b11111111_11111111_11111111;
        
        assert_eq!(hamming_distance(a, b), 12);
        assert!((hamming_distance_normalized(a, b) - 0.6).abs() < 1e-6);
    }
    
    #[test]
    fn test_build_puzzle_graph() {
        let config = PuzzleConfig::simple();
        let (graph, current, goal) = build_graph_puzzle(
            config.initial_state,
            config.goal_state,
            3,
            None,
        );
        
        assert!(graph.num_nodes() > 1);
        assert!(graph.num_edges() > 0);
        
        // Current should be different from goal (unless trivial case)
        if config.initial_state != config.goal_state {
            assert_ne!(current, goal);
        }
        
        // All nodes should have button press edges (degree >= 1 unless isolated)
        let has_neighbors = graph.neighbors(current).len() > 0;
        assert!(has_neighbors);
    }
    
    #[test]
    fn test_astar_solver() {
        // Simple case: all off -> all on
        let solution = solve_puzzle_astar(0, 0xFFFFF, 30);
        
        // There should be a solution (may not be optimal)
        assert!(solution.is_some());
        
        if let Some(moves) = solution {
            // Verify solution by applying moves
            let mut config = 0u32;
            for button in moves {
                let mask = puzzle_button_mask(button);
                config ^= mask;
            }
            assert_eq!(config, 0xFFFFF);
        }
    }
    
    #[test]
    fn test_config_conversion() {
        let original_config = 0b10101_01010_11001_00110;
        let node = config_to_node_feat(original_config);
        let recovered_config = node_feat_to_config(&node);
        
        assert_eq!(original_config, recovered_config);
    }
}

//==============================================================================
// FILE: ./examples/simple_demo.rs
//==============================================================================
use fusion_core::*;
use fusion_core::actions::pick_next_node_weighted;
use fusion_core::propagation::propagate_risk_sensitive;
use fusion_envs::*;
use rand::SeedableRng;
use rand_chacha::ChaCha20Rng;

fn main() -> anyhow::Result<()> {
    println!("Fusion Alpha Demo: Committor Planning");
    
    // Create simple maze
    let maze = MazeConfig::simple_maze();
    println!("Created {}x{} maze", maze.width, maze.height);
    
    // Mock humanoid observation
    let obs = HumanoidObs {
        x: 1.0,
        y: 1.0,
        angle: 0.0,
        velocity: (0.0, 0.0),
    };
    
    // Goal in opposite corner
    let goal = GoalSpec::new(8.0, 8.0, 1.0);
    println!("Goal at ({:.1}, {:.1}) with radius {:.1}", goal.x, goal.y, goal.radius);
    
    // Build graph
    let (graph, current_node, goal_node) = build_graph_humanoid(&obs, &goal, &maze, None);
    println!("Built graph: {} nodes, {} edges", graph.num_nodes(), graph.num_edges());
    println!("Current node: {}, Goal node: {}", current_node, goal_node);
    
    // Mock ENN state (high uncertainty)
    let enn_state = FusionState::from_severity(0.6, 0.8, 0.7);
    println!(
        "ENN state: q_prior={:.2}, obs_reliability={:.2}, risk_aversion={:.2}",
        enn_state.q_prior_enn,
        enn_state.obs_reliability,
        enn_state.risk_aversion
    );
    
    // Build priors
    let priors = build_humanoid_priors(&graph, current_node, goal_node, Some(&enn_state), None);
    println!("Set priors for {} nodes", priors.len());
    
    // Propagation config
    let prop_config = PropConfig {
        t_max: 50,
        eps: 1e-4,
        use_parallel: true,
        alpha_max: 6.0,
        step_policy: StepPolicy::RiskScaled,
    };
    
    // Severity-scaled propagation steps
    let t_steps = enn_state.propagation_steps(&prop_config);
    println!(
        "Propagation steps: {} (risk-scaled from max {})",
        t_steps, prop_config.t_max
    );
    
    // Propagate committor values
    let q_values = propagate_committor(
        &graph,
        &priors.q0,
        &priors.eta,
        &prop_config,
        t_steps,
        enn_state.effective_risk(),
    );
    println!("Computed committor values");
    
    // Display results
    println!("\nCommittor values:");
    println!("Current node {}: q = {:.3}", current_node, q_values[current_node]);
    println!("Goal node {}: q = {:.3}", goal_node, q_values[goal_node]);
    
    // Show neighbors of current node
    let neighbors = graph.neighbors(current_node);
    println!("\nNeighbors of current node:");
    for &(neighbor_id, weight) in neighbors {
        println!("  Node {} (weight {:.2}): q = {:.3}", 
                 neighbor_id, weight, q_values[neighbor_id]);
    }
    
    // Pick next action
    if let Some(next_node) = pick_next_node(&graph, &q_values, current_node) {
        println!("\nSelected next node: {} (q = {:.3})", next_node, q_values[next_node]);
        
        let current_pos = &graph.nodes[current_node];
        let target_pos = &graph.nodes[next_node];
        println!("Move from ({:.1}, {:.1}) to ({:.1}, {:.1})", 
                 current_pos.x, current_pos.y, target_pos.x, target_pos.y);
    } else {
        println!("No valid next node found!");
    }
    
    // Test with exploration
    let mut rng = ChaCha20Rng::seed_from_u64(42);
    println!("\nExploration test (10 samples with temperature 0.5):");
    for i in 0..10 {
        if let Some(next) = pick_next_node_weighted(&graph, &q_values, current_node, 0.5, &mut rng) {
            println!("  Sample {}: node {} (q = {:.3})", i+1, next, q_values[next]);
        }
    }
    
    // Test risk-sensitive propagation
    println!("\nRisk-sensitive comparison:");
    let alpha_pessimistic = 2.0;
    let alpha_optimistic = -2.0;
    
    let q_pess = propagate_risk_sensitive(&graph, &priors.q0, &priors.eta, alpha_pessimistic, &prop_config, t_steps);
    let q_opt = propagate_risk_sensitive(&graph, &priors.q0, &priors.eta, alpha_optimistic, &prop_config, t_steps);
    
    println!("Current node committor values:");
    println!("  Regular: {:.3}", q_values[current_node]);
    println!("  Pessimistic (α={}): {:.3}", alpha_pessimistic, q_pess[current_node]);
    println!("  Optimistic (α={}): {:.3}", alpha_optimistic, q_opt[current_node]);
    
    Ok(())
}

//==============================================================================
// FILE: ./integration_test.py
//==============================================================================
#!/usr/bin/env python3
"""
Integration Test: BICEP → ENN → Fusion Alpha Pipeline

Tests the complete pipeline:
1. Load BICEP trajectory data (parquet) 
2. Convert to graph edges
3. Load ENN weights (JSON)
4. Run ENN forward pass for q0 priors
5. Run Fusion Alpha propagation
6. Verify end-to-end functionality

Usage:
  python integration_test.py \
    --bicep-data ../BICEPsrc/BICEPrust/bicep/runs/dw.parquet \
    --enn-weights ../ENNsrc/ENNrust/enn/runs/enn_weights.json
"""

import argparse
import os
import sys
import numpy as np
from typing import Tuple, Optional

# Add paths
sys.path.append(os.path.join(os.path.dirname(__file__), 'target', 'release'))
sys.path.append(os.path.join(os.path.dirname(__file__), 'python'))

try:
    import fusion_alpha as fa
except ImportError:
    print("⚠️  fusion_alpha module not found. Run: cargo build --release -p fusion-bindings")
    fa = None

try:
    from enn_forward import ENNForward
    from bicep_to_edges import compute_transition_stats, transitions_to_edge_weights, create_grid_nodes
    import pandas as pd
except ImportError as e:
    print(f"⚠️  Missing dependencies: {e}")
    sys.exit(1)


def load_bicep_data(parquet_path: str) -> Tuple[np.ndarray, np.ndarray]:
    """Load BICEP data and convert to graph"""
    print(f"Loading BICEP data from {parquet_path}")
    
    if not os.path.exists(parquet_path):
        print(f"⚠️  BICEP data not found: {parquet_path}")
        # Create synthetic data for testing
        print("Creating synthetic trajectory data...")
        return create_synthetic_bicep_graph()
    
    # Load real data
    df = pd.read_parquet(parquet_path)
    print(f"Loaded {len(df)} trajectories")
    
    # Compute transition statistics
    stats = compute_transition_stats(df, n_bins=10)  # Smaller for test
    print(f"Computed {len(stats['transitions'])} transitions")
    
    # Convert to edges
    edges = transitions_to_edge_weights(stats, temperature=1.0)
    print(f"Created {len(edges)} edges")
    
    # Create nodes
    bounds = np.array(stats['state_bounds'])
    nodes = create_grid_nodes(stats['n_bins'], bounds)
    
    # Convert edges to numpy format
    edge_array = np.array(edges, dtype=np.float32) if edges else np.zeros((0, 3), dtype=np.float32)
    
    print(f"Graph: {len(nodes)} nodes, {len(edge_array)} edges")
    return nodes, edge_array


def create_synthetic_bicep_graph() -> Tuple[np.ndarray, np.ndarray]:
    """Create synthetic graph for testing when BICEP data unavailable"""
    print("Creating synthetic 2D grid graph...")
    
    # Create 5x5 grid
    nodes = []
    for i in range(5):
        for j in range(5):
            nodes.append([float(i), float(j)])
    
    nodes = np.array(nodes, dtype=np.float32)
    
    # Create edges (4-connected grid)
    edges = []
    for i in range(5):
        for j in range(5):
            idx = i * 5 + j
            
            # Right neighbor
            if j < 4:
                neighbor = i * 5 + (j + 1)
                edges.append([idx, neighbor, 0.8])
                
            # Down neighbor  
            if i < 4:
                neighbor = (i + 1) * 5 + j
                edges.append([idx, neighbor, 0.8])
    
    # Add some long-range connections with lower weights
    edges.extend([
        [0, 24, 0.1],   # Corner to corner
        [12, 6, 0.3],   # Center connections
        [12, 18, 0.3],
    ])
    
    edges = np.array(edges, dtype=np.float32)
    return nodes, edges


def create_enn_features(nodes: np.ndarray, current_idx: int, goal_idx: int) -> np.ndarray:
    """Create ENN features from graph nodes"""
    current_pos = nodes[current_idx]
    goal_pos = nodes[goal_idx]
    
    features = []
    for pos in nodes:
        # Distance-based features (matching double-well training)
        dist_to_current = np.linalg.norm(pos - current_pos)
        dist_to_goal = np.linalg.norm(pos - goal_pos)
        
        x = dist_to_goal - dist_to_current  # Relative position
        
        feat = np.array([
            x,                      # position
            x**2,                   # quadratic
            x**3,                   # cubic
            (x**2 - 1)**2 / 4,     # potential-like
            x**3 - x,              # force-like
        ], dtype=np.float32)
        
        features.append(feat)
    
    return np.array(features, dtype=np.float32)


def run_integration_test(bicep_data_path: str, enn_weights_path: str):
    """Run the complete integration test"""
    
    print("=== BICEP → ENN → Fusion Alpha Integration Test ===\n")
    
    # Check dependencies
    if fa is None:
        print("❌ fusion_alpha module missing")
        return False
    
    # 1. Load BICEP data and create graph
    print("Step 1: Load BICEP data")
    try:
        nodes, edges = load_bicep_data(bicep_data_path)
        if len(nodes) == 0:
            raise ValueError("No nodes created")
        if len(edges) == 0:
            print("⚠️  No edges created, adding minimal connectivity")
            # Add minimal edges for test
            for i in range(min(len(nodes)-1, 10)):
                edges = np.append(edges, [[i, i+1, 1.0]], axis=0)
        
        print(f"✅ BICEP graph: {len(nodes)} nodes, {len(edges)} edges")
    except Exception as e:
        print(f"❌ BICEP loading failed: {e}")
        return False
    
    # 2. Load ENN weights
    print(f"\nStep 2: Load ENN from {enn_weights_path}")
    if not os.path.exists(enn_weights_path):
        print(f"❌ ENN weights not found: {enn_weights_path}")
        print("Run: cargo run -r -p enn-examples --bin collapse_committor_train -- \\")
        print("  --in ../BICEPsrc/BICEPrust/bicep/runs/dw.parquet \\")
        print("  --epochs 10 --export-weights runs/enn_weights.json")
        return False
    
    try:
        enn = ENNForward(enn_weights_path)
        print(f"✅ ENN loaded: d={enn.d}, h={enn.h}, k={enn.k}")
    except Exception as e:
        print(f"❌ ENN loading failed: {e}")
        return False
    
    # 3. Set up test scenario
    print(f"\nStep 3: Set up test scenario")
    current_node = 0
    goal_node = len(nodes) - 1  # Last node as goal
    
    print(f"Current node: {current_node} at {nodes[current_node]}")
    print(f"Goal node: {goal_node} at {nodes[goal_node]}")
    
    # 4. ENN forward pass
    print(f"\nStep 4: ENN forward pass")
    try:
        features = create_enn_features(nodes, current_node, goal_node)
        print(f"Created features: {features.shape}")
        
        q0_enn, alpha = enn.forward(features)
        severity = enn.compute_severity(alpha)
        
        print(f"✅ ENN predictions:")
        print(f"  q0 range: [{q0_enn.min():.3f}, {q0_enn.max():.3f}]")
        print(f"  q0[current]: {q0_enn[current_node]:.3f}")
        print(f"  q0[goal]: {q0_enn[goal_node]:.3f}")
        print(f"  Severity: {severity:.3f}")
        
    except Exception as e:
        print(f"❌ ENN forward pass failed: {e}")
        return False
    
    # 5. Fusion Alpha propagation
    print(f"\nStep 5: Fusion Alpha propagation")
    try:
        # Configure propagation
        t_max = int(20 + 50 * severity)
        q_prior = q0_enn[current_node]
        
        print(f"Propagation config:")
        print(f"  t_max: {t_max}")
        print(f"  q_prior: {q_prior:.3f}")
        print(f"  severity: {severity:.3f}")
        
        # Run propagation
        q_fusion = fa.simple_propagate(
            nodes=nodes,
            edges=edges,
            goal_node=goal_node,
            current_node=current_node,
            enn_q_prior=q_prior,
            severity=severity,
            t_max=t_max
        )
        
        print(f"✅ Fusion Alpha results:")
        print(f"  q range: [{q_fusion.min():.3f}, {q_fusion.max():.3f}]")
        print(f"  q[current]: {q_fusion[current_node]:.3f}")
        print(f"  q[goal]: {q_fusion[goal_node]:.3f}")
        
        # Verify boundary conditions
        if abs(q_fusion[goal_node] - 1.0) > 0.01:
            print(f"⚠️  Goal boundary condition not satisfied: {q_fusion[goal_node]:.3f} ≠ 1.0")
        
    except Exception as e:
        print(f"❌ Fusion Alpha propagation failed: {e}")
        return False
    
    # 6. Action selection test
    print(f"\nStep 6: Action selection")
    try:
        # Find neighbors of current node
        neighbors = []
        for edge in edges:
            if int(edge[0]) == current_node:
                neighbor = int(edge[1])
                neighbors.append((neighbor, q_fusion[neighbor]))
        
        if neighbors:
            best_neighbor = max(neighbors, key=lambda x: x[1])
            print(f"Best neighbor: node {best_neighbor[0]} (q={best_neighbor[1]:.3f})")
            print(f"Direction: {nodes[best_neighbor[0]] - nodes[current_node]}")
        else:
            print("No neighbors found for current node")
            
    except Exception as e:
        print(f"❌ Action selection failed: {e}")
        return False
    
    # 7. Integration verification
    print(f"\nStep 7: Integration verification")
    
    # Check that ENN and Fusion Alpha are consistent
    enn_goal_q = q0_enn[goal_node]
    fusion_goal_q = q_fusion[goal_node]
    
    print(f"ENN goal q0: {enn_goal_q:.3f}")
    print(f"Fusion goal q: {fusion_goal_q:.3f}")
    
    # Check monotonicity (values should generally increase toward goal)
    avg_q_near_current = np.mean([q_fusion[n] for n, _ in neighbors[:3]] if neighbors else [q_fusion[current_node]])
    
    print(f"Average q near current: {avg_q_near_current:.3f}")
    
    if fusion_goal_q > avg_q_near_current:
        print("✅ Committor field has reasonable gradient")
    else:
        print("⚠️  Committor field may be flat")
    
    print(f"\n🎉 Integration test completed successfully!")
    print(f"All components (BICEP → ENN → Fusion Alpha) are working together.")
    
    return True


def main():
    parser = argparse.ArgumentParser(description="BICEP → ENN → Fusion Alpha integration test")
    parser.add_argument("--bicep-data", 
                       default="../BICEPsrc/BICEPrust/bicep/runs/dw.parquet",
                       help="Path to BICEP parquet file")
    parser.add_argument("--enn-weights",
                       default="../ENNsrc/ENNrust/enn/runs/enn_weights.json", 
                       help="Path to ENN weights JSON")
    
    args = parser.parse_args()
    
    success = run_integration_test(args.bicep_data, args.enn_weights)
    
    if success:
        print("\n✅ All tests passed! Pipeline is ready for deployment.")
        sys.exit(0)
    else:
        print("\n❌ Integration test failed. Check the output above.")
        sys.exit(1)


if __name__ == "__main__":
    main()
//==============================================================================
// FILE: ./ogbench_eval/fusion_alpha_agent.py
//==============================================================================
#!/usr/bin/env python3
"""
Fusion Alpha Agent for OGBench
Implements the main agent that uses committor planning for OGBench environments
"""

import numpy as np
import sys
import os
from typing import Dict, Tuple, Any, Optional
from abc import ABC, abstractmethod

# Add paths
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'target', 'release'))
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'python'))

try:
    import fusion_alpha as fa
except ImportError as e:
    print(f"Warning: Could not import fusion_alpha: {e}")
    print("Build with: cargo build --release -p fusion-bindings")
    fa = None

# Import our graph builder and ENN forward
try:
    from graph_builder import create_graph_builder
    from enn_forward import ENNForward
except ImportError as e:
    print(f"Warning: Could not import graph_builder or enn_forward: {e}")
    create_graph_builder = None
    ENNForward = None

class BaseAgent(ABC):
    """Base agent interface for OGBench"""
    
    @abstractmethod
    def reset(self):
        """Reset agent state"""
        pass
    
    @abstractmethod
    def act(self, obs, info: Dict) -> Any:
        """Select action given observation"""
        pass

class RandomAgent(BaseAgent):
    """Random baseline agent"""
    
    def __init__(self, action_space):
        self.action_space = action_space
        
    def reset(self):
        pass
        
    def act(self, obs, info: Dict):
        return self.action_space.sample()

class FusionAlphaAgent(BaseAgent):
    """Fusion Alpha committor planning agent"""
    
    def __init__(self, 
                 env_name: str,
                 action_space,
                 observation_space,
                 # Fusion Alpha parameters
                 k_neighbors: int = 10,
                 max_nodes: int = 100,
                 t_max_base: int = 20,
                 severity_scale: float = 1.0,
                 # ENN parameters
                 enn_weights_path: Optional[str] = None,
                 # BICEP parameters  
                 bicep_graph_path: Optional[str] = None):
        
        self.env_name = env_name
        self.action_space = action_space
        self.observation_space = observation_space
        
        # Fusion Alpha config
        self.k_neighbors = k_neighbors
        self.max_nodes = max_nodes
        self.t_max_base = t_max_base
        self.severity_scale = severity_scale
        
        # Agent state
        self.step_count = 0
        self.episode_count = 0
        self.success_history = []
        self.q_predictions = []  # For tracking ENN predictions
        
        # Initialize graph builder
        if create_graph_builder is not None:
            self.graph_builder = create_graph_builder(
                env_name, 
                k_neighbors=k_neighbors,
                max_nodes=max_nodes
            )
        else:
            self.graph_builder = None
            
        # Load ENN if available
        self.enn = None
        if enn_weights_path and os.path.exists(enn_weights_path) and ENNForward is not None:
            try:
                self.enn = ENNForward(enn_weights_path)
                print(f"Loaded ENN weights from {enn_weights_path}")
            except Exception as e:
                print(f"Failed to load ENN weights: {e}")
        
        # Load BICEP graph if available
        self.bicep_edges = None
        if bicep_graph_path and os.path.exists(bicep_graph_path):
            try:
                import json
                with open(bicep_graph_path, 'r') as f:
                    data = json.load(f)
                    self.bicep_edges = data.get('edges', [])
                print(f"Loaded {len(self.bicep_edges)} BICEP edges")
            except Exception as e:
                print(f"Failed to load BICEP graph: {e}")
        
        # Environment-specific setup
        self._setup_env_specific()
        
    def _setup_env_specific(self):
        """Set up environment-specific parameters"""
        if "humanoid" in self.env_name.lower():
            self.env_type = "humanoid_maze"
            self.cell_size = 1.0  # Default cell size
            
        elif "ant" in self.env_name.lower() and "soccer" in self.env_name.lower():
            self.env_type = "ant_soccer"
            
        elif "puzzle" in self.env_name.lower():
            self.env_type = "puzzle"
            self.puzzle_depth = 6
            
        else:
            raise ValueError(f"Unsupported environment: {self.env_name}")
    
    def reset(self):
        """Reset agent for new episode"""
        self.step_count = 0
        self.episode_count += 1
        
    def act(self, obs, info: Dict) -> Any:
        """Select action using Fusion Alpha planning"""
        self.step_count += 1
        
        if fa is None:
            # Fallback to random if Fusion Alpha not available
            return self.action_space.sample()
            
        try:
            if self.env_type == "humanoid_maze":
                return self._act_humanoid_maze(obs, info)
            elif self.env_type == "ant_soccer":
                return self._act_ant_soccer(obs, info)
            elif self.env_type == "puzzle":
                return self._act_puzzle(obs, info)
            else:
                return self.action_space.sample()
                
        except Exception as e:
            print(f"Fusion Alpha planning failed: {e}")
            return self.action_space.sample()
    
    def _act_humanoid_maze(self, obs, info: Dict) -> np.ndarray:
        """Action selection for HumanoidMaze"""
        # Extract observation
        agent_x, agent_y, agent_angle = obs[0], obs[1], obs[2]
        goal_x, goal_y = obs[3], obs[4]
        
        # Build current state vector
        current_state = obs.copy()
        goal_state = np.array([goal_x, goal_y] + [0.0] * (len(obs) - 2))
        
        # Add state to graph builder buffer
        if self.graph_builder is not None:
            self.graph_builder.add_state(current_state)
        
        # Use real graph builder or fallback
        if self.graph_builder is not None:
            nodes, edges, current_node, goal_node = self.graph_builder.build_graph(
                current_state, goal_state
            )
        else:
            # Fallback to simple graph
            nodes, edges, current_node, goal_node = self._create_humanoid_graph(
                agent_x, agent_y, goal_x, goal_y
            )
        
        # Get ENN predictions if available
        if self.enn is not None:
            # Convert nodes to ENN features
            enn_features = self._nodes_to_enn_features(
                nodes, current_node, goal_node, info
            )
            
            # Get ENN forward pass
            q0_enn, alpha = self.enn.forward(enn_features)
            severity = self.enn.compute_severity(alpha)
            q_prior_enn = q0_enn[current_node]
        else:
            # Fallback to mock predictions
            q_prior_enn = 0.5  # Neutral prior
            severity = 0.5
        
        # Dynamic t_max based on severity
        t_max = int(self.t_max_base + 50 * severity * self.severity_scale)
        
        # Run Fusion Alpha propagation
        q_values = fa.simple_propagate(
            nodes=nodes,
            edges=edges,
            goal_node=goal_node,
            current_node=current_node,
            enn_q_prior=q_prior_enn,
            severity=severity,
            t_max=t_max,
        )
        
        # Convert committor values to action
        action = self._committor_to_humanoid_action(
            q_values, nodes, current_node, agent_angle
        )
        
        # Store for learning
        self.q_predictions.append(q_prior_enn)
        
        return action
    
    def _act_ant_soccer(self, obs, info: Dict) -> np.ndarray:
        """Action selection for AntSoccer"""
        ant_x, ant_y = obs[0], obs[1]
        ball_x, ball_y = obs[2], obs[3]
        goal_x, goal_y = obs[6], obs[7]
        
        # Build state vectors
        current_state = obs.copy()
        # Goal state has ball at goal position
        goal_state = obs.copy()
        goal_state[2] = goal_x
        goal_state[3] = goal_y
        
        # Add state to buffer
        if self.graph_builder is not None:
            self.graph_builder.add_state(current_state)
        
        # Use real graph builder or fallback
        if self.graph_builder is not None:
            nodes, edges, current_node, goal_node = self.graph_builder.build_graph(
                current_state, goal_state
            )
        else:
            nodes, edges, current_node, goal_node = self._create_soccer_graph(
                ball_x, ball_y, goal_x, goal_y
            )
        
        # Get ENN predictions
        if self.enn is not None:
            enn_features = self._nodes_to_enn_features(
                nodes, current_node, goal_node, info
            )
            q0_enn, alpha = self.enn.forward(enn_features)
            severity = self.enn.compute_severity(alpha)
            q_prior_enn = q0_enn[current_node]
        else:
            q_prior_enn = 0.3  # Lower prior for soccer (harder)
            severity = 0.6
        
        # Dynamic t_max
        t_max = int(self.t_max_base + 50 * severity * self.severity_scale)
        
        # Run propagation
        q_values = fa.simple_propagate(
            nodes=nodes,
            edges=edges,
            goal_node=goal_node,
            current_node=current_node,
            enn_q_prior=q_prior_enn,
            severity=severity,
            t_max=t_max,
        )
        
        # Convert to ant joint torques
        action = self._committor_to_soccer_action(
            q_values, nodes, current_node, ant_x, ant_y, ball_x, ball_y
        )
        
        return action
    
    def _act_puzzle(self, obs, info: Dict) -> int:
        """Action selection for Puzzle"""
        # Current state is observation
        current_state = obs.copy()
        
        # Goal state from info
        goal_config = info.get('goal_config', 0)
        goal_state = np.zeros_like(obs)
        for i in range(len(obs)):
            if goal_config & (1 << i):
                goal_state[i] = 1.0
        
        # Use real graph builder
        if self.graph_builder is not None:
            nodes, edges, current_node, goal_node = self.graph_builder.build_graph(
                current_state, goal_state
            )
        else:
            # Fallback
            config = 0
            for i, light in enumerate(obs):
                if light > 0.5:
                    config |= (1 << i)
            nodes, edges, current_node, goal_node = self._create_puzzle_graph(
                config, goal_config
            )
        
        # Get ENN predictions
        if self.enn is not None:
            enn_features = self._nodes_to_enn_features(
                nodes, current_node, goal_node, info
            )
            q0_enn, alpha = self.enn.forward(enn_features)
            severity = self.enn.compute_severity(alpha)
            q_prior_enn = q0_enn[current_node]
        else:
            hamming_dist = info.get('hamming_distance', 10)
            q_prior_enn = max(0.1, 1.0 - hamming_dist / 20.0)
            severity = min(0.9, hamming_dist / 10.0)
        
        # Dynamic t_max
        t_max = int(self.t_max_base + 30 * severity * self.severity_scale)
        
        # Run propagation
        q_values = fa.simple_propagate(
            nodes=nodes,
            edges=edges,
            goal_node=goal_node,
            current_node=current_node,
            enn_q_prior=q_prior_enn,
            severity=severity,
            t_max=t_max,
        )
        
        # Find best button press
        action = self._committor_to_puzzle_action(q_values, current_node, nodes.shape[0])
        
        return action
    
    def _nodes_to_enn_features(self, nodes: np.ndarray, 
                               current_idx: int, goal_idx: int, 
                               info: Dict) -> np.ndarray:
        """Convert graph nodes to ENN features"""
        # This should match the feature engineering used during ENN training
        # For now, using distance-based features similar to enn_fusion_demo.py
        
        current_pos = nodes[current_idx][:2]  # Use first 2 dims as position
        goal_pos = nodes[goal_idx][:2] if goal_idx >= 0 else current_pos
        
        features = []
        for i, node in enumerate(nodes):
            pos = node[:2]
            
            # Distance features
            dist_to_current = np.linalg.norm(pos - current_pos)
            dist_to_goal = np.linalg.norm(pos - goal_pos)
            
            # Relative position feature
            x = dist_to_goal - dist_to_current
            
            # Create feature vector (matching double-well style)
            feat = np.array([
                x,                      # position-like
                x**2,                   # quadratic
                x**3,                   # cubic  
                (x**2 - 1)**2 / 4,     # potential-like
                x**3 - x,              # force-like
            ], dtype=np.float32)
            
            features.append(feat)
        
        return np.array(features, dtype=np.float32)
    
    def _create_humanoid_graph(self, agent_x, agent_y, goal_x, goal_y) -> Tuple:
        """Create simple spatial graph for humanoid"""
        # Simple 3x3 grid around agent
        grid_size = 3
        spacing = 1.5
        
        nodes = []
        # Current position
        nodes.append([agent_x, agent_y])
        
        # Neighboring positions  
        for i in range(-1, 2):
            for j in range(-1, 2):
                if i == 0 and j == 0:
                    continue
                x = agent_x + i * spacing
                y = agent_y + j * spacing
                nodes.append([x, y])
                
        # Goal position
        nodes.append([goal_x, goal_y])
        
        nodes = np.array(nodes, dtype=np.float32)
        
        # Simple connectivity (all-to-all for small graph)
        edges = []
        n_nodes = len(nodes)
        for i in range(n_nodes):
            for j in range(n_nodes):
                if i != j:
                    dist = np.linalg.norm(nodes[i] - nodes[j])
                    weight = 1.0 / (1.0 + dist)  # Distance-based weights
                    edges.append([i, j, weight])
                    
        edges = np.array(edges, dtype=np.float32)
        
        current_node = 0  # Agent position is first node
        goal_node = n_nodes - 1  # Goal is last node
        
        return nodes, edges, current_node, goal_node
    
    def _create_soccer_graph(self, ball_x, ball_y, goal_x, goal_y) -> Tuple:
        """Create ball-centric graph for soccer"""
        # Grid around ball position
        grid_size = 2
        spacing = 1.0
        
        nodes = []
        # Current ball position
        nodes.append([ball_x, ball_y])
        
        # Surrounding positions
        for i in range(-grid_size, grid_size + 1):
            for j in range(-grid_size, grid_size + 1):
                if i == 0 and j == 0:
                    continue
                x = ball_x + i * spacing
                y = ball_y + j * spacing
                # Keep within field bounds roughly
                x = np.clip(x, 0.5, 11.5)
                y = np.clip(y, 0.5, 7.5)
                nodes.append([x, y])
                
        # Goal position
        nodes.append([goal_x, goal_y])
        
        nodes = np.array(nodes, dtype=np.float32)
        
        # Connect nodes with goal bias
        edges = []
        n_nodes = len(nodes)
        goal_node = n_nodes - 1
        
        for i in range(n_nodes):
            for j in range(n_nodes):
                if i != j:
                    dist = np.linalg.norm(nodes[i] - nodes[j])
                    weight = 1.0 / (1.0 + dist)
                    
                    # Boost edges toward goal
                    if j == goal_node:
                        weight *= 2.0
                        
                    edges.append([i, j, weight])
                    
        edges = np.array(edges, dtype=np.float32)
        
        return nodes, edges, 0, goal_node
    
    def _create_puzzle_graph(self, config, goal_config) -> Tuple:
        """Create local puzzle graph"""
        # BFS around current config
        from collections import deque
        
        visited = set()
        queue = deque([config])
        visited.add(config)
        configs = [config]
        
        depth = min(3, self.puzzle_depth)  # Limit for mock version
        
        for level in range(depth):
            level_size = len(queue)
            for _ in range(level_size):
                if not queue:
                    break
                    
                current = queue.popleft()
                
                # Try each button press
                for button in range(20):
                    mask = self._get_puzzle_mask(button)
                    next_config = current ^ mask
                    
                    if next_config not in visited:
                        visited.add(next_config)
                        queue.append(next_config)
                        configs.append(next_config)
                        
                        if len(configs) >= 20:  # Limit graph size
                            break
                            
                if len(configs) >= 20:
                    break
                    
        # Add goal if not present
        if goal_config not in configs:
            configs.append(goal_config)
            
        # Convert configs to spatial nodes (using Hamming distance as coordinates)
        nodes = []
        for cfg in configs:
            x = bin(cfg).count('1') / 20.0  # Light density
            y = bin(cfg ^ goal_config).count('1') / 20.0  # Distance to goal
            nodes.append([x, y])
            
        nodes = np.array(nodes, dtype=np.float32)
        
        # Connect configs that differ by one button press
        edges = []
        for i, cfg1 in enumerate(configs):
            for j, cfg2 in enumerate(configs):
                if i != j:
                    # Check if one button press transforms cfg1 to cfg2
                    diff = cfg1 ^ cfg2
                    if bin(diff).count('1') <= 7:  # Plausible button press
                        weight = 1.0 / (1.0 + bin(diff).count('1'))
                        edges.append([i, j, weight])
                        
        edges = np.array(edges, dtype=np.float32)
        
        current_node = 0  # Current config is first
        try:
            goal_node = configs.index(goal_config)
        except ValueError:
            goal_node = len(configs) - 1  # Use last node as proxy
            
        return nodes, edges, current_node, goal_node
    
    def _get_puzzle_mask(self, button: int) -> int:
        """Get button press mask"""
        row = button // 5
        col = button % 5
        
        mask = 1 << button  # Button itself
        
        # Cross neighbors
        for dr, dc in [(-1, 0), (1, 0), (0, -1), (0, 1)]:
            nr, nc = row + dr, col + dc
            if 0 <= nr < 4 and 0 <= nc < 5:
                neighbor = nr * 5 + nc
                mask |= (1 << neighbor)
                
        return mask
    
    def _committor_to_humanoid_action(self, q_values, nodes, current_node, agent_angle) -> np.ndarray:
        """Convert committor values to humanoid action"""
        # Find neighbor with highest q-value
        current_pos = nodes[current_node]
        
        best_q = -1
        best_target = current_pos
        
        for i, q in enumerate(q_values):
            if i != current_node and q > best_q:
                best_q = q
                best_target = nodes[i]
        
        # Compute desired direction
        dx = best_target[0] - current_pos[0]
        dy = best_target[1] - current_pos[1]
        target_angle = np.arctan2(dy, dx)
        
        # Compute angular difference
        angle_diff = target_angle - agent_angle
        while angle_diff > np.pi:
            angle_diff -= 2 * np.pi
        while angle_diff < -np.pi:
            angle_diff += 2 * np.pi
            
        # Action: [forward_velocity, angular_velocity]
        forward_vel = 0.8 if abs(angle_diff) < 0.5 else 0.3
        angular_vel = np.clip(angle_diff * 2.0, -1.0, 1.0)
        
        return np.array([forward_vel, angular_vel], dtype=np.float32)
    
    def _committor_to_soccer_action(self, q_values, nodes, current_node, ant_x, ant_y, ball_x, ball_y) -> np.ndarray:
        """Convert committor values to ant action"""
        # Find best ball target position
        best_q = -1
        best_target = nodes[current_node]
        
        for i, q in enumerate(q_values):
            if i != current_node and q > best_q:
                best_q = q
                best_target = nodes[i]
                
        # Compute desired ant position to push ball toward target
        push_dir_x = best_target[0] - ball_x
        push_dir_y = best_target[1] - ball_y
        push_length = np.sqrt(push_dir_x**2 + push_dir_y**2) + 1e-6
        
        push_dir_x /= push_length
        push_dir_y /= push_length
        
        # Ant should be behind ball relative to target
        desired_ant_x = ball_x - 0.8 * push_dir_x
        desired_ant_y = ball_y - 0.8 * push_dir_y
        
        # Simple controller: move ant toward desired position
        ant_force_x = np.clip((desired_ant_x - ant_x) * 5.0, -1.0, 1.0)
        ant_force_y = np.clip((desired_ant_y - ant_y) * 5.0, -1.0, 1.0)
        
        # Convert to joint torques (mock)
        action = np.zeros(8, dtype=np.float32)
        action[:4] = ant_force_x * 0.5  # Front legs
        action[4:] = ant_force_y * 0.5  # Back legs
        
        # Add some noise for realism
        action += np.random.normal(0, 0.1, 8)
        action = np.clip(action, -1.0, 1.0)
        
        return action
    
    def _committor_to_puzzle_action(self, q_values, current_node, n_nodes) -> int:
        """Convert committor values to button press"""
        # Find node with highest q-value (excluding current)
        best_q = -1
        best_node = current_node
        
        for i, q in enumerate(q_values):
            if i != current_node and q > best_q:
                best_q = q
                best_node = i
        
        # For puzzle with exact graph builder, edges encode the button press
        # Try to find which button leads to best_node
        if self.graph_builder is not None and hasattr(self.graph_builder, '_get_button_mask'):
            # Get current config from node
            current_config = self.graph_builder.configs[current_node]
            target_config = self.graph_builder.configs[best_node] if best_node < len(self.graph_builder.configs) else current_config
            
            # Find button that transforms current -> target
            for button in range(20):
                mask = self.graph_builder._get_button_mask(button)
                if (current_config ^ mask) == target_config:
                    return button
        
        # Fallback: prefer buttons with higher impact
        if best_q > q_values[current_node]:
            weights = []
            for button in range(20):
                mask = self._get_puzzle_mask(button)
                impact = bin(mask).count('1')
                weights.append(impact)
                
            weights = np.array(weights, dtype=np.float32)
            weights = weights / weights.sum()
            
            return np.random.choice(20, p=weights)
        else:
            return np.random.randint(20)
    
    def update(self, obs, action, reward, next_obs, done, info: Dict):
        """Update agent after step (for learning)"""
        if done:
            success = reward > 50  # Success threshold varies by env
            self.success_history.append(success)
            
            # Keep history bounded
            if len(self.success_history) > 50:
                self.success_history = self.success_history[-50:]
                
            if len(self.q_predictions) > 10:
                self.q_predictions = self.q_predictions[-10:]
            
            # Note: Real ENN training would happen offline with collected trajectories

def create_agent(env_name: str, action_space, observation_space, 
                agent_type: str = "fusion_alpha", **kwargs) -> BaseAgent:
    """Factory function to create agents"""
    if agent_type == "random":
        return RandomAgent(action_space)
    elif agent_type == "fusion_alpha":
        return FusionAlphaAgent(env_name, action_space, observation_space, **kwargs)
    else:
        raise ValueError(f"Unknown agent type: {agent_type}")

if __name__ == "__main__":
    # Quick test
    from mock_ogbench import create_mock_env
    
    print("Testing Fusion Alpha Agent")
    
    env = create_mock_env("HumanoidMaze-v1")
    agent = create_agent("HumanoidMaze-v1", env.action_space, env.observation_space, "fusion_alpha")
    
    obs, info = env.reset(seed=42)
    agent.reset()
    
    for step in range(10):
        action = agent.act(obs, info)
        next_obs, reward, term, trunc, next_info = env.step(action)
        
        agent.update(obs, action, reward, next_obs, term or trunc, next_info)
        
        print(f"Step {step}: reward={reward:.3f}, distance={next_info.get('distance_to_goal', 0):.3f}")
        
        if term or trunc:
            break
            
        obs, info = next_obs, next_info
    
    print("✅ Fusion Alpha agent test complete!")
//==============================================================================
// FILE: ./ogbench_eval/mock_ogbench.py
//==============================================================================
#!/usr/bin/env python3
"""
Mock OGBench Environment for Fusion Alpha Testing
Simulates the OGBench API without requiring the full installation
"""

import numpy as np
import gymnasium as gym
from gymnasium import spaces
import matplotlib.pyplot as plt
from typing import Dict, Tuple, Any, List, Optional
import time
import json
import os

class MockHumanoidMaze(gym.Env):
    """Mock HumanoidMaze environment following OGBench API"""
    
    def __init__(self, maze_type="small", render_mode=None):
        super().__init__()
        
        self.maze_type = maze_type
        self.render_mode = render_mode
        
        # Environment parameters
        if maze_type == "small":
            self.maze_size = (10, 10)
            self.cell_size = 0.5
        elif maze_type == "giant":
            self.maze_size = (20, 20)  
            self.cell_size = 0.5
        else:
            self.maze_size = (15, 15)
            self.cell_size = 0.5
            
        self.width, self.height = self.maze_size
        
        # Action space: [forward_velocity, angular_velocity]
        self.action_space = spaces.Box(
            low=np.array([-1.0, -1.0], dtype=np.float32),
            high=np.array([1.0, 1.0], dtype=np.float32)
        )
        
        # Observation space: [x, y, angle, goal_x, goal_y]
        max_coord = max(self.width, self.height) * self.cell_size
        self.observation_space = spaces.Box(
            low=np.array([-max_coord, -max_coord, -np.pi, -max_coord, -max_coord], dtype=np.float32),
            high=np.array([max_coord, max_coord, np.pi, max_coord, max_coord], dtype=np.float32)
        )
        
        # Create maze walls (simple pattern)
        self.walls = self._create_maze_walls()
        
        self.reset()
        
    def _create_maze_walls(self) -> np.ndarray:
        """Create maze wall pattern"""
        walls = np.zeros((self.height, self.width), dtype=bool)
        
        # Perimeter walls
        walls[0, :] = True
        walls[-1, :] = True  
        walls[:, 0] = True
        walls[:, -1] = True
        
        # Internal maze structure
        for i in range(2, self.height-2, 3):
            for j in range(2, self.width-2, 3):
                if np.random.rand() > 0.3:  # 70% chance of wall
                    walls[i, j] = True
                    
        return walls
        
    def reset(self, seed=None, options=None) -> Tuple[np.ndarray, Dict]:
        super().reset(seed=seed)
        if seed is not None:
            np.random.seed(seed)
            
        # Random start position (avoid walls)
        while True:
            start_i = np.random.randint(1, self.height-1)
            start_j = np.random.randint(1, self.width-1)
            if not self.walls[start_i, start_j]:
                break
                
        self.agent_x = start_j * self.cell_size + self.cell_size/2
        self.agent_y = start_i * self.cell_size + self.cell_size/2
        self.agent_angle = np.random.uniform(-np.pi, np.pi)
        
        # Random goal position (avoid walls, far from start)
        while True:
            goal_i = np.random.randint(1, self.height-1)
            goal_j = np.random.randint(1, self.width-1)
            goal_x = goal_j * self.cell_size + self.cell_size/2
            goal_y = goal_i * self.cell_size + self.cell_size/2
            
            dist = np.sqrt((goal_x - self.agent_x)**2 + (goal_y - self.agent_y)**2)
            if not self.walls[goal_i, goal_j] and dist > 3.0:
                break
                
        self.goal_x = goal_x
        self.goal_y = goal_y
        self.goal_radius = 0.8
        
        self.steps = 0
        self.max_steps = 500 if self.maze_type == "small" else 1000
        
        obs = self._get_obs()
        info = self._get_info()
        
        return obs, info
        
    def step(self, action: np.ndarray) -> Tuple[np.ndarray, float, bool, bool, Dict]:
        """Step the environment"""
        self.steps += 1
        
        # Apply action
        forward_vel, angular_vel = action
        dt = 0.05  # 20 Hz
        
        # Update agent state
        self.agent_angle += angular_vel * dt
        self.agent_angle = ((self.agent_angle + np.pi) % (2 * np.pi)) - np.pi  # Wrap angle
        
        # Move forward
        dx = forward_vel * np.cos(self.agent_angle) * dt
        dy = forward_vel * np.sin(self.agent_angle) * dt
        
        new_x = self.agent_x + dx
        new_y = self.agent_y + dy
        
        # Check wall collision
        if not self._is_in_wall(new_x, new_y):
            self.agent_x = new_x
            self.agent_y = new_y
            
        # Compute reward
        reward = self._compute_reward(action)
        
        # Check termination
        terminated = self._is_goal_reached()
        truncated = self.steps >= self.max_steps
        
        obs = self._get_obs()
        info = self._get_info()
        
        return obs, reward, terminated, truncated, info
        
    def _get_obs(self) -> np.ndarray:
        """Get current observation"""
        return np.array([
            self.agent_x,
            self.agent_y, 
            self.agent_angle,
            self.goal_x,
            self.goal_y,
        ], dtype=np.float32)
        
    def _get_info(self) -> Dict:
        """Get info dict"""
        return {
            'distance_to_goal': np.sqrt((self.agent_x - self.goal_x)**2 + (self.agent_y - self.goal_y)**2),
            'steps': self.steps,
            'success': self._is_goal_reached(),
        }
        
    def _is_in_wall(self, x: float, y: float) -> bool:
        """Check if position is in a wall"""
        i = int(y / self.cell_size)
        j = int(x / self.cell_size)
        
        if i < 0 or i >= self.height or j < 0 or j >= self.width:
            return True
            
        return self.walls[i, j]
        
    def _is_goal_reached(self) -> bool:
        """Check if goal is reached"""
        dist = np.sqrt((self.agent_x - self.goal_x)**2 + (self.agent_y - self.goal_y)**2)
        return dist <= self.goal_radius
        
    def _compute_reward(self, action: np.ndarray) -> float:
        """Compute reward"""
        # Distance reward
        dist_to_goal = np.sqrt((self.agent_x - self.goal_x)**2 + (self.agent_y - self.goal_y)**2)
        dist_reward = -0.01 * dist_to_goal
        
        # Goal reward
        if self._is_goal_reached():
            return 100.0 + dist_reward
            
        # Step penalty
        step_penalty = -0.1
        
        # Control penalty
        control_penalty = -0.001 * (action[0]**2 + action[1]**2)
        
        return dist_reward + step_penalty + control_penalty
        
    def render(self):
        """Render the environment"""
        if self.render_mode is None:
            return
            
        fig, ax = plt.subplots(figsize=(8, 8))
        
        # Draw maze
        for i in range(self.height):
            for j in range(self.width):
                if self.walls[i, j]:
                    rect = plt.Rectangle((j*self.cell_size, i*self.cell_size), 
                                       self.cell_size, self.cell_size, 
                                       facecolor='black')
                    ax.add_patch(rect)
                    
        # Draw goal
        goal_circle = plt.Circle((self.goal_x, self.goal_y), self.goal_radius, 
                               color='green', alpha=0.5)
        ax.add_patch(goal_circle)
        
        # Draw agent
        agent_circle = plt.Circle((self.agent_x, self.agent_y), 0.2, color='red')
        ax.add_patch(agent_circle)
        
        # Draw agent direction
        arrow_length = 0.4
        arrow_dx = arrow_length * np.cos(self.agent_angle)
        arrow_dy = arrow_length * np.sin(self.agent_angle)
        ax.arrow(self.agent_x, self.agent_y, arrow_dx, arrow_dy, 
                head_width=0.1, head_length=0.1, fc='red', ec='red')
        
        ax.set_xlim(0, self.width * self.cell_size)
        ax.set_ylim(0, self.height * self.cell_size)
        ax.set_aspect('equal')
        ax.set_title(f'HumanoidMaze ({self.maze_type})')
        
        plt.tight_layout()
        plt.show()

class MockAntSoccer(gym.Env):
    """Mock AntSoccer environment"""
    
    def __init__(self, render_mode=None):
        super().__init__()
        
        self.render_mode = render_mode
        
        # Field dimensions
        self.field_width = 12.0
        self.field_height = 8.0
        self.goal_width = 2.0
        
        # Action space: ant joint torques (8 joints)
        self.action_space = spaces.Box(
            low=-1.0, high=1.0, shape=(8,), dtype=np.float32
        )
        
        # Observation space: [ant_pos(2), ball_pos(2), ball_vel(2), goal_info(2)]
        self.observation_space = spaces.Box(
            low=-20.0, high=20.0, shape=(8,), dtype=np.float32
        )
        
        self.reset()
        
    def reset(self, seed=None, options=None) -> Tuple[np.ndarray, Dict]:
        super().reset(seed=seed)
        if seed is not None:
            np.random.seed(seed)
            
        # Reset positions
        self.ant_x = np.random.uniform(1.0, 3.0)
        self.ant_y = np.random.uniform(2.0, 6.0)
        self.ball_x = np.random.uniform(4.0, 8.0)
        self.ball_y = np.random.uniform(2.0, 6.0)
        self.ball_vx = 0.0
        self.ball_vy = 0.0
        
        # Goal position (right side)
        self.goal_x = 12.0
        self.goal_y = 4.0
        
        self.steps = 0
        self.max_steps = 1000
        
        obs = self._get_obs()
        info = self._get_info()
        
        return obs, info
        
    def step(self, action: np.ndarray) -> Tuple[np.ndarray, float, bool, bool, Dict]:
        self.steps += 1
        
        # Simplified ant dynamics
        dt = 0.02
        
        # Convert joint torques to ant movement (simplified)
        ant_force_x = np.mean(action[:4]) * 2.0
        ant_force_y = np.mean(action[4:]) * 2.0
        
        self.ant_x += ant_force_x * dt
        self.ant_y += ant_force_y * dt
        
        # Keep ant in bounds
        self.ant_x = np.clip(self.ant_x, 0.5, self.field_width - 0.5)
        self.ant_y = np.clip(self.ant_y, 0.5, self.field_height - 0.5)
        
        # Ball interaction (if ant is close)
        ant_ball_dist = np.sqrt((self.ant_x - self.ball_x)**2 + (self.ant_y - self.ball_y)**2)
        
        if ant_ball_dist < 1.0:  # Ant can push ball
            push_strength = 0.5
            push_dir_x = (self.ball_x - self.ant_x) / (ant_ball_dist + 1e-6)
            push_dir_y = (self.ball_y - self.ant_y) / (ant_ball_dist + 1e-6)
            
            self.ball_vx += push_strength * push_dir_x * dt
            self.ball_vy += push_strength * push_dir_y * dt
            
        # Ball physics
        friction = 0.9
        self.ball_vx *= friction
        self.ball_vy *= friction
        
        self.ball_x += self.ball_vx * dt
        self.ball_y += self.ball_vy * dt
        
        # Ball boundaries
        if self.ball_x <= 0:
            self.ball_x = 0.1
            self.ball_vx = abs(self.ball_vx) * 0.5
        elif self.ball_x >= self.field_width:
            self.ball_x = self.field_width - 0.1
            self.ball_vx = -abs(self.ball_vx) * 0.5
            
        if self.ball_y <= 0:
            self.ball_y = 0.1
            self.ball_vy = abs(self.ball_vy) * 0.5
        elif self.ball_y >= self.field_height:
            self.ball_y = self.field_height - 0.1
            self.ball_vy = -abs(self.ball_vy) * 0.5
            
        # Check goal
        scored = (self.ball_x >= self.goal_x - 0.5 and 
                 abs(self.ball_y - self.goal_y) <= self.goal_width/2)
                 
        reward = self._compute_reward(action, scored)
        
        terminated = scored
        truncated = self.steps >= self.max_steps
        
        obs = self._get_obs()
        info = self._get_info()
        info['scored'] = scored
        
        return obs, reward, terminated, truncated, info
        
    def _get_obs(self) -> np.ndarray:
        return np.array([
            self.ant_x, self.ant_y,
            self.ball_x, self.ball_y,
            self.ball_vx, self.ball_vy,
            self.goal_x, self.goal_y,
        ], dtype=np.float32)
        
    def _get_info(self) -> Dict:
        ball_goal_dist = np.sqrt((self.ball_x - self.goal_x)**2 + (self.ball_y - self.goal_y)**2)
        return {
            'ball_goal_distance': ball_goal_dist,
            'steps': self.steps,
            'ant_ball_distance': np.sqrt((self.ant_x - self.ball_x)**2 + (self.ant_y - self.ball_y)**2),
        }
        
    def _compute_reward(self, action: np.ndarray, scored: bool) -> float:
        if scored:
            return 1000.0
            
        # Distance rewards
        ball_goal_dist = np.sqrt((self.ball_x - self.goal_x)**2 + (self.ball_y - self.goal_y)**2)
        ant_ball_dist = np.sqrt((self.ant_x - self.ball_x)**2 + (self.ant_y - self.ball_y)**2)
        
        # Reward being close to ball and ball being close to goal
        reward = -0.1 * ball_goal_dist - 0.05 * ant_ball_dist
        
        # Control penalty
        reward -= 0.001 * np.sum(action**2)
        
        # Step penalty
        reward -= 0.01
        
        return reward

class MockPuzzle(gym.Env):
    """Mock Puzzle-4x5 environment"""
    
    def __init__(self, render_mode=None):
        super().__init__()
        
        self.render_mode = render_mode
        self.width = 5
        self.height = 4
        self.n_buttons = 20
        
        # Action space: discrete button press (0-19)
        self.action_space = spaces.Discrete(self.n_buttons)
        
        # Observation space: 20-bit light configuration
        self.observation_space = spaces.Box(
            low=0, high=1, shape=(20,), dtype=np.float32
        )
        
        self.reset()
        
    def reset(self, seed=None, options=None) -> Tuple[np.ndarray, Dict]:
        super().reset(seed=seed)
        if seed is not None:
            np.random.seed(seed)
            
        # Random initial configuration
        self.config = np.random.randint(0, 2**20, dtype=np.uint32)
        
        # Random goal configuration (but solvable)
        self.goal_config = np.random.randint(0, 2**20, dtype=np.uint32)
        
        self.steps = 0
        self.max_steps = 50
        
        obs = self._config_to_obs(self.config)
        info = self._get_info()
        
        return obs, info
        
    def step(self, action: int) -> Tuple[np.ndarray, float, bool, bool, Dict]:
        self.steps += 1
        
        # Apply button press
        mask = self._get_button_mask(action)
        self.config ^= mask
        
        # Check if solved
        solved = (self.config == self.goal_config)
        
        # Compute reward
        if solved:
            reward = 100.0
        else:
            # Hamming distance reward
            hamming_dist = bin(self.config ^ self.goal_config).count('1')
            reward = -hamming_dist - 0.1
            
        terminated = solved
        truncated = self.steps >= self.max_steps
        
        obs = self._config_to_obs(self.config)
        info = self._get_info()
        info['solved'] = solved
        
        return obs, reward, terminated, truncated, info
        
    def _config_to_obs(self, config: np.uint32) -> np.ndarray:
        """Convert bit configuration to observation array"""
        obs = np.zeros(20, dtype=np.float32)
        for i in range(20):
            obs[i] = float((config >> i) & 1)
        return obs
        
    def _get_button_mask(self, button: int) -> np.uint32:
        """Get toggle mask for button press (cross pattern)"""
        row = button // 5
        col = button % 5
        
        mask = 0
        # Toggle button itself
        mask |= (1 << button)
        
        # Toggle cross neighbors
        neighbors = [
            (row-1, col), (row+1, col),  # up, down
            (row, col-1), (row, col+1),  # left, right
        ]
        
        for r, c in neighbors:
            if 0 <= r < self.height and 0 <= c < self.width:
                neighbor_id = r * self.width + c
                mask |= (1 << neighbor_id)
                
        return np.uint32(mask)
        
    def _get_info(self) -> Dict:
        hamming_dist = bin(self.config ^ self.goal_config).count('1')
        return {
            'hamming_distance': hamming_dist,
            'steps': self.steps,
            'current_config': int(self.config),
            'goal_config': int(self.goal_config),
        }

def create_mock_env(env_name: str, **kwargs):
    """Factory function to create mock environments"""
    if "humanoid" in env_name.lower() and "maze" in env_name.lower():
        maze_type = "small"
        if "giant" in env_name.lower():
            maze_type = "giant"
        elif "teleport" in env_name.lower():
            maze_type = "teleport"
        return MockHumanoidMaze(maze_type=maze_type, **kwargs)
        
    elif "ant" in env_name.lower() and "soccer" in env_name.lower():
        return MockAntSoccer(**kwargs)
        
    elif "puzzle" in env_name.lower():
        return MockPuzzle(**kwargs)
        
    else:
        raise ValueError(f"Unknown environment: {env_name}")

if __name__ == "__main__":
    # Quick test of mock environments
    print("Testing Mock OGBench Environments")
    
    # Test HumanoidMaze
    print("\n=== HumanoidMaze Test ===")
    env = create_mock_env("HumanoidMaze-v1")
    obs, info = env.reset(seed=42)
    print(f"Initial obs: {obs}")
    print(f"Initial info: {info}")
    
    for i in range(5):
        action = env.action_space.sample()
        obs, reward, term, trunc, info = env.step(action)
        print(f"Step {i+1}: reward={reward:.3f}, distance={info['distance_to_goal']:.3f}")
        if term or trunc:
            break
            
    # Test AntSoccer
    print("\n=== AntSoccer Test ===")
    env = create_mock_env("AntSoccer-v1") 
    obs, info = env.reset(seed=42)
    print(f"Initial obs: {obs}")
    
    for i in range(5):
        action = env.action_space.sample()
        obs, reward, term, trunc, info = env.step(action)
        print(f"Step {i+1}: reward={reward:.3f}, ball_dist={info['ball_goal_distance']:.3f}")
        if term or trunc:
            break
            
    # Test Puzzle
    print("\n=== Puzzle Test ===")
    env = create_mock_env("Puzzle-4x5-v1")
    obs, info = env.reset(seed=42)
    print(f"Initial config: {info['current_config']:020b}")
    print(f"Goal config:    {info['goal_config']:020b}")
    print(f"Hamming dist: {info['hamming_distance']}")
    
    for i in range(3):
        action = env.action_space.sample()
        obs, reward, term, trunc, info = env.step(action)
        print(f"Step {i+1}: button={action}, hamming={info['hamming_distance']}")
        if term or trunc:
            break
            
    print("✅ Mock OGBench environments working!")
//==============================================================================
// FILE: ./ogbench_eval/run_ogbench_eval.py
//==============================================================================
#!/usr/bin/env python3
"""
OGBench Evaluation Suite for Fusion Alpha
Runs comprehensive evaluation comparing Fusion Alpha to baseline methods
"""

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import json
import time
import os
from typing import Dict, List, Tuple
from dataclasses import dataclass
from collections import defaultdict

from mock_ogbench import create_mock_env
from fusion_alpha_agent import create_agent

@dataclass
class EvalConfig:
    """Evaluation configuration"""
    envs: List[str]
    agents: List[str]
    n_episodes: int
    max_steps_per_episode: int
    seeds: List[int]
    save_dir: str

@dataclass
class EpisodeResult:
    """Single episode results"""
    env_name: str
    agent_name: str
    episode: int
    seed: int
    success: bool
    total_reward: float
    steps: int
    final_distance: float
    solve_time: float

class OGBenchEvaluator:
    """Main evaluation class"""
    
    def __init__(self, config: EvalConfig):
        self.config = config
        self.results: List[EpisodeResult] = []
        
        # Create save directory
        os.makedirs(config.save_dir, exist_ok=True)
        
    def run_evaluation(self):
        """Run complete evaluation suite"""
        print("🚀 Starting OGBench Evaluation for Fusion Alpha")
        print(f"Environments: {self.config.envs}")
        print(f"Agents: {self.config.agents}")
        print(f"Episodes per config: {self.config.n_episodes}")
        
        start_time = time.time()
        
        for env_name in self.config.envs:
            print(f"\n{'='*50}")
            print(f"Environment: {env_name}")
            print(f"{'='*50}")
            
            for agent_name in self.config.agents:
                print(f"\n--- Running {agent_name} on {env_name} ---")
                
                self._eval_agent_on_env(env_name, agent_name)
                
        total_time = time.time() - start_time
        print(f"\n✅ Evaluation complete! Total time: {total_time:.1f}s")
        
        # Analyze and save results
        self._analyze_results()
        self._save_results()
        
    def _eval_agent_on_env(self, env_name: str, agent_name: str):
        """Evaluate single agent on single environment"""
        episode_results = []
        
        for episode in range(self.config.n_episodes):
            for seed in self.config.seeds:
                result = self._run_single_episode(env_name, agent_name, episode, seed)
                episode_results.append(result)
                self.results.append(result)
                
                # Print progress
                if (episode * len(self.config.seeds) + len(self.config.seeds)) % 10 == 0:
                    success_rate = sum(r.success for r in episode_results) / len(episode_results)
                    avg_reward = np.mean([r.total_reward for r in episode_results])
                    print(f"  Episodes {len(episode_results):3d}: "
                          f"Success={success_rate:.2%}, "
                          f"Avg Reward={avg_reward:.1f}")
        
        # Episode summary
        success_rate = sum(r.success for r in episode_results) / len(episode_results)
        avg_reward = np.mean([r.total_reward for r in episode_results])
        avg_steps = np.mean([r.steps for r in episode_results])
        
        print(f"\n{agent_name} on {env_name} Summary:")
        print(f"  Success Rate: {success_rate:.2%}")
        print(f"  Average Reward: {avg_reward:.2f}")
        print(f"  Average Steps: {avg_steps:.1f}")
        
    def _run_single_episode(self, env_name: str, agent_name: str, episode: int, seed: int) -> EpisodeResult:
        """Run a single episode"""
        
        # Create environment and agent
        env = create_mock_env(env_name, render_mode=None)
        agent = create_agent(env_name, env.action_space, env.observation_space, agent_name)
        
        # Reset
        obs, info = env.reset(seed=seed)
        agent.reset()
        
        total_reward = 0
        steps = 0
        start_time = time.time()
        
        for step in range(self.config.max_steps_per_episode):
            # Agent acts
            action = agent.act(obs, info)
            
            # Environment step
            next_obs, reward, terminated, truncated, next_info = env.step(action)
            
            # Update agent
            if hasattr(agent, 'update'):
                agent.update(obs, action, reward, next_obs, terminated or truncated, next_info)
            
            total_reward += reward
            steps += 1
            
            # Check termination
            if terminated or truncated:
                break
                
            obs, info = next_obs, next_info
            
        solve_time = time.time() - start_time
        
        # Determine success and final distance
        success = info.get('success', False) or info.get('solved', False) or info.get('scored', False)
        if not success and terminated:
            success = True  # Terminated successfully
            
        # Get final distance/metric
        final_distance = info.get('distance_to_goal', 
                                info.get('ball_goal_distance',
                                       info.get('hamming_distance', 0)))
        
        return EpisodeResult(
            env_name=env_name,
            agent_name=agent_name,
            episode=episode,
            seed=seed,
            success=success,
            total_reward=total_reward,
            steps=steps,
            final_distance=final_distance,
            solve_time=solve_time,
        )
    
    def _analyze_results(self):
        """Analyze and visualize results"""
        print("\n📊 Analyzing Results...")
        
        # Convert to DataFrame for analysis
        df = pd.DataFrame([
            {
                'env': r.env_name,
                'agent': r.agent_name,
                'episode': r.episode,
                'seed': r.seed,
                'success': r.success,
                'reward': r.total_reward,
                'steps': r.steps,
                'distance': r.final_distance,
                'time': r.solve_time,
            }
            for r in self.results
        ])
        
        # Aggregate statistics
        stats = df.groupby(['env', 'agent']).agg({
            'success': ['mean', 'std'],
            'reward': ['mean', 'std'],
            'steps': ['mean', 'std'],
            'distance': ['mean', 'std'],
            'time': ['mean', 'std'],
        }).round(3)
        
        print("\n📈 Performance Summary:")
        print(stats)
        
        # Create visualizations
        self._create_plots(df)
        
        return df, stats
        
    def _create_plots(self, df: pd.DataFrame):
        """Create evaluation plots"""
        plt.style.use('seaborn-v0_8' if 'seaborn-v0_8' in plt.style.available else 'seaborn')
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle('Fusion Alpha OGBench Evaluation Results', fontsize=16, fontweight='bold')
        
        # 1. Success Rate by Environment
        ax1 = axes[0, 0]
        success_rates = df.groupby(['env', 'agent'])['success'].mean().unstack()
        success_rates.plot(kind='bar', ax=ax1, rot=45)
        ax1.set_title('Success Rate by Environment')
        ax1.set_ylabel('Success Rate')
        ax1.legend(title='Agent')
        ax1.grid(True, alpha=0.3)
        
        # 2. Average Reward by Environment  
        ax2 = axes[0, 1]
        avg_rewards = df.groupby(['env', 'agent'])['reward'].mean().unstack()
        avg_rewards.plot(kind='bar', ax=ax2, rot=45)
        ax2.set_title('Average Reward by Environment')
        ax2.set_ylabel('Average Reward')
        ax2.legend(title='Agent')
        ax2.grid(True, alpha=0.3)
        
        # 3. Steps to Completion
        ax3 = axes[1, 0]
        # Box plot of steps by agent
        sns.boxplot(data=df, x='agent', y='steps', hue='env', ax=ax3)
        ax3.set_title('Steps to Completion Distribution')
        ax3.set_ylabel('Steps')
        ax3.tick_params(axis='x', rotation=45)
        
        # 4. Success Rate Over Episodes (Learning Curves)
        ax4 = axes[1, 1]
        for env in df['env'].unique():
            for agent in df['agent'].unique():
                env_agent_df = df[(df['env'] == env) & (df['agent'] == agent)]
                if not env_agent_df.empty:
                    # Rolling success rate
                    rolling_success = env_agent_df.groupby('episode')['success'].mean().rolling(5, min_periods=1).mean()
                    ax4.plot(rolling_success.index, rolling_success.values, 
                           label=f'{agent}-{env}', marker='o', markersize=3)
                    
        ax4.set_title('Learning Curves (Rolling Success Rate)')
        ax4.set_xlabel('Episode')
        ax4.set_ylabel('Success Rate (Rolling Avg)')
        ax4.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
        ax4.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(os.path.join(self.config.save_dir, 'evaluation_results.png'), 
                   dpi=300, bbox_inches='tight')
        plt.show()
        
        # Additional detailed plots
        self._create_detailed_plots(df)
        
    def _create_detailed_plots(self, df: pd.DataFrame):
        """Create additional detailed analysis plots"""
        
        # Environment-specific analysis
        for env in df['env'].unique():
            env_df = df[df['env'] == env]
            
            fig, axes = plt.subplots(2, 2, figsize=(12, 10))
            fig.suptitle(f'Detailed Analysis: {env}', fontsize=14, fontweight='bold')
            
            # Success rate comparison
            ax1 = axes[0, 0]
            success_by_agent = env_df.groupby('agent')['success'].mean()
            success_by_agent.plot(kind='bar', ax=ax1, color=['skyblue', 'lightcoral', 'lightgreen'][:len(success_by_agent)])
            ax1.set_title('Success Rate by Agent')
            ax1.set_ylabel('Success Rate')
            ax1.set_xticklabels(ax1.get_xticklabels(), rotation=45)
            
            # Reward distribution
            ax2 = axes[0, 1]
            sns.boxplot(data=env_df, x='agent', y='reward', ax=ax2)
            ax2.set_title('Reward Distribution')
            ax2.set_xticklabels(ax2.get_xticklabels(), rotation=45)
            
            # Episode success over time
            ax3 = axes[1, 0]
            for agent in env_df['agent'].unique():
                agent_df = env_df[env_df['agent'] == agent]
                episode_success = agent_df.groupby('episode')['success'].mean()
                ax3.plot(episode_success.index, episode_success.values, 
                        label=agent, marker='o', markersize=2)
            ax3.set_title('Success Rate by Episode')
            ax3.set_xlabel('Episode')
            ax3.set_ylabel('Success Rate')
            ax3.legend()
            ax3.grid(True, alpha=0.3)
            
            # Final distance/quality metric
            ax4 = axes[1, 1]
            sns.boxplot(data=env_df, x='agent', y='distance', ax=ax4)
            ax4.set_title('Final Distance/Error Distribution')
            ax4.set_xticklabels(ax4.get_xticklabels(), rotation=45)
            
            plt.tight_layout()
            env_clean = env.replace('/', '_').replace('-', '_')
            plt.savefig(os.path.join(self.config.save_dir, f'{env_clean}_detailed.png'), 
                       dpi=300, bbox_inches='tight')
            plt.show()
            
    def _save_results(self):
        """Save results to files"""
        print(f"\n💾 Saving results to {self.config.save_dir}")
        
        # Save raw results
        results_data = [
            {
                'env_name': r.env_name,
                'agent_name': r.agent_name,
                'episode': r.episode,
                'seed': r.seed,
                'success': r.success,
                'total_reward': r.total_reward,
                'steps': r.steps,
                'final_distance': r.final_distance,
                'solve_time': r.solve_time,
            }
            for r in self.results
        ]
        
        with open(os.path.join(self.config.save_dir, 'raw_results.json'), 'w') as f:
            json.dump(results_data, f, indent=2)
            
        # Save aggregated statistics
        df = pd.DataFrame(results_data)
        
        summary_stats = {}
        for env in df['env_name'].unique():
            summary_stats[env] = {}
            env_df = df[df['env_name'] == env]
            
            for agent in env_df['agent_name'].unique():
                agent_df = env_df[env_df['agent_name'] == agent]
                
                summary_stats[env][agent] = {
                    'success_rate': float(agent_df['success'].mean()),
                    'success_rate_std': float(agent_df['success'].std()),
                    'avg_reward': float(agent_df['total_reward'].mean()),
                    'avg_reward_std': float(agent_df['total_reward'].std()),
                    'avg_steps': float(agent_df['steps'].mean()),
                    'avg_steps_std': float(agent_df['steps'].std()),
                    'avg_final_distance': float(agent_df['final_distance'].mean()),
                    'avg_solve_time': float(agent_df['solve_time'].mean()),
                    'total_episodes': len(agent_df),
                }
                
        with open(os.path.join(self.config.save_dir, 'summary_stats.json'), 'w') as f:
            json.dump(summary_stats, f, indent=2)
            
        # Save CSV for further analysis
        df.to_csv(os.path.join(self.config.save_dir, 'results.csv'), index=False)
        
        print("Results saved:")
        print(f"  - Raw results: raw_results.json")
        print(f"  - Summary stats: summary_stats.json") 
        print(f"  - CSV data: results.csv")
        print(f"  - Plots: evaluation_results.png + detailed plots")

def main():
    """Main evaluation script"""
    
    # Evaluation configuration
    config = EvalConfig(
        envs=[
            "HumanoidMaze-small-v1",
            "AntSoccer-v1", 
            "Puzzle-4x5-v1",
        ],
        agents=[
            "random",
            "fusion_alpha",
        ],
        n_episodes=20,  # Episodes per seed
        max_steps_per_episode=500,
        seeds=[42, 123, 456],  # Multiple seeds for robustness
        save_dir="ogbench_results"
    )
    
    # Run evaluation
    evaluator = OGBenchEvaluator(config)
    evaluator.run_evaluation()
    
    print("\n🎉 OGBench evaluation complete!")
    print("Check the 'ogbench_results' directory for detailed results and plots.")

if __name__ == "__main__":
    main()
//==============================================================================
// FILE: ./python/bicep_to_edges.py
//==============================================================================
#!/usr/bin/env python3
"""
Convert BICEP trajectories to edge weights for Fusion Alpha graphs
Reads BICEP parquet files and computes transition statistics
"""

import numpy as np
import pandas as pd
import json
import ast
from collections import defaultdict
from typing import Dict, List, Tuple, Optional
import argparse


def _coerce_state_value(value) -> np.ndarray:
    """Convert misc state representations into a 1D numpy array."""
    if isinstance(value, np.ndarray):
        arr = value.astype(np.float32)
    elif isinstance(value, (list, tuple)):
        arr = np.asarray(value, dtype=np.float32)
    elif isinstance(value, (float, int, np.floating, np.integer)):
        arr = np.array([value], dtype=np.float32)
    elif isinstance(value, str):
        text = value.strip()
        try:
            if text.startswith('[') and text.endswith(']'):
                parsed = ast.literal_eval(text)
                if isinstance(parsed, (list, tuple)):
                    arr = np.asarray(parsed, dtype=np.float32)
                else:
                    arr = np.array([float(parsed)], dtype=np.float32)
            else:
                arr = np.array([float(text)], dtype=np.float32)
        except Exception:
            arr = np.array([0.0], dtype=np.float32)
    else:
        arr = np.array([float(value)], dtype=np.float32)
    if arr.ndim == 0:
        arr = arr.reshape(1)
    return arr.ravel().astype(np.float32)


def _row_state_to_vec(row, columns) -> np.ndarray:
    """Robustly extract a state vector from a DataFrame row.

    Supports BICEP parity parquet (one row per step with a 1D list),
    flattened columns like 'state_0', or falling back to 'input'.
    """
    # Preferred: 'state' column (list-like or scalar)
    if 'state' in columns:
        s = row['state']
        return _coerce_state_value(s)
    # Next: flattened component
    if 'state_0' in columns:
        return _coerce_state_value(row['state_0'])
    # Fallback: use 'input' as proxy state (parity task)
    if 'input' in columns:
        return _coerce_state_value(row['input'])
    # Last resort: try any numeric columns
    numeric_cols = [c for c in columns if isinstance(row[c], (float, int, np.floating, np.integer))]
    if numeric_cols:
        return np.array([row[numeric_cols[0]]], dtype=np.float32)
    raise ValueError("Could not derive state vector from row; missing 'state', 'state_0', or 'input'.")


def discretize_state(state: np.ndarray, bounds: np.ndarray, n_bins: int = 20) -> int:
    """
    Discretize continuous state to grid index
    
    Args:
        state: continuous state vector
        bounds: (2, d) min/max bounds per dimension
        n_bins: discretization resolution per dimension
    
    Returns:
        grid_index: flattened grid index
    """
    # Normalize to [0, 1] per dimension
    normalized = (state - bounds[0]) / (bounds[1] - bounds[0] + 1e-8)
    normalized = np.clip(normalized, 0, 0.999)
    
    # Convert to grid indices
    indices = (normalized * n_bins).astype(int)
    
    # Flatten to single index (for simplicity, just use first 2 dims)
    if len(indices) >= 2:
        return indices[0] * n_bins + indices[1]
    else:
        return int(indices[0])


def compute_transition_stats(trajectories: pd.DataFrame,
                             n_bins: int = 20,
                             dt: float = 0.01) -> Dict:
    """
    Compute transition statistics from BICEP trajectories.

    Works with step-wise Parquet (one row per step) by grouping on
    'sequence_id' and sorting by 'step'.

    Returns dict with:
      - transitions: {(i,j): count}
      - variances: {(i,j): variance}
      - state_bounds: (2, d) array
    """
    if len(trajectories) == 0:
      return {
        'transitions': {},
        'variances': {},
        'state_bounds': [[0.0], [1.0]],
        'n_bins': n_bins,
        'n_states': n_bins * n_bins,
      }

    # Compute bounds from all rows
    cols = trajectories.columns
    states_list = []
    for _, row in trajectories.iterrows():
        v = _row_state_to_vec(row, cols)
        states_list.append(v)
    states = np.vstack(states_list)  # (N, d)
    state_dim = states.shape[1]

    state_bounds = np.array([
        states.min(axis=0),
        states.max(axis=0)
    ], dtype=np.float32)

    # Count node occupancy across the dataset
    node_counts = defaultdict(int)
    for state in states:
        idx = discretize_state(state, state_bounds, n_bins)
        node_counts[int(idx)] += 1

    # Count transitions by sequence
    transitions = defaultdict(int)
    transition_times = defaultdict(list)

    if 'sequence_id' in cols and 'step' in cols:
        grouped = trajectories.groupby('sequence_id', sort=False)
        for _, df_seq in grouped:
            df_seq = df_seq.sort_values('step')
            prev = None
            for _, row in df_seq.iterrows():
                cur = _row_state_to_vec(row, cols)
                if prev is not None:
                    i = discretize_state(prev, state_bounds, n_bins)
                    j = discretize_state(cur, state_bounds, n_bins)
                    if i != j:
                        transitions[(i, j)] += 1
                        transition_times[(i, j)].append(dt)
                prev = cur
    else:
        # Fallback: treat consecutive rows as a single trajectory
        prev = None
        for _, row in trajectories.iterrows():
            cur = _row_state_to_vec(row, cols)
            if prev is not None:
                i = discretize_state(prev, state_bounds, n_bins)
                j = discretize_state(cur, state_bounds, n_bins)
                if i != j:
                    transitions[(i, j)] += 1
                    transition_times[(i, j)].append(dt)
            prev = cur

    # Compute variances
    variances = {}
    for (i, j), times in transition_times.items():
        if len(times) > 1:
            variances[(i, j)] = float(np.var(times))
        else:
            variances[(i, j)] = 0.1  # Default variance

    return {
        'transitions': dict(transitions),
        'variances': dict(variances),
        'state_bounds': state_bounds.tolist(),
        'n_bins': n_bins,
        'n_states': int(n_bins * n_bins),  # 2D grid indexing even for 1D state
        'node_counts': {int(k): int(v) for k, v in node_counts.items()},
        'state_dim': int(state_dim),
    }


def transitions_to_edge_weights(stats: Dict,
                               temperature: float = 1.0) -> List[Tuple[int, int, float]]:
    """
    Convert transition statistics to edge weights
    
    Uses: w_ij = count_ij / max_count * exp(-var_ij / temperature)
    """
    transitions = stats['transitions']
    variances = stats['variances']
    
    if not transitions:
        return []
    
    max_count = max(transitions.values())
    edges = []
    
    for (i, j), count in transitions.items():
        # Skip self-loops for cleaner graphs
        if i == j:
            continue
            
        # Count-based weight
        count_weight = count / max_count
        
        # Variance penalty
        var = variances.get((i, j), 0.1)
        var_weight = np.exp(-var / temperature)
        
        # Combined weight
        weight = count_weight * var_weight
        
        # Store as (i, j, weight)
        edges.append((int(i), int(j), float(weight)))
    
    return edges


def build_spatial_edges(stats: Dict,
                        nodes: np.ndarray,
                        spatial_k: int = 4,
                        spatial_sigma: float = 0.25,
                        min_count: int = 5,
                        weight_scale: float = 0.3,
                        include_full_grid: bool = False) -> List[Tuple[int, int, float]]:
    if spatial_k <= 0:
        return []
    node_counts = stats.get('node_counts', {})
    if include_full_grid:
        visited = list(range(nodes.shape[0]))
    else:
        visited = [idx for idx, cnt in node_counts.items() if cnt >= min_count]
    if len(visited) < 2:
        return []

    coords = nodes[visited]
    edges: List[Tuple[int, int, float]] = []
    for idx, coord in zip(visited, coords):
        dists = np.linalg.norm(coords - coord, axis=1)
        order = np.argsort(dists)
        neighbor_count = 0
        for neighbor_idx in order[1:]:  # skip self at 0
            neighbor_node = visited[neighbor_idx]
            dist = dists[neighbor_idx]
            if dist <= 0:
                continue
            weight = weight_scale * float(np.exp(-dist / max(1e-6, spatial_sigma)))
            edges.append((int(idx), int(neighbor_node), weight))
            edges.append((int(neighbor_node), int(idx), weight))
            neighbor_count += 1
            if neighbor_count >= spatial_k:
                break
    return edges


def merge_edge_sets(*edge_lists: List[Tuple[int, int, float]]) -> List[Tuple[int, int, float]]:
    edge_map: Dict[Tuple[int, int], float] = {}
    for edges in edge_lists:
        for i, j, w in edges:
            key = (int(i), int(j))
            if key in edge_map:
                edge_map[key] = max(edge_map[key], w)
            else:
                edge_map[key] = w
    return [(i, j, w) for (i, j), w in edge_map.items()]


def create_grid_nodes(n_bins: int, bounds: np.ndarray) -> np.ndarray:
    """Create node positions for discretized grid"""
    nodes = []
    
    for i in range(n_bins):
        for j in range(n_bins):
            # Map back to continuous space
            x = bounds[0, 0] + (i + 0.5) * (bounds[1, 0] - bounds[0, 0]) / n_bins
            y = bounds[0, 1] + (j + 0.5) * (bounds[1, 1] - bounds[0, 1]) / n_bins if bounds.shape[1] > 1 else 0.0
            nodes.append([x, y])
    
    return np.array(nodes, dtype=np.float32)


def load_bicep_dataframe(parquet_path: Optional[str], csv_path: Optional[str]) -> pd.DataFrame:
    if csv_path:
        print(f"Loading BICEP trajectories from CSV: {csv_path}")
        df = pd.read_csv(csv_path)
        print(f"Loaded {len(df)} rows")
        return df
    if parquet_path:
        print(f"Loading BICEP trajectories from Parquet: {parquet_path}")
        try:
            import polars as pl  # type: ignore
            df = pl.read_parquet(parquet_path).to_pandas()
        except Exception:
            df = pd.read_parquet(parquet_path)
        print(f"Loaded {len(df)} rows")
        return df
    raise ValueError("Must supply either parquet or csv input")


def main():
    parser = argparse.ArgumentParser(description="Convert BICEP trajectories to graph edges")
    parser.add_argument("--bicep-parquet", help="Path to BICEP trajectory parquet")
    parser.add_argument("--bicep-csv", help="Path to BICEP trajectory CSV (parity_data.csv)")
    parser.add_argument("--output", default="bicep_graph.json", help="Output JSON file")
    parser.add_argument("--n-bins", type=int, default=20, help="Discretization resolution")
    parser.add_argument("--temperature", type=float, default=1.0, help="Variance temperature")
    parser.add_argument("--spatial-k", type=int, default=0, help="Add k-NN spatial edges per node (0=disable)")
    parser.add_argument("--spatial-sigma", type=float, default=0.25, help="Spatial decay length for spatial edges")
    parser.add_argument("--spatial-weight", type=float, default=0.3, help="Scaling factor for spatial edges")
    parser.add_argument("--min-count", type=int, default=5, help="Minimum node visits before spatial edges are added")
    parser.add_argument("--spatial-full-grid", action="store_true", help="Include all grid nodes when building spatial edges")
    
    args = parser.parse_args()

    if not args.bicep_parquet and not args.bicep_csv:
        parser.error("Must supply --bicep-parquet or --bicep-csv")

    df = load_bicep_dataframe(args.bicep_parquet, args.bicep_csv)
    
    # Compute transition statistics
    print(f"Computing transition statistics (n_bins={args.n_bins})...")
    stats = compute_transition_stats(df, n_bins=args.n_bins)
    
    n_transitions = len(stats['transitions'])
    print(f"Found {n_transitions} unique transitions")
    
    # Create node positions
    bounds = np.array(stats['state_bounds'])
    nodes = create_grid_nodes(args.n_bins, bounds)

    # Convert to edge weights
    print("Converting to edge weights...")
    transition_edges = transitions_to_edge_weights(stats, temperature=args.temperature)
    spatial_edges = build_spatial_edges(
        stats,
        nodes,
        spatial_k=args.spatial_k,
        spatial_sigma=args.spatial_sigma,
        min_count=args.min_count,
        weight_scale=args.spatial_weight,
        include_full_grid=args.spatial_full_grid,
    )
    edges = merge_edge_sets(transition_edges, spatial_edges)
    print(f"Created {len(edges)} edges")
    
    # Save results
    stats_json = {
        'n_bins': stats['n_bins'],
        'n_states': stats['n_states'],
        'state_bounds': stats['state_bounds'],
        'transitions': [
            {'source': int(i), 'target': int(j), 'count': int(count)}
            for (i, j), count in stats['transitions'].items()
        ],
        'variances': [
            {'source': int(i), 'target': int(j), 'variance': float(var)}
            for (i, j), var in stats['variances'].items()
        ],
        'node_counts': stats.get('node_counts', {}),
        'state_dim': stats.get('state_dim', 1),
    }

    output = {
        'nodes': nodes.tolist(),
        'edges': edges,
        'stats': stats_json,
        'n_nodes': len(nodes),
        'n_edges': len(edges),
    }
    
    with open(args.output, 'w') as f:
        json.dump(output, f, indent=2)
    
    print(f"\nSaved graph to {args.output}")
    print(f"  Nodes: {len(nodes)}")
    print(f"  Edges: {len(edges)}")
    if edges:
        w_min = min(e[2] for e in edges)
        w_max = max(e[2] for e in edges)
        print(f"  Edge weight range: [{w_min:.3f}, {w_max:.3f}]")
    else:
        print("  Edge weight range: [n/a]")
    
    # Print example edges
    print("\nExample edges (top 10 by weight):")
    sorted_edges = sorted(edges, key=lambda e: e[2], reverse=True)[:10]
    for i, j, w in sorted_edges:
        print(f"  {i} → {j}: {w:.3f}")


if __name__ == "__main__":
    main()

//==============================================================================
// FILE: ./python/dump_q.py
//==============================================================================
#!/usr/bin/env python3
"""Dump deterministic q-values from the simple_propagate binding."""

import argparse
import json
import numpy as np
import os
import sys

sys.path.append(os.path.join(os.path.dirname(__file__), "..", "target", "release"))

try:
    import fusion_alpha as fa
except ImportError as exc:
    print(f"Failed to import fusion_alpha: {exc}")
    print("Build with: cargo build --release -p fusion-bindings")
    sys.exit(1)


def build_chain(length: int) -> tuple[np.ndarray, np.ndarray, int, int]:
    nodes = np.array([[float(i), 0.0] for i in range(length)], dtype=np.float32)
    edges = []
    for i in range(length - 1):
        edges.append([i, i + 1, 1.0])
        edges.append([i + 1, i, 1.0])
    return nodes, np.array(edges, dtype=np.float32), 0, length - 1


def main() -> None:
    parser = argparse.ArgumentParser(description="Dump q-values for a chain graph")
    parser.add_argument("--length", type=int, default=5)
    parser.add_argument("--severity", type=float, default=0.4)
    parser.add_argument("--t-max", type=int, default=60)
    parser.add_argument("--output", required=True)
    args = parser.parse_args()

    nodes, edges, current, goal = build_chain(args.length)
    q_values = fa.simple_propagate(
        nodes=nodes,
        edges=edges,
        goal_node=goal,
        current_node=current,
        enn_q_prior=0.6,
        severity=args.severity,
        t_max=args.t_max,
    )
    with open(args.output, "w", encoding="utf-8") as fh:
        json.dump({
            "length": args.length,
            "severity": args.severity,
            "t_max": args.t_max,
            "current": current,
            "goal": goal,
            "q_values": [float(x) for x in q_values],
        }, fh, indent=2)
    print(f"Wrote q-values to {args.output}")


if __name__ == "__main__":
    main()

//==============================================================================
// FILE: ./python/enn_forward.py
//==============================================================================
import json
import numpy as np
from typing import Tuple, Union

def _relu(x: np.ndarray) -> np.ndarray:
    """ReLU activation function"""
    return np.maximum(x, 0.0)

def _sigmoid(x: np.ndarray) -> np.ndarray:
    """Sigmoid activation function"""
    return 1.0 / (1.0 + np.exp(-np.clip(x, -50, 50)))  # Clip for numerical stability

def _softmax(x: np.ndarray, tau: float = 1.0) -> np.ndarray:
    """Softmax with temperature"""
    x = x / max(tau, 1e-6)
    x = x - x.max(axis=-1, keepdims=True)  # Numerical stability
    ex = np.exp(x)
    return ex / np.clip(ex.sum(axis=-1, keepdims=True), 1e-6, None)

class ENNForward:
    """
    Mirrors the minimal 'collapse' forward pass from ENN:
      x ∈ R^d (input features)
      z = ReLU(x @ Wf + bf)             # Hidden layer (h)
      logits = z @ Wc + bc              # Collapse logits (k)
      logits = logits @ L^T             # Apply entanglement
      alpha = softmax(logits / tau)     # Mixture weights (k)
      q0 = sigmoid(alpha @ w_out + b)   # Committor value in (0,1)
      
    Expects JSON weights exported by collapse_committor_train --export-weights
    """
    def __init__(self, weights_json_path: str):
        """Load ENN weights from JSON file"""
        with open(weights_json_path, "r") as f:
            d = json.load(f)
            
        # Load weight matrices
        self.Wf = np.asarray(d["feat_w"], dtype=np.float32)      # (d, h)
        self.bf = np.asarray(d["feat_b"], dtype=np.float32)      # (h,)
        self.Wc = np.asarray(d["collapse_w"], dtype=np.float32)  # (h, k)
        self.bc = np.asarray(d["collapse_b"], dtype=np.float32)  # (k,)
        self.L  = np.asarray(d["L"], dtype=np.float32)           # (k, k)
        self.wo = np.asarray(d["readout_w"], dtype=np.float32)   # (k,)
        self.bo = float(d.get("readout_b", 0.0))
        self.tau = float(d.get("temperature", 1.0))
        
        # Store dimensions
        self.d = d["d"]  # Input dimension
        self.h = d["h"]  # Hidden dimension
        self.k = d["k"]  # Number of collapse states
        
        # Sanity checks
        d_in, h = self.Wf.shape
        h2, k = self.Wc.shape
        assert d_in == self.d, f"Expected d={self.d}, got {d_in}"
        assert h == self.h, f"Expected h={self.h}, got {h}"
        assert self.bf.shape == (h,)
        assert h2 == h
        assert k == self.k, f"Expected k={self.k}, got {k}"
        assert self.bc.shape == (k,)
        assert self.L.shape == (k, k)
        assert self.wo.shape == (k,)
        
        print(f"Loaded ENN weights: d={self.d}, h={self.h}, k={self.k}")

    def forward(self, X: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        """
        Forward pass through ENN collapse head
        
        Args:
            X: (n, d) node features
            
        Returns:
            q0: (n,) committor values in (0,1)
            alpha: (n, k) latent mixture weights
        """
        X = np.asarray(X, dtype=np.float32)
        if X.ndim == 1:
            X = X.reshape(1, -1)
        
        n, d = X.shape
        assert d == self.d, f"Expected input dim {self.d}, got {d}"
        
        # Feature projection with ReLU
        Z = _relu(X @ self.Wf + self.bf)      # (n, h)
        
        # Collapse head
        logits = Z @ self.Wc + self.bc        # (n, k)
        
        # Apply entanglement matrix
        logits = logits @ self.L.T             # (n, k)
        
        # Softmax to get mixture weights
        alpha = _softmax(logits, tau=self.tau) # (n, k)
        
        # Final readout to committor
        q0 = _sigmoid(alpha @ self.wo + self.bo)  # (n,)
        
        return q0.astype(np.float32), alpha.astype(np.float32)

    def forward_one(self, x: np.ndarray) -> float:
        """
        Convenience method for single node
        
        Args:
            x: (d,) single node features
            
        Returns:
            q0: scalar committor value in (0,1)
        """
        q0, _ = self.forward(x.reshape(1, -1))
        return float(q0[0])
    
    def compute_severity(self, alpha: np.ndarray) -> float:
        """
        Compute severity from alpha entropy
        
        Args:
            alpha: (n, k) mixture weights from forward pass
            
        Returns:
            severity: scalar in [0, 1] based on entropy
        """
        # Compute entropy of mixture weights
        eps = 1e-12
        alpha_entropy = -(alpha * np.clip(np.log(alpha + eps), -30, 30)).sum(axis=1).mean()
        
        # Normalize by max entropy (log k)
        max_entropy = np.log(self.k)
        severity = float(np.clip(alpha_entropy / max_entropy, 0.0, 1.0))
        
        return severity


# Example usage and testing
if __name__ == "__main__":
    import os
    
    # Path to exported weights (update this)
    weights_path = "../ENNsrc/ENNrust/enn/runs/enn_weights.json"
    
    if os.path.exists(weights_path):
        # Load ENN
        enn = ENNForward(weights_path)
        
        # Test on dummy features
        n_nodes = 5
        X = np.random.randn(n_nodes, enn.d).astype(np.float32)
        
        # Forward pass
        q0, alpha = enn.forward(X)
        
        print(f"\nTest forward pass:")
        print(f"Input shape: {X.shape}")
        print(f"q0 shape: {q0.shape}, values: {q0}")
        print(f"alpha shape: {alpha.shape}")
        print(f"alpha sums: {alpha.sum(axis=1)}")  # Should be all ~1.0
        
        # Compute severity
        severity = enn.compute_severity(alpha)
        print(f"Severity: {severity:.3f}")
        
        # Test single node
        x_single = X[0]
        q0_single = enn.forward_one(x_single)
        print(f"\nSingle node q0: {q0_single:.3f}")
        assert abs(q0_single - q0[0]) < 1e-6, "Single node forward mismatch"
        
        print("\n✅ ENN forward pass working!")
    else:
        print(f"⚠️  Weights file not found at {weights_path}")
        print("Run collapse_committor_train with --export-weights first")
//==============================================================================
// FILE: ./python/enn_fusion_demo.py
//==============================================================================
#!/usr/bin/env python3
"""
Demo: ENN → Fusion Alpha integration
Shows how to use ENN forward pass to provide priors for committor propagation
"""

import numpy as np
import sys
import os

# Add path for fusion_alpha module
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'target', 'release'))

try:
    import fusion_alpha as fa
except ImportError:
    print("Warning: fusion_alpha not built. Run: cargo build --release -p fusion-bindings")
    fa = None

from enn_forward import ENNForward


def create_simple_maze_graph(width=5, height=5):
    """Create a simple grid maze for testing"""
    nodes = []
    edges = []
    
    # Create grid nodes
    for i in range(height):
        for j in range(width):
            x = float(j)
            y = float(i)
            nodes.append([x, y])
    
    # Create edges (4-connected grid)
    node_id = lambda i, j: i * width + j
    
    for i in range(height):
        for j in range(width):
            current = node_id(i, j)
            
            # Right edge
            if j < width - 1:
                neighbor = node_id(i, j + 1)
                edges.append([current, neighbor, 1.0])
                edges.append([neighbor, current, 1.0])
            
            # Down edge
            if i < height - 1:
                neighbor = node_id(i + 1, j)
                edges.append([current, neighbor, 1.0])
                edges.append([neighbor, current, 1.0])
    
    nodes = np.array(nodes, dtype=np.float32)
    edges = np.array(edges, dtype=np.float32)
    
    return nodes, edges


def node_to_features(nodes, current_idx, goal_idx):
    """
    Convert node positions to features for ENN
    This should match the feature engineering in collapse_committor_train.rs
    """
    current_pos = nodes[current_idx]
    goal_pos = nodes[goal_idx]
    
    features = []
    for i, pos in enumerate(nodes):
        # Distance-based features
        dist_to_current = np.linalg.norm(pos - current_pos)
        dist_to_goal = np.linalg.norm(pos - goal_pos)
        
        # Create feature vector similar to double-well features
        x = dist_to_goal - dist_to_current  # Relative position
        feat = np.array([
            x,                      # position-like
            x**2,                   # quadratic
            x**3,                   # cubic
            (x**2 - 1)**2 / 4,     # potential-like
            x**3 - x,              # force-like
        ], dtype=np.float32)
        
        features.append(feat)
    
    return np.array(features, dtype=np.float32)


def main():
    # Check if weights exist
    enn_weights_path = "../../ENNsrc/ENNrust/enn/runs/enn_weights.json"
    
    if not os.path.exists(enn_weights_path):
        print(f"⚠️  ENN weights not found at {enn_weights_path}")
        print("Please run: cargo run -r -p enn-examples --bin collapse_committor_train -- \\")
        print("  --in ../../BICEPsrc/BICEPrust/bicep/runs/dw.parquet \\")
        print("  --epochs 10 --export-weights runs/enn_weights.json")
        return
    
    if fa is None:
        print("⚠️  fusion_alpha module not available")
        return
    
    print("=== ENN → Fusion Alpha Integration Demo ===\n")
    
    # 1. Create simple maze graph
    nodes, edges = create_simple_maze_graph(5, 5)
    n_nodes = len(nodes)
    
    current_node = 0      # Top-left corner
    goal_node = 24        # Bottom-right corner
    
    print(f"Created {n_nodes}-node grid graph")
    print(f"Start: node {current_node} at {nodes[current_node]}")
    print(f"Goal: node {goal_node} at {nodes[goal_node]}")
    
    # 2. Load ENN and compute features
    enn = ENNForward(enn_weights_path)
    features = node_to_features(nodes, current_node, goal_node)
    
    # 3. Get ENN predictions
    q0_enn, alpha = enn.forward(features)
    severity = enn.compute_severity(alpha)
    
    print(f"\nENN predictions:")
    print(f"  q0 range: [{q0_enn.min():.3f}, {q0_enn.max():.3f}]")
    print(f"  q0[current]: {q0_enn[current_node]:.3f}")
    print(f"  q0[goal]: {q0_enn[goal_node]:.3f}")
    print(f"  Severity: {severity:.3f}")
    
    # 4. Run Fusion Alpha propagation
    print(f"\nRunning Fusion Alpha propagation...")
    
    # Map severity to propagation config
    t_max = int(20 + 80 * severity)
    
    # Use fusion_alpha
    q_fusion = fa.simple_propagate(
        nodes=nodes,
        edges=edges,
        goal_node=goal_node,
        current_node=current_node,
        enn_q_prior=q0_enn[current_node],
        severity=severity,
        t_max=t_max
    )
    
    print(f"  t_max: {t_max} (based on severity)")
    print(f"  Converged values:")
    print(f"  q range: [{q_fusion.min():.3f}, {q_fusion.max():.3f}]")
    print(f"  q[current]: {q_fusion[current_node]:.3f}")
    print(f"  q[goal]: {q_fusion[goal_node]:.3f}")
    
    # 5. Visualize results
    print("\nCommittor field (5x5 grid):")
    for i in range(5):
        row = []
        for j in range(5):
            idx = i * 5 + j
            val = q_fusion[idx]
            if idx == current_node:
                row.append(f"[{val:.2f}]")  # Current position
            elif idx == goal_node:
                row.append(f"<{val:.2f}>")  # Goal
            else:
                row.append(f" {val:.2f} ")
        print("  ".join(row))
    
    # 6. Action selection
    current_neighbors = []
    for edge in edges:
        if int(edge[0]) == current_node:
            neighbor_id = int(edge[1])
            current_neighbors.append((neighbor_id, q_fusion[neighbor_id]))
    
    if current_neighbors:
        best_neighbor = max(current_neighbors, key=lambda x: x[1])
        print(f"\nBest next node: {best_neighbor[0]} (q={best_neighbor[1]:.3f})")
        print(f"Direction: {nodes[best_neighbor[0]] - nodes[current_node]}")
    
    print("\n✅ ENN → Fusion Alpha pipeline working!")


if __name__ == "__main__":
    main()
//==============================================================================
// FILE: ./python/export_graph.py
//==============================================================================
#!/usr/bin/env python3
"""Export graph spec and serialized graph for reproducibility."""

import argparse
import json
import numpy as np
from graph_builder import (
    HumanoidMazeGraphBuilder,
    AntSoccerGraphBuilder,
    PuzzleGraphBuilder,
)

BUILDERS = {
    "humanoid": HumanoidMazeGraphBuilder,
    "ant": AntSoccerGraphBuilder,
    "puzzle": PuzzleGraphBuilder,
}


def parse_array(arg: str) -> np.ndarray:
    return np.asarray([float(x) for x in arg.split(',')], dtype=np.float32)


def main() -> None:
    parser = argparse.ArgumentParser(description="Export graph spec + graph JSON")
    parser.add_argument("builder", choices=BUILDERS.keys())
    parser.add_argument("--current", required=True, help="Current state vector, comma-separated")
    parser.add_argument("--goal", required=False, help="Goal state vector, comma-separated")
    parser.add_argument("--spec-out", required=True)
    parser.add_argument("--graph-out", required=True)
    parser.add_argument("--params", nargs="*", help="key=value overrides")
    args = parser.parse_args()

    params = {}
    if args.params:
        for item in args.params:
            key, value = item.split('=', 1)
            try:
                params[key] = float(value)
            except ValueError:
                params[key] = value

    builder_cls = BUILDERS[args.builder]
    builder = builder_cls(**{k: int(v) if isinstance(v, float) and v.is_integer() else v for k, v in params.items()})
    current = parse_array(args.current)
    goal = parse_array(args.goal) if args.goal else None

    nodes, edges, _, _, spec, graph = builder.build_graph_with_artifacts(current, goal)

    # Attach simple stats for downstream mapping (state_bounds, n_bins)
    try:
        x = np.asarray(nodes, dtype=np.float32)
        x_min = float(np.min(x[:, 0]))
        x_max = float(np.max(x[:, 0]))
        n_bins = int(len(nodes))
        graph.setdefault('stats', {})
        graph['stats']['state_bounds'] = [[x_min], [x_max]]
        graph['stats']['n_bins'] = n_bins
    except Exception:
        pass

    with open(args.spec_out, "w", encoding="utf-8") as fh:
        json.dump(spec, fh, indent=2)
    with open(args.graph_out, "w", encoding="utf-8") as fh:
        json.dump(graph, fh, indent=2)
    print(f"Wrote spec to {args.spec_out} and graph to {args.graph_out}")


if __name__ == "__main__":
    main()

//==============================================================================
// FILE: ./python/fit_fused_calibrator.py
//==============================================================================
#!/usr/bin/env python3
"""
Fit a calibrator for FusionAlpha propagated scores (q_fused).

Inputs: CSV with either columns (propagated_q,target) or (score,target).
Outputs: JSON with Platt parameters and calibration metrics (ECE/Brier/curve).
"""

from __future__ import annotations

import argparse
import csv
import json
from typing import List, Tuple

import numpy as np


def load_score_target(csv_path: str) -> Tuple[np.ndarray, np.ndarray]:
    scores: List[float] = []
    targets: List[float] = []
    with open(csv_path, 'r', newline='') as fh:
        reader = csv.DictReader(fh)
        fields = set(reader.fieldnames or [])
        score_key = 'propagated_q' if 'propagated_q' in fields else ('score' if 'score' in fields else None)
        if score_key is None or 'target' not in fields:
            raise ValueError("CSV must include ('propagated_q' or 'score') and 'target'")
        for row in reader:
            try:
                scores.append(float(row[score_key]))
                targets.append(float(row['target']))
            except Exception as exc:
                raise ValueError(f'Invalid row: {row}') from exc
    if not scores:
        raise ValueError('No rows loaded from CSV')
    return np.asarray(scores, dtype=np.float64), np.asarray(targets, dtype=np.float64)


def platt_fit(scores: np.ndarray, targets: np.ndarray, max_iter: int = 500, lr: float = 5e-3,
              tol: float = 1e-6) -> Tuple[float, float]:
    A = 0.0
    B = 0.0
    for _ in range(max_iter):
        z = np.clip(A * scores + B, -50.0, 50.0)
        p = 1.0 / (1.0 + np.exp(-z))
        error = p - targets
        grad_A = float(np.dot(error, scores) / len(scores))
        grad_B = float(np.sum(error) / len(scores))
        if max(abs(grad_A), abs(grad_B)) < tol:
            break
        A -= lr * grad_A
        B -= lr * grad_B
    return float(A), float(B)


def reliability_curve(probs: np.ndarray, targets: np.ndarray, bins: int):
    cuts = np.linspace(0.0, 1.0, bins + 1)
    buckets = []
    ece = 0.0
    for i in range(bins):
        lo = cuts[i]
        hi = cuts[i + 1]
        mask = (probs >= lo) & (probs <= hi if i == bins - 1 else probs < hi)
        if mask.sum() == 0:
            continue
        bucket_conf = float(probs[mask].mean())
        bucket_acc = float(targets[mask].mean())
        weight = float(mask.sum()) / len(probs)
        ece += weight * abs(bucket_acc - bucket_conf)
        buckets.append({
            'lower': float(lo),
            'upper': float(hi),
            'confidence': bucket_conf,
            'accuracy': bucket_acc,
            'weight': weight,
        })
    return buckets, float(ece)


def brier_score(probs: np.ndarray, targets: np.ndarray) -> float:
    return float(np.mean((probs - targets) ** 2))


def main() -> None:
    p = argparse.ArgumentParser(description='Fit calibrator for FusionAlpha propagated scores')
    p.add_argument('csv', help='CSV with propagated_q/score and target columns')
    p.add_argument('out', help='Output JSON calibrator path')
    p.add_argument('--bins', type=int, default=10)
    p.add_argument('--calibrator-id', default='fused_platt')
    args = p.parse_args()

    scores, targets = load_score_target(args.csv)
    A, B = platt_fit(scores, targets)
    z = np.clip(A * scores + B, -50.0, 50.0)
    probs = 1.0 / (1.0 + np.exp(-z))

    curve, ece = reliability_curve(probs, targets, args.bins)
    brier = brier_score(probs, targets)

    payload = {
        'schema': 'fusion_fused_calibrator_v1',
        'method': 'platt',
        'calibrator_id': args.calibrator_id,
        'params': {'A': A, 'B': B},
        'metrics': {'ece': ece, 'brier': brier, 'bins': curve},
        'fit_on': {'path': args.csv, 'n': int(len(scores))},
    }
    with open(args.out, 'w', encoding='utf-8') as fh:
        json.dump(payload, fh, indent=2)
    print(f'[OK] Wrote fused calibrator to {args.out}')


if __name__ == '__main__':
    main()


//==============================================================================
// FILE: ./python/fusion_alpha_demo.py
//==============================================================================
#!/usr/bin/env python3
"""
FusionAlpha Python Demo

Demonstrates the current Python bindings (`simple_propagate` and `create_simple_graph`).
Builds a few small graphs directly in Python and runs the committor propagation pipeline.
"""

import numpy as np
import os
import sys

# Add the shared library produced by cargo build -p fusion-bindings --release
sys.path.append(os.path.join(os.path.dirname(__file__), "..", "target", "release"))

try:
    import fusion_alpha as fa
except ImportError as exc:
    print(f"Failed to import fusion_alpha: {exc}")
    print("Build with: cargo build --release -p fusion-bindings")
    sys.exit(1)


def build_chain_graph(length: int = 3) -> tuple[np.ndarray, np.ndarray, int, int]:
    """Chain of `length` nodes equally spaced on the x-axis."""
    nodes = np.array([[float(x), 0.0] for x in range(length)], dtype=np.float32)
    edges = []
    for i in range(length - 1):
        edges.append([i, i + 1, 1.0])
        edges.append([i + 1, i, 1.0])
    edges = np.array(edges, dtype=np.float32)
    return nodes, edges, 0, length - 1


def build_grid_graph(width: int, height: int, cell_size: float = 1.0) -> tuple[np.ndarray, np.ndarray, int, int]:
    """Grid graph on a rectangular lattice."""
    nodes = []
    for j in range(height):
        for i in range(width):
            nodes.append([i * cell_size, j * cell_size])
    nodes = np.array(nodes, dtype=np.float32)
    edges = []
    def node_id(x: int, y: int) -> int:
        return y * width + x
    for y in range(height):
        for x in range(width):
            u = node_id(x, y)
            if x + 1 < width:
                v = node_id(x + 1, y)
                edges.append([u, v, 1.0])
                edges.append([v, u, 1.0])
            if y + 1 < height:
                v = node_id(x, y + 1)
                edges.append([u, v, 1.0])
                edges.append([v, u, 1.0])
    edges = np.array(edges, dtype=np.float32)
    return nodes, edges, node_id(0, 0), node_id(width - 1, height - 1)


def describe_neighbors(edges: np.ndarray, node: int, q_values: np.ndarray) -> str:
    neighbors = []
    for u, v, w in edges:
        if int(u) == node:
            neighbors.append((int(v), float(w)))
    neighbors.sort(key=lambda item: item[0])
    lines = []
    for v, weight in neighbors:
        lines.append(f"  {v}: q={q_values[v]:.3f}, weight={weight:.2f}")
    return "\n".join(lines) if lines else "  (no outgoing edges)"


def run_demo(title: str, nodes: np.ndarray, edges: np.ndarray, current: int, goal: int, severity: float) -> None:
    print(f"\n=== {title} ===")
    print(f"Nodes: {nodes.shape[0]}, Edges: {edges.shape[0]}")
    print(f"Current node: {current}, Goal node: {goal}")
    q_values = fa.simple_propagate(
        nodes=nodes,
        edges=edges,
        goal_node=goal,
        current_node=current,
        enn_q_prior=0.6,
        severity=severity,
        t_max=60,
    )
    print(f"q[current]={q_values[current]:.3f}, q[goal]={q_values[goal]:.3f}")
    print("Neighbors of current node:")
    print(describe_neighbors(edges, current, q_values))


def demo_risk_sensitive(nodes: np.ndarray, edges: np.ndarray, current: int, goal: int) -> None:
    print("\n=== Risk-Sensitive Comparison ===")
    conservative = fa.simple_propagate(nodes, edges, goal, current, 0.6, severity=0.9, t_max=60)
    aggressive = fa.simple_propagate(nodes, edges, goal, current, 0.6, severity=0.1, t_max=60)
    print(f"Conservative q[current]={conservative[current]:.3f}")
    print(f"Aggressive   q[current]={aggressive[current]:.3f}")


def main():
    chain_nodes, chain_edges, c0, g0 = build_chain_graph(length=3)
    run_demo("Chain Graph", chain_nodes, chain_edges, c0, g0, severity=0.5)

    grid_nodes, grid_edges, c1, g1 = build_grid_graph(width=4, height=4, cell_size=1.0)
    run_demo("Grid Graph", grid_nodes, grid_edges, c1, g1, severity=0.3)
    demo_risk_sensitive(grid_nodes, grid_edges, c1, g1)

if __name__ == "__main__":
    main()

//==============================================================================
// FILE: ./python/graph_builder.py
//==============================================================================
#!/usr/bin/env python3
"""
Graph builders for OGBench environments
Creates local k-NN graphs around current state for Fusion Alpha
"""

import numpy as np
from typing import Dict, Tuple, List, Optional
from sklearn.neighbors import NearestNeighbors
import json
import hashlib


def _hash_buffer(buffer: List[np.ndarray]) -> str:
    if not buffer:
        return "empty"
    hasher = hashlib.blake2s()
    for state in buffer:
        hasher.update(np.asarray(state, dtype=np.float32).tobytes())
    return hasher.hexdigest()


def _serialize_graph(nodes: np.ndarray, edges: np.ndarray) -> Dict:
    adjacency: Dict[int, List[Dict[str, float]]] = {}
    for u, v, w in edges:
        adjacency.setdefault(int(u), []).append({"v": int(v), "w": float(w)})
    for neighbors in adjacency.values():
        neighbors.sort(key=lambda item: (item["v"], item["w"]))
    return {
        "nodes": nodes.tolist(),
        "edges": [
            {"u": int(u), "v": int(v), "w": float(w)} for u, v, w in edges
        ],
        "adjacency": adjacency,
    }


class StateGraphBuilder:
    """Base class for building state-space graphs"""
    
    def __init__(self, k_neighbors: int = 10, max_nodes: int = 100):
        self.k_neighbors = k_neighbors
        self.max_nodes = max_nodes
        self.state_buffer = []  # Replay buffer of visited states
        
    def add_state(self, state: np.ndarray):
        """Add state to replay buffer"""
        self.state_buffer.append(state.copy())
        # Keep buffer size reasonable
        if len(self.state_buffer) > 10000:
            self.state_buffer = self.state_buffer[-5000:]
    
    def _finalize_edges(self, edges: List[List[float]]) -> np.ndarray:
        if not edges:
            return np.zeros((0, 3), dtype=np.float32)
        edges_sorted = sorted(edges, key=lambda e: (int(e[0]), int(e[1]), float(e[2])))
        return np.array(edges_sorted, dtype=np.float32)
    
    def build_graph(self, current_state: np.ndarray, 
                   goal_state: Optional[np.ndarray] = None) -> Tuple[np.ndarray, np.ndarray, int, int]:
        """
        Build k-NN graph around current state
        
        Returns:
            nodes: (N, d) array of states
            edges: (M, 3) array of [i, j, weight]
            current_idx: index of current state in nodes
            goal_idx: index of goal state in nodes (-1 if no goal)
        """
        raise NotImplementedError

    def build_graph_with_artifacts(
        self,
        current_state: np.ndarray,
        goal_state: Optional[np.ndarray] = None,
    ) -> Tuple[np.ndarray, np.ndarray, int, int, Dict, Dict]:
        nodes, edges, current_idx, goal_idx = self.build_graph(current_state, goal_state)
        spec = {
            "builder_type": self.__class__.__name__,
            "params": self._builder_params(),
            "buffer_hash": _hash_buffer(self.state_buffer),
            "node_dim": int(nodes.shape[1]),
        }
        graph = _serialize_graph(nodes, edges)
        graph["current_node"] = current_idx
        graph["goal_node"] = goal_idx
        return nodes, edges, current_idx, goal_idx, spec, graph

    def _builder_params(self) -> Dict:
        return {
            "k_neighbors": self.k_neighbors,
            "max_nodes": self.max_nodes,
        }


class HumanoidMazeGraphBuilder(StateGraphBuilder):
    """Graph builder for Humanoid/Ant maze environments"""
    
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        self.position_dim = 2  # (x, y) position
        
    def build_graph(self, current_state: np.ndarray, 
                   goal_state: Optional[np.ndarray] = None) -> Tuple[np.ndarray, np.ndarray, int, int]:
        
        # Extract position from full state
        current_pos = current_state[:self.position_dim]
        
        # Start with current state
        nodes = [current_state]
        node_positions = [current_pos]
        current_idx = 0
        
        # Add goal if provided
        goal_idx = -1
        if goal_state is not None:
            nodes.append(goal_state)
            node_positions.append(goal_state[:self.position_dim])
            goal_idx = 1
        
        # Add nearby states from buffer
        if len(self.state_buffer) > 0:
            buffer_positions = np.array([s[:self.position_dim] for s in self.state_buffer])
            
            # Find k nearest neighbors deterministically
            nbrs = NearestNeighbors(
                n_neighbors=min(self.k_neighbors, len(buffer_positions)),
                algorithm='brute',
                metric='euclidean',
                n_jobs=1
            )
            nbrs.fit(buffer_positions)
            
            _, indices = nbrs.kneighbors([current_pos])
            
            for idx in sorted(indices[0]):
                if len(nodes) < self.max_nodes:
                    nodes.append(self.state_buffer[idx])
                    node_positions.append(buffer_positions[idx])
        
        # Convert to arrays
        nodes = np.array(nodes, dtype=np.float32)
        node_positions = np.array(node_positions, dtype=np.float32)
        
        # Build edges based on position distance
        edges = []
        n_nodes = len(nodes)
        
        for i in range(n_nodes):
            # Find k nearest neighbors for each node
            if n_nodes > 1:
                distances = np.linalg.norm(node_positions - node_positions[i], axis=1)
                nearest = np.argsort(distances)[1:self.k_neighbors+1]  # Exclude self
                
                for j in nearest:
                    if j < n_nodes:
                        # Weight inversely proportional to distance
                        dist = distances[j]
                        weight = np.exp(-dist / 2.0)  # Gaussian kernel
                        edges.append([i, j, weight])
                        edges.append([j, i, weight])  # Bidirectional
        
        edges = self._finalize_edges(edges)
        
        return nodes, edges, current_idx, goal_idx

    def _builder_params(self) -> Dict:
        return {
            **super()._builder_params(),
            "position_dim": self.position_dim,
        }


class AntSoccerGraphBuilder(StateGraphBuilder):
    """Graph builder for AntSoccer - focuses on ball dynamics"""
    
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        self.ant_pos_dim = 2
        self.ball_pos_dim = 2
        
    def build_graph(self, current_state: np.ndarray, 
                   goal_state: Optional[np.ndarray] = None) -> Tuple[np.ndarray, np.ndarray, int, int]:
        
        # Extract positions (ant_x, ant_y, ball_x, ball_y, ...)
        current_ball_pos = current_state[2:4]  # Ball position
        
        # Build graph around ball positions
        nodes = [current_state]
        ball_positions = [current_ball_pos]
        current_idx = 0
        
        # Add goal (typically a target ball position)
        goal_idx = -1
        if goal_state is not None:
            nodes.append(goal_state)
            ball_positions.append(goal_state[2:4])
            goal_idx = 1
        
        # Sample reachable ball positions
        # Create a grid of potential ball positions
        grid_size = int(np.sqrt(self.max_nodes))
        x_range = np.linspace(current_ball_pos[0] - 2, current_ball_pos[0] + 2, grid_size)
        y_range = np.linspace(current_ball_pos[1] - 2, current_ball_pos[1] + 2, grid_size)
        
        for x in x_range:
            for y in y_range:
                if len(nodes) < self.max_nodes:
                    # Create synthetic state with ball at (x, y)
                    new_state = current_state.copy()
                    new_state[2] = x
                    new_state[3] = y
                    nodes.append(new_state)
                    ball_positions.append([x, y])
        
        nodes = np.array(nodes, dtype=np.float32)
        ball_positions = np.array(ball_positions, dtype=np.float32)
        
        # Build edges based on ball reachability
        edges = []
        n_nodes = len(nodes)
        
        for i in range(n_nodes):
            distances = np.linalg.norm(ball_positions - ball_positions[i], axis=1)
            nearest = np.argsort(distances)[1:self.k_neighbors+1]
            
            for j in nearest:
                if j < n_nodes:
                    dist = distances[j]
                    # Prefer small moves
                    weight = np.exp(-dist / 0.5)
                    edges.append([i, j, weight])
        
        edges = self._finalize_edges(edges)
        
        return nodes, edges, current_idx, goal_idx

    def _builder_params(self) -> Dict:
        return {
            **super()._builder_params(),
            "ant_pos_dim": self.ant_pos_dim,
            "ball_pos_dim": self.ball_pos_dim,
            "grid_span": 4.0,
        }


class PuzzleGraphBuilder(StateGraphBuilder):
    """Graph builder for Puzzle - uses exact toggle dynamics"""
    
    def __init__(self, width: int = 5, height: int = 4, **kwargs):
        super().__init__(**kwargs)
        self.width = width
        self.height = height
        self.n_lights = width * height
        
    def _get_button_mask(self, button: int) -> int:
        """Get toggle mask for button press (cross pattern)"""
        row = button // self.width
        col = button % self.width
        
        mask = 1 << button  # Button itself
        
        # Cross neighbors
        neighbors = [
            (row-1, col), (row+1, col),  # up, down
            (row, col-1), (row, col+1),  # left, right
        ]
        
        for r, c in neighbors:
            if 0 <= r < self.height and 0 <= c < self.width:
                neighbor_id = r * self.width + c
                mask |= (1 << neighbor_id)
        
        return mask
    
    def _state_to_config(self, state: np.ndarray) -> int:
        """Convert observation vector to bit configuration"""
        config = 0
        for i in range(self.n_lights):
            if state[i] > 0.5:
                config |= (1 << i)
        return config
    
    def _config_to_state(self, config: int, template: np.ndarray) -> np.ndarray:
        """Convert bit configuration to state vector"""
        state = template.copy()
        for i in range(self.n_lights):
            state[i] = 1.0 if (config & (1 << i)) else 0.0
        return state
    
    def build_graph(self, current_state: np.ndarray, 
                   goal_state: Optional[np.ndarray] = None) -> Tuple[np.ndarray, np.ndarray, int, int]:
        
        current_config = self._state_to_config(current_state)
        goal_config = self._state_to_config(goal_state) if goal_state is not None else None
        
        # BFS to build local graph
        from collections import deque
        
        nodes = [current_state]
        configs = [current_config]
        config_to_idx = {current_config: 0}
        current_idx = 0
        
        queue = deque([(current_config, 0)])  # (config, depth)
        max_depth = 3  # Limited depth for tractability
        
        while queue and len(nodes) < self.max_nodes:
            config, depth = queue.popleft()
            
            if depth >= max_depth:
                continue
            
            # Try all button presses
            for button in range(self.n_lights):
                mask = self._get_button_mask(button)
                next_config = config ^ mask
                
                if next_config not in config_to_idx:
                    idx = len(nodes)
                    config_to_idx[next_config] = idx
                    configs.append(next_config)
                    nodes.append(self._config_to_state(next_config, current_state))
                    
                    if depth + 1 < max_depth:
                        queue.append((next_config, depth + 1))
        
        # Add goal if not already present
        goal_idx = -1
        if goal_config is not None and goal_config not in config_to_idx:
            goal_idx = len(nodes)
            nodes.append(goal_state)
            configs.append(goal_config)
            config_to_idx[goal_config] = goal_idx
        elif goal_config is not None:
            goal_idx = config_to_idx[goal_config]
        
        nodes = np.array(nodes, dtype=np.float32)
        
        # Build edges based on button presses
        edges = []
        for i, config in enumerate(configs):
            for button in range(self.n_lights):
                mask = self._get_button_mask(button)
                next_config = config ^ mask
                
                if next_config in config_to_idx:
                    j = config_to_idx[next_config]
                    # All button presses have equal weight
                    edges.append([i, j, 1.0])
        
        edges = self._finalize_edges(edges)
        
        return nodes, edges, current_idx, goal_idx

    def _builder_params(self) -> Dict:
        return {
            **super()._builder_params(),
            "width": self.width,
            "height": self.height,
            "n_lights": self.n_lights,
        }


# Factory function
def create_graph_builder(env_name: str, **kwargs) -> StateGraphBuilder:
    """Create appropriate graph builder for environment"""
    
    env_lower = env_name.lower()
    
    if "humanoid" in env_lower or "ant" in env_lower and "maze" in env_lower:
        return HumanoidMazeGraphBuilder(**kwargs)
    elif "soccer" in env_lower:
        return AntSoccerGraphBuilder(**kwargs)
    elif "puzzle" in env_lower:
        return PuzzleGraphBuilder(**kwargs)
    else:
        raise ValueError(f"Unknown environment: {env_name}")


# Example usage
if __name__ == "__main__":
    print("Testing graph builders...")
    
    # Test HumanoidMaze
    print("\n=== HumanoidMaze ===")
    builder = HumanoidMazeGraphBuilder(k_neighbors=5, max_nodes=20)
    
    # Add some states to buffer
    for _ in range(50):
        state = np.random.randn(10)  # Mock state
        builder.add_state(state)
    
    current = np.array([1.0, 2.0] + [0.0] * 8)  # Position at (1, 2)
    goal = np.array([5.0, 5.0] + [0.0] * 8)     # Goal at (5, 5)
    
    nodes, edges, curr_idx, goal_idx = builder.build_graph(current, goal)
    print(f"Nodes: {len(nodes)}, Edges: {len(edges)}")
    print(f"Current: {curr_idx}, Goal: {goal_idx}")
    
    # Test Puzzle
    print("\n=== Puzzle ===")
    builder = PuzzleGraphBuilder(width=5, height=4, max_nodes=50)
    
    current = np.zeros(20)
    current[5] = 1.0  # One light on
    
    goal = np.zeros(20)
    goal[10] = 1.0
    goal[15] = 1.0  # Two different lights on
    
    nodes, edges, curr_idx, goal_idx = builder.build_graph(current, goal)
    print(f"Nodes: {len(nodes)}, Edges: {len(edges)}")
    print(f"Current: {curr_idx}, Goal: {goal_idx}")
    
    print("\n✅ Graph builders working!")

//==============================================================================
// FILE: ./python/ingest_enn.py
//==============================================================================
#!/usr/bin/env python3
"""FusionAlpha ingest stub - consumes ENN artifact and emits decision receipt.

Phase 2c: Close the verification loop
- Read ENN output artifact
- Apply simple threshold decision
- Emit FusionDecisionReceipt with cryptographic binding

This completes the chain: BICEP receipt -> ENN receipt -> FusionAlpha receipt
Even if decisions are dumb, the chain is real.

Usage:
    python ingest_enn.py --enn-artifact <path> --output <receipt_path>
"""
from __future__ import annotations

import argparse
import csv
import hashlib
import json
import sys
from dataclasses import dataclass, asdict
from datetime import datetime, timezone
from pathlib import Path
from typing import Any, Optional

# Import from capsule if available, otherwise define locally
try:
    from bef_zk.capsule.features_sidecar import (
        ENNOutputArtifact,
        FusionDecisionReceipt,
        compute_features_hash,
        hash_canonical,
    )
except ImportError:
    # Standalone definitions for testing
    def hash_canonical(obj: Any) -> str:
        data = json.dumps(obj, sort_keys=True, separators=(',', ':')).encode('utf-8')
        return hashlib.sha256(data).hexdigest()

    def compute_features_hash(path: Path) -> str:
        hasher = hashlib.sha256()
        with open(path, 'rb') as f:
            for chunk in iter(lambda: f.read(8192), b''):
                hasher.update(chunk)
        return hasher.hexdigest()

    @dataclass
    class ENNOutputArtifact:
        schema: str = "enn_output_v1"
        input_features_shard_hash: str = ""
        input_sidecar_hash: str = ""
        trace_anchor_head: str = ""
        enn_config_hash: str = ""
        enn_code_hash: str = ""
        enn_version: str = ""
        predictions_hash: str = ""
        predictions_row_count: int = 0
        embeddings_hash: str = ""
        created_at: str = ""

        @classmethod
        def load(cls, path: Path) -> 'ENNOutputArtifact':
            with open(path) as f:
                data = json.load(f)
            return cls(**{k: v for k, v in data.items() if k in cls.__dataclass_fields__})

    @dataclass
    class FusionDecisionReceipt:
        schema: str = "fusion_decision_v1"
        enn_artifact_hash: str = ""
        enn_predictions_hash: str = ""
        bicep_trace_anchor_head: str = ""
        bicep_manifest_hash: str = ""
        decisions_hash: str = ""
        decisions_count: int = 0
        decision_method: str = ""
        created_at: str = ""
        fusion_version: str = ""

        def to_dict(self) -> dict:
            d = asdict(self)
            d["receipt_hash"] = hash_canonical(d)
            return d

        def save(self, path: Path) -> None:
            with open(path, 'w') as f:
                json.dump(self.to_dict(), f, indent=2)


FUSION_VERSION = "0.1.0"


def load_predictions(predictions_path: Path) -> list[float]:
    """Load predictions from CSV file."""
    predictions = []

    with open(predictions_path) as f:
        reader = csv.DictReader(f)
        for row in reader:
            # Try common column names
            for col in ['prediction', 'pred', 'q_pred', 'output']:
                if col in row:
                    predictions.append(float(row[col]))
                    break

    return predictions


def apply_threshold(predictions: list[float], threshold: float = 0.5) -> list[int]:
    """Simple threshold decision: pred > threshold -> 1, else 0."""
    return [1 if p > threshold else 0 for p in predictions]


def create_decision_receipt(
    enn_artifact: ENNOutputArtifact,
    predictions: list[float],
    decisions: list[int],
    decision_method: str,
    bicep_manifest_hash: str = "",
) -> FusionDecisionReceipt:
    """Create decision receipt with cryptographic binding."""
    # Hash decisions
    decisions_data = json.dumps(decisions, sort_keys=True, separators=(',', ':')).encode('utf-8')
    decisions_hash = hashlib.sha256(decisions_data).hexdigest()

    # Compute ENN artifact hash
    enn_artifact_hash = hash_canonical(asdict(enn_artifact))

    receipt = FusionDecisionReceipt(
        enn_artifact_hash=enn_artifact_hash,
        enn_predictions_hash=enn_artifact.predictions_hash,
        bicep_trace_anchor_head=enn_artifact.trace_anchor_head,
        bicep_manifest_hash=bicep_manifest_hash,
        decisions_hash=decisions_hash,
        decisions_count=len(decisions),
        decision_method=decision_method,
        created_at=datetime.now(timezone.utc).isoformat(),
        fusion_version=FUSION_VERSION,
    )

    return receipt


def main():
    parser = argparse.ArgumentParser(
        description="FusionAlpha ingest: consume ENN artifact, emit decision receipt"
    )
    parser.add_argument(
        "--enn-artifact", "-e",
        type=str,
        help="Path to ENN output artifact JSON"
    )
    parser.add_argument(
        "--predictions", "-p",
        type=str,
        help="Path to predictions CSV (if no artifact)"
    )
    parser.add_argument(
        "--threshold", "-t",
        type=float,
        default=0.5,
        help="Decision threshold (default: 0.5)"
    )
    parser.add_argument(
        "--output", "-o",
        type=str,
        default="fusion_decision_receipt.json",
        help="Output path for decision receipt"
    )
    parser.add_argument(
        "--bicep-manifest-hash",
        type=str,
        default="",
        help="BICEP manifest hash (for transitive binding)"
    )

    args = parser.parse_args()

    # Load ENN artifact or create stub
    if args.enn_artifact:
        artifact_path = Path(args.enn_artifact)
        if not artifact_path.exists():
            print(f"ERROR: ENN artifact not found: {artifact_path}", file=sys.stderr)
            sys.exit(1)
        enn_artifact = ENNOutputArtifact.load(artifact_path)
        print(f"[FusionAlpha] Loaded ENN artifact from {artifact_path}")
    else:
        # Create stub artifact
        enn_artifact = ENNOutputArtifact(
            enn_version="unknown",
            created_at=datetime.now(timezone.utc).isoformat(),
        )

    # Load predictions
    if args.predictions:
        pred_path = Path(args.predictions)
        if not pred_path.exists():
            print(f"ERROR: Predictions file not found: {pred_path}", file=sys.stderr)
            sys.exit(1)
        predictions = load_predictions(pred_path)
        enn_artifact.predictions_hash = compute_features_hash(pred_path)
        enn_artifact.predictions_row_count = len(predictions)
        print(f"[FusionAlpha] Loaded {len(predictions)} predictions from {pred_path}")
    elif args.enn_artifact:
        print("[FusionAlpha] No predictions file provided, using artifact metadata only")
        predictions = []
    else:
        print("ERROR: Either --enn-artifact or --predictions required", file=sys.stderr)
        sys.exit(1)

    # Apply threshold decision
    decision_method = f"threshold_{args.threshold}"
    decisions = apply_threshold(predictions, args.threshold)

    if decisions:
        positive_rate = sum(decisions) / len(decisions)
        print(f"[FusionAlpha] Decisions: {len(decisions)} total, {sum(decisions)} positive ({positive_rate:.1%})")
    else:
        print("[FusionAlpha] No decisions made (empty predictions)")

    # Create receipt
    receipt = create_decision_receipt(
        enn_artifact=enn_artifact,
        predictions=predictions,
        decisions=decisions,
        decision_method=decision_method,
        bicep_manifest_hash=args.bicep_manifest_hash,
    )

    # Save receipt
    output_path = Path(args.output)
    receipt.save(output_path)

    print(f"[FusionAlpha] Decision receipt saved to {output_path}")
    print(f"[FusionAlpha] Receipt hash: {hash_canonical(receipt.to_dict())[:16]}...")

    # Print chain summary
    print("\n=== Verification Chain Summary ===")
    if enn_artifact.trace_anchor_head:
        print(f"  BICEP trace_anchor_head: {enn_artifact.trace_anchor_head[:16]}...")
    if args.bicep_manifest_hash:
        print(f"  BICEP manifest_hash: {args.bicep_manifest_hash[:16]}...")
    print(f"  ENN predictions_hash: {enn_artifact.predictions_hash[:16] if enn_artifact.predictions_hash else 'N/A'}...")
    print(f"  Fusion decisions_hash: {receipt.decisions_hash[:16]}...")
    print("  Chain: BICEP -> ENN -> FusionAlpha (complete)")


if __name__ == "__main__":
    main()

//==============================================================================
// FILE: ./python/ogbench_integration.py
//==============================================================================
#!/usr/bin/env python3
"""
Example wrapper showing how to embed FusionAlpha's simple Python bindings into a planner class.
This version mirrors what an OGBench integration would do without relying on the removed PyGraph APIs.
"""

from dataclasses import dataclass
from typing import Tuple, Dict
import numpy as np
import os
import sys

sys.path.append(os.path.join(os.path.dirname(__file__), "..", "target", "release"))

try:
    import fusion_alpha as fa
except ImportError as exc:
    print(f"Warning: fusion_alpha bindings not available: {exc}")
    print("Build with: cargo build --release -p fusion-bindings")
    fa = None


def build_grid_graph(width: int, height: int, cell_size: float = 1.0) -> Tuple[np.ndarray, np.ndarray]:
    nodes = []
    for j in range(height):
        for i in range(width):
            nodes.append([i * cell_size, j * cell_size])
    nodes = np.array(nodes, dtype=np.float32)

    edges = []
    def node_id(x: int, y: int) -> int:
        return y * width + x

    for y in range(height):
        for x in range(width):
            u = node_id(x, y)
            if x + 1 < width:
                v = node_id(x + 1, y)
                edges.append([u, v, 1.0])
                edges.append([v, u, 1.0])
            if y + 1 < height:
                v = node_id(x, y + 1)
                edges.append([u, v, 1.0])
                edges.append([v, u, 1.0])
    edges = np.array(edges, dtype=np.float32)
    return nodes, edges


def pick_next_node(edges: np.ndarray, q_values: np.ndarray, current: int) -> int:
    candidates = []
    for u, v, _ in edges:
        if int(u) == current:
            candidates.append(int(v))
    if not candidates:
        return current
    candidates.sort()
    best = candidates[0]
    best_q = q_values[best]
    for nid in candidates[1:]:
        if q_values[nid] > best_q + 1e-9 or (abs(q_values[nid] - best_q) <= 1e-9 and nid < best):
            best = nid
            best_q = q_values[nid]
    return best


@dataclass
class GridPlanner:
    width: int = 6
    height: int = 6
    cell_size: float = 1.0
    severity: float = 0.4

    def plan_action(self, obs: Dict[str, float], goal: Dict[str, float]) -> Tuple[int, int, np.ndarray]:
        if fa is None:
            raise RuntimeError("fusion_alpha bindings not available")
        nodes, edges = build_grid_graph(self.width, self.height, self.cell_size)

        def nearest(pos: Tuple[float, float]) -> int:
            dists = np.linalg.norm(nodes - np.array(pos, dtype=np.float32), axis=1)
            return int(np.argmin(dists))

        current_node = nearest((obs['x'], obs['y']))
        goal_node = nearest((goal['x'], goal['y']))

        q_values = fa.simple_propagate(
            nodes=nodes,
            edges=edges,
            goal_node=goal_node,
            current_node=current_node,
            enn_q_prior=0.6,
            severity=self.severity,
            t_max=80,
        )
        next_node = pick_next_node(edges, q_values, current_node)
        action = nodes[next_node] - nodes[current_node]
        return current_node, next_node, action


def main():
    planner = GridPlanner(width=8, height=8, cell_size=0.5)
    obs = {'x': 0.5, 'y': 0.5}
    goal = {'x': 3.5, 'y': 3.5}
    current, nxt, action = planner.plan_action(obs, goal)
    print(f"Current node: {current}, Next node: {nxt}, Suggested displacement: {action}")


if __name__ == "__main__":
    main()

//==============================================================================
// FILE: ./python/run_fusion_on_enn.py
//==============================================================================
#!/usr/bin/env python3
"""
FusionAlpha Integration Script

Reads ENN predictions from CSV, builds a k-NN graph, and runs global committor propagation.
"""

import sys
import os
import pandas as pd
import numpy as np
from sklearn.neighbors import NearestNeighbors
import matplotlib.pyplot as plt
from matplotlib.tri import Triangulation

# Add shared library path
sys.path.append(os.path.join(os.path.dirname(__file__), "..", "target", "release"))

try:
    import fusion_alpha as fa
except ImportError as exc:
    print(f"Failed to import fusion_alpha: {exc}")
    print("Build with: cd FusionAlpha && cargo build --release -p fusion-bindings")
    sys.exit(1)

def main():
    if len(sys.argv) < 2:
        print("Usage: python run_fusion_on_enn.py <enn_output.csv>")
        sys.exit(1)

    csv_path = sys.argv[1]
    print(f"Loading {csv_path}...")
    
    # Load ENN output
    df = pd.read_csv(csv_path)
    
    # Load original data to get X back
    original_csv = "double_well_data_fixed.csv"
    if not os.path.exists(original_csv):
        print(f"Error: Original data {original_csv} needed to recover X coordinates.")
        sys.exit(1)
        
    print(f"Loading original data {original_csv} to merge coordinates...")
    df_orig = pd.read_csv(original_csv)
    
    # Merge on sequence_id
    df = pd.merge(df, df_orig[['sequence_id', 'state_0']], on='sequence_id', how='left')
    
    # Now we have state_0 (X) and state_mean (Y)
    coords = df[['state_0', 'state_mean']].to_numpy().astype(np.float32)
    q_enn = df['q_pred'].to_numpy().astype(np.float32)
    
    # Confidence from variance
    variance = df['state_std'].to_numpy().astype(np.float32)
    epsilon = 1e-4
    confidence = 1.0 / (variance + epsilon)
    confidence = np.clip(confidence, 0.1, 1000.0) 
    
    print(f"Building k-NN graph for {len(coords)} nodes...")
    k = 10
    nbrs = NearestNeighbors(n_neighbors=k+1, algorithm='ball_tree').fit(coords)
    distances, indices = nbrs.kneighbors(coords)
    
    # Build edge list [u, v, w]
    edges = []
    sigma_graph = 0.5 
    
    for i in range(len(coords)):
        for j_idx, idx in enumerate(indices[i]):
            if i == idx: continue 
            dist = distances[i][j_idx]
            w = np.exp(- (dist**2) / (sigma_graph**2))
            edges.append([i, idx, w])
            
    edges_array = np.array(edges, dtype=np.float32)
    
    print("Running FusionAlpha propagation...")
    
    priors = q_enn
    q_final = fa.propagate_field(
        nodes=coords,
        edges=edges_array,
        priors=priors,
        confidences=confidence.astype(np.float32),
        severity=0.0, 
        t_max=100
    )
    
    print("Propagation complete.")
    
    # Save result
    df['q_fusion'] = q_final
    out_file = "fusion_output.csv"
    df.to_csv(out_file, index=False)
    print(f"Saved fused results to {out_file}")
    
    # === PNG Plotting ===
    print("Generating fusion_surface.png...")
    x = df['state_0'].to_numpy()
    y = df['state_mean'].to_numpy()
    z = df['q_fusion'].to_numpy()
    
    tri = Triangulation(x, y)
    
    plt.figure(figsize=(10, 8))
    plt.tricontourf(tri, z, levels=np.linspace(0, 1, 21), cmap='viridis')
    plt.colorbar(label='Committor Probability (q)')
    plt.scatter(x, y, c=z, s=5, cmap='viridis', edgecolors='none', alpha=0.5)
    plt.title('FusionAlpha: Double Well Committor Field')
    plt.xlabel('X (State 0)')
    plt.ylabel('Y (State Mean)')
    plt.tight_layout()
    plt.savefig('fusion_surface.png', dpi=150)
    print("Saved fusion_surface.png")

if __name__ == "__main__":
    main()

//==============================================================================
// FILE: ./python/setup.py
//==============================================================================
#!/usr/bin/env python3
"""Setup script for Fusion Alpha Python package"""

from setuptools import setup, find_packages
import os

# Read README if available
readme_path = os.path.join(os.path.dirname(__file__), '..', 'README.md')
long_description = ""
if os.path.exists(readme_path):
    with open(readme_path, 'r', encoding='utf-8') as f:
        long_description = f.read()

setup(
    name="fusion-alpha",
    version="0.1.0", 
    description="Committor planning for reinforcement learning",
    long_description=long_description,
    long_description_content_type="text/markdown",
    author="Fusion Alpha Team",
    author_email="contact@fusionalpha.dev",
    url="https://github.com/your-org/fusion-alpha",
    packages=find_packages(),
    classifiers=[
        "Development Status :: 3 - Alpha",
        "Intended Audience :: Science/Research",
        "License :: OSI Approved :: MIT License",
        "Programming Language :: Python :: 3",
        "Programming Language :: Python :: 3.8",
        "Programming Language :: Python :: 3.9",
        "Programming Language :: Python :: 3.10",
        "Programming Language :: Python :: 3.11",
        "Programming Language :: Rust",
        "Topic :: Scientific/Engineering :: Artificial Intelligence",
        "Topic :: Scientific/Engineering :: Mathematics",
    ],
    python_requires=">=3.8",
    install_requires=[
        "numpy>=1.20.0",
        "scipy>=1.7.0",
    ],
    extras_require={
        "dev": [
            "pytest>=6.0",
            "black>=21.0",
            "flake8>=3.9",
            "mypy>=0.910",
        ],
        "benchmark": [
            "matplotlib>=3.0",
            "seaborn>=0.11",
            "pandas>=1.3",
        ],
        "ogbench": [
            "gym>=0.21",
            "mujoco-py>=2.1",
            "ogbench>=0.1",
        ],
    },
    package_data={
        "fusion_alpha": ["*.so", "*.pyd", "*.dll"],  # Include compiled binaries
    },
    include_package_data=True,
    zip_safe=False,
)
//==============================================================================
// FILE: ./python/simple_demo.py
//==============================================================================
#!/usr/bin/env python3
"""
Simple Fusion Alpha Demo
Tests the working Python bindings
"""

import numpy as np
import sys
import os

# Add the built library to path
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'target', 'release'))

try:
    import fusion_alpha as fa
except ImportError as e:
    print(f"Failed to import fusion_alpha: {e}")
    print("Make sure to build with: cargo build --release -p fusion-bindings")
    sys.exit(1)

def main():
    print("Simple Fusion Alpha Demo")
    
    # Create test graph
    nodes, edges, current_node, goal_node = fa.create_simple_graph()
    print(f"Created test graph with {nodes.shape[0]} nodes")
    print(f"Current node: {current_node}, Goal node: {goal_node}")
    
    # Test propagation
    enn_q_prior = 0.5
    severity = 0.7  # High uncertainty
    t_max = 50
    
    print(f"Running propagation with severity={severity}, t_max={t_max}")
    
    q_values = fa.simple_propagate(
        nodes=nodes,
        edges=edges, 
        goal_node=goal_node,
        current_node=current_node,
        enn_q_prior=enn_q_prior,
        severity=severity,
        t_max=t_max
    )
    
    print("Results:")
    for i, q in enumerate(q_values):
        print(f"  Node {i}: q = {q:.3f}")
        
    # Verify gradient
    assert q_values[goal_node] >= 0.99, "Goal should have q ≈ 1"
    assert q_values[0] < q_values[1] < q_values[2], "Should have increasing gradient"
    
    print("✅ Simple demo passed!")

if __name__ == "__main__":
    main()
//==============================================================================
// FILE: ./python/verify_graph_artifacts.py
//==============================================================================
#!/usr/bin/env python3
"""
Verify FusionAlpha graph artifacts for determinism and consistency.

Usage:
  Strict mode (recommended for replay):
    python verify_graph_artifacts.py --strict graph_v1.json

  Compare two graph JSONs (byte-level ordering not required, but sets must match):
    python verify_graph_artifacts.py --compare graph_v1_a.json graph_v1_b.json

Notes:
- Rebuild mode is intentionally omitted here unless a buffer snapshot and builder inputs
  are available; strict verification covers most reproducibility cases in CI.
"""

from __future__ import annotations

import argparse
import json
from typing import Dict, List, Tuple


def _is_sorted_neighbors(neighbors: List[Dict]) -> bool:
    last = (-1, float('-inf'))
    for item in neighbors:
        key = (int(item.get('v', -1)), float(item.get('w', 0.0)))
        if key < last:
            return False
        last = key
    return True


def _normalize_edges(edges: List[Dict]) -> List[Tuple[int, int, float]]:
    norm = []
    for e in edges:
        u = int(e.get('u', -1))
        v = int(e.get('v', -1))
        w = float(e.get('w', 0.0))
        norm.append((u, v, w))
    norm.sort(key=lambda t: (t[0], t[1], t[2]))
    return norm


def _adj_from_edges(n_nodes: int, edges: List[Tuple[int, int, float]]) -> Dict[int, List[Dict]]:
    adj: Dict[int, List[Dict]] = {i: [] for i in range(n_nodes)}
    for u, v, w in edges:
        if 0 <= u < n_nodes and 0 <= v < n_nodes:
            adj[u].append({"v": v, "w": w})
    for k in adj:
        adj[k].sort(key=lambda item: (int(item['v']), float(item['w'])))
    return adj


def verify_strict(graph_path: str) -> None:
    with open(graph_path, 'r', encoding='utf-8') as fh:
        graph = json.load(fh)

    nodes = graph.get('nodes')
    edges = graph.get('edges')
    adjacency = graph.get('adjacency')
    current = int(graph.get('current_node', -1))
    goal = int(graph.get('goal_node', -1))

    if not isinstance(nodes, list) or not isinstance(edges, list):
        raise AssertionError('nodes/edges must be lists')
    n_nodes = len(nodes)
    norm_edges = _normalize_edges(edges)
    if any(u < 0 or v < 0 or u >= n_nodes or v >= n_nodes for u, v, _ in norm_edges):
        raise AssertionError('Edge indices out of range')

    # Recompute adjacency and compare
    recomputed_adj = _adj_from_edges(n_nodes, norm_edges)
    if not isinstance(adjacency, dict):
        raise AssertionError('adjacency must be present and a dict')

    for key, nbrs in adjacency.items():
        k = int(key)
        if k < 0 or k >= n_nodes:
            raise AssertionError(f'adjacency key {k} out of range')
        if not isinstance(nbrs, list):
            raise AssertionError(f'adjacency for {k} must be list')
        if not _is_sorted_neighbors(nbrs):
            raise AssertionError(f'neighbors list for {k} is not sorted deterministically')
        # Compare with recomputed
        exp = recomputed_adj[k]
        if len(exp) != len(nbrs):
            raise AssertionError(f'neighbor count mismatch for {k}: {len(nbrs)} vs {len(exp)}')
        for a, b in zip(nbrs, exp):
            if int(a['v']) != int(b['v']) or abs(float(a['w']) - float(b['w'])) > 1e-12:
                raise AssertionError(f'neighbor mismatch for {k}: {a} vs {b}')

    # Index checks
    if current != -1 and not (0 <= current < n_nodes):
        raise AssertionError('current_node out of range')
    if goal != -1 and not (0 <= goal < n_nodes):
        raise AssertionError('goal_node out of range')

    print(f'[OK] Graph verification passed for {graph_path} (n_nodes={n_nodes}, n_edges={len(norm_edges)})')


def compare_graphs(a_path: str, b_path: str) -> None:
    with open(a_path, 'r', encoding='utf-8') as fa:
        a = json.load(fa)
    with open(b_path, 'r', encoding='utf-8') as fb:
        b = json.load(fb)

    a_edges = _normalize_edges(a.get('edges', []))
    b_edges = _normalize_edges(b.get('edges', []))

    if len(a.get('nodes', [])) != len(b.get('nodes', [])):
        raise AssertionError('node counts differ')
    if a_edges != b_edges:
        raise AssertionError('edge sets differ')

    # Optional adjacency checks
    n_nodes = len(a.get('nodes', []))
    a_adj = _adj_from_edges(n_nodes, a_edges)
    b_adj = _adj_from_edges(n_nodes, b_edges)
    if a_adj != b_adj:
        raise AssertionError('adjacency differs after normalization')

    print(f'[OK] Graphs are equivalent: {a_path} == {b_path}')


def main() -> None:
    p = argparse.ArgumentParser(description='Verify FusionAlpha graph artifacts')
    sub = p.add_subparsers(dest='mode', required=True)

    s1 = sub.add_parser('strict', help='Strict verification of a single graph JSON')
    s1.add_argument('graph')

    s2 = sub.add_parser('compare', help='Compare two graph JSONs for equality')
    s2.add_argument('graph_a')
    s2.add_argument('graph_b')

    args = p.parse_args()
    if args.mode == 'strict':
        verify_strict(args.graph)
    elif args.mode == 'compare':
        compare_graphs(args.graph_a, args.graph_b)


if __name__ == '__main__':
    main()

